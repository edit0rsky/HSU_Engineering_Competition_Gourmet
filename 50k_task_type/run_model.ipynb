{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9718f91e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 20:37:59.323508: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-30 20:37:59.683772: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-08-30 20:38:01.239659: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error,\n",
    "    mean_absolute_error,\n",
    "    mean_absolute_percentage_error,\n",
    ")\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "233a5a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK = [\n",
    "    \"RETRIEVAL_QUERY\",\n",
    "    \"CLASSIFICATION\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e690afcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존 모델 학습 코드를 이은다음에 for task in TASK로 반복 실행\n",
    "\n",
    "for task in TASK:\n",
    "    input_file = \"../Dataset/states/fl_split5_\" + task + \".jsonl\"\n",
    "    print(input_file)\n",
    "\n",
    "    df_processed = pd.read_json(\n",
    "        input_file,\n",
    "        lines=True,\n",
    "    )\n",
    "\n",
    "    df_processed.info()\n",
    "\n",
    "    df_processed.head(10)\n",
    "\n",
    "    print(f\"전체 데이터셋 크기: {len(df_processed)}\")\n",
    "\n",
    "    # 각 인코더 객체 생성\n",
    "    user_encoder = LabelEncoder()\n",
    "    business_encoder = LabelEncoder()\n",
    "\n",
    "    # 인코딩 수행\n",
    "    encoded_user_ids = user_encoder.fit_transform(df_processed[\"user_id\"])\n",
    "    encoded_business_ids = business_encoder.fit_transform(df_processed[\"business_id\"])\n",
    "\n",
    "    # 데이터프레임에 인코딩된 열 추가\n",
    "    df_processed[\"user_encoded\"] = encoded_user_ids\n",
    "    df_processed[\"business_encoded\"] = encoded_business_ids\n",
    "\n",
    "    # 리뷰 데이터에서 고유한 사용자와 비지니스 수 계산(이후 모델 입력에 사용)\n",
    "\n",
    "    num_users = len(user_encoder.classes_)\n",
    "    num_businesses = len(business_encoder.classes_)\n",
    "\n",
    "    print(num_users)\n",
    "    print(num_businesses)\n",
    "\n",
    "    # 7:1:2 비율로 데이터셋을 학습, 검증, 테스트로 나누기\n",
    "    # 먼저 학습+검증 / 테스트로 나눔\n",
    "    # 그 후 학습 / 검증으로 나눔\n",
    "\n",
    "    # 학습+검증 / 테스트\n",
    "    train_val_df, test_df = train_test_split(\n",
    "        df_processed, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    # 학습 / 검증\n",
    "    val_size_ratio = 1 / 8  # 전체 데이터의 10% = 학습+검증 데이터의 12.5%\n",
    "    train_df, val_df = train_test_split(\n",
    "        train_val_df, test_size=val_size_ratio, random_state=42\n",
    "    )\n",
    "\n",
    "    print(f\"전체 데이터 수: {len(df_processed)}\")\n",
    "    print(\n",
    "        f\"학습 데이터 수: {len(train_df)} ({len(train_df)/len(df_processed)*100:.2f}%)\"\n",
    "    )\n",
    "    print(f\"검증 데이터 수: {len(val_df)} ({len(val_df)/len(df_processed)*100:.2f}%)\")\n",
    "    print(\n",
    "        f\"테스트 데이터 수: {len(test_df)} ({len(test_df)/len(df_processed)*100:.2f}%)\"\n",
    "    )\n",
    "\n",
    "    train_embeddings = np.array(train_df[\"embedding\"].tolist(), dtype=np.float32)\n",
    "    val_embeddings = np.array(val_df[\"embedding\"].tolist(), dtype=np.float32)\n",
    "    test_embeddings = np.array(test_df[\"embedding\"].tolist(), dtype=np.float32)\n",
    "\n",
    "    print(f\"학습 임베딩 데이터 형태: {train_embeddings.shape}\")\n",
    "    print(f\"검증 임베딩 데이터 형태: {val_embeddings.shape}\")\n",
    "    print(f\"테스트 임베딩 데이터 형태: {test_embeddings.shape}\")\n",
    "\n",
    "    print(f\"데이터 type: {train_embeddings.dtype}\")\n",
    "\n",
    "    # user_id, business_id의 벡터 차원\n",
    "    user_business_embedding_dim = 64\n",
    "\n",
    "    # 유저-비즈니스 상호작용을 처리하는 MLP의 레이어 크기\n",
    "    user_biz_mlp_dims = [128, 64]\n",
    "\n",
    "    # 제미나이 리뷰 텍스트 임베딩 차원\n",
    "    gemini_embedding_dim = 3072\n",
    "\n",
    "    # 최종 예측을 위한 MLP의 각 레이어 크기\n",
    "    final_mlp_dims = [32, 16]\n",
    "\n",
    "    # 학습률\n",
    "    learning_rate = 0.001\n",
    "\n",
    "    # 배치 사이즈\n",
    "    batch_size = 128\n",
    "    # batch_size = 32\n",
    "\n",
    "    # 입력층 정의\n",
    "    user_input = keras.Input(shape=(1,), name=\"user_id_input\")\n",
    "    business_input = keras.Input(shape=(1,), name=\"business_id_input\")\n",
    "\n",
    "    # 임베딩 레이어: 각 유저/비즈니스 ID를 고유한 벡터로 변환\n",
    "    user_embedding_layer = layers.Embedding(\n",
    "        num_users, user_business_embedding_dim, name=\"user_embedding\"\n",
    "    )\n",
    "    business_embedding_layer = layers.Embedding(\n",
    "        num_businesses, user_business_embedding_dim, name=\"business_embedding\"\n",
    "    )\n",
    "\n",
    "    user_vec = layers.Flatten()(user_embedding_layer(user_input))\n",
    "    business_vec = layers.Flatten()(business_embedding_layer(business_input))\n",
    "\n",
    "    # 두 벡터를 하나로 합침\n",
    "    combined_vec = layers.concatenate([user_vec, business_vec])\n",
    "\n",
    "    # 합쳐진 벡터를 MLP에 통과시켜 상호작용 특징을 추출\n",
    "    interaction_features = combined_vec\n",
    "    for dim in user_biz_mlp_dims:\n",
    "        interaction_features = layers.Dense(dim, activation=\"relu\")(\n",
    "            interaction_features\n",
    "        )\n",
    "\n",
    "    # 입력층 정의\n",
    "    gemini_input = keras.Input(\n",
    "        shape=(gemini_embedding_dim,), name=\"gemini_embedding_input\"\n",
    "    )\n",
    "\n",
    "    # 제미나이 임베딩(리뷰 텍스트)을 처리하는 MLP\n",
    "    review_features = layers.Dense(1536, activation=\"relu\")(gemini_input)\n",
    "    review_features = layers.Dense(768, activation=\"relu\")(review_features)\n",
    "    review_features = layers.Dense(512, activation=\"relu\")(review_features)\n",
    "    # review_features = layers.Dense(256, activation=\"relu\")(review_features)\n",
    "\n",
    "    # 모듈 1과 모듈 2에서 추출된 특징들을 concat\n",
    "    final_combined_features = layers.concatenate(\n",
    "        [interaction_features, review_features]\n",
    "    )\n",
    "\n",
    "    # 최종적으로 별점을 예측하는 MLP\n",
    "    predicted_rating = final_combined_features\n",
    "    for dim in final_mlp_dims:\n",
    "        predicted_rating = layers.Dense(dim, activation=\"relu\")(predicted_rating)\n",
    "\n",
    "    # 출력층 : 1개의 숫자로 된 최종 별점을 예측\n",
    "    output_rating = layers.Dense(1, activation=\"linear\", name=\"output_rating\")(\n",
    "        predicted_rating\n",
    "    )\n",
    "\n",
    "    # 최종 모델 정의, 어떤 입력들을 받고 어떤 출력을 내보낼지 설정\n",
    "    final_model = models.Model(\n",
    "        inputs=[user_input, business_input, gemini_input], outputs=output_rating\n",
    "    )\n",
    "\n",
    "    ############################################################\n",
    "\n",
    "    final_model.compile(\n",
    "        # Adam 옵티마이저\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        # loss 함수 = 평균 제곱 오차 (MSE)\n",
    "        loss=\"mse\",\n",
    "        # 학습 중 모니터링할 지표 설정(rmse, mae)\n",
    "        metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"rmse\"), \"mae\"],\n",
    "    )\n",
    "\n",
    "    final_model_base_path = f\"final_best_gemini_model_{task}\"\n",
    "\n",
    "    early_stopping_callback = callbacks.EarlyStopping(\n",
    "        monitor=\"val_rmse\",\n",
    "        patience=10,\n",
    "        min_delta=0.0005,\n",
    "        mode=\"min\",\n",
    "        restore_best_weights=True,\n",
    "    )\n",
    "\n",
    "    final_model_path = f\"{final_model_base_path}_main.keras\"\n",
    "\n",
    "    model_checkpoint_callback = callbacks.ModelCheckpoint(\n",
    "        filepath=final_model_path,\n",
    "        monitor=\"val_rmse\",\n",
    "        save_best_only=True,\n",
    "        mode=\"min\",\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    #####################################################\n",
    "\n",
    "    print(f\"\\n==== [{task}] 버전 학습 시작\")\n",
    "\n",
    "    epochs = 50\n",
    "\n",
    "    history = final_model.fit(\n",
    "        # 입력 데이터\n",
    "        {\n",
    "            \"user_id_input\": train_df[\"user_encoded\"],\n",
    "            \"business_id_input\": train_df[\"business_encoded\"],\n",
    "            \"gemini_embedding_input\": train_embeddings,\n",
    "        },\n",
    "        # 정답 데이터\n",
    "        train_df[\"review_stars\"],\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        # 검증 시 사용할 데이터\n",
    "        validation_data=(\n",
    "            {\n",
    "                \"user_id_input\": val_df[\"user_encoded\"],\n",
    "                \"business_id_input\": val_df[\"business_encoded\"],\n",
    "                \"gemini_embedding_input\": val_embeddings,\n",
    "            },\n",
    "            val_df[\"review_stars\"],\n",
    "        ),\n",
    "        # 콜백 설정\n",
    "        callbacks=[early_stopping_callback, model_checkpoint_callback],\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    #########################################################################################\n",
    "\n",
    "    final_model = keras.models.load_model(final_model_path)\n",
    "\n",
    "    test_predictions = final_model.predict(\n",
    "        {\n",
    "            \"user_id_input\": test_df[\"user_encoded\"],\n",
    "            \"business_id_input\": test_df[\"business_encoded\"],\n",
    "            \"gemini_embedding_input\": test_embeddings,\n",
    "        }\n",
    "    ).flatten()\n",
    "\n",
    "    # 테스트 데이터 평점 열을 nparray로 가져옴\n",
    "    true_ratings = test_df[\"review_stars\"].values\n",
    "\n",
    "    # 각종 평가지표 계산\n",
    "    mse = mean_squared_error(true_ratings, test_predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(true_ratings, test_predictions)\n",
    "    mape = mean_absolute_percentage_error(true_ratings, test_predictions) * 100\n",
    "\n",
    "    # 출력\n",
    "    print(f\"{task}버전 모델 성능 평가\")\n",
    "    print(f\"MSE: {mse:.4f}\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "    print(f\"MAPE: {mape:.2f}%\")\n",
    "\n",
    "    # 5번 반복해 테스트하고 각 평가지표들의 표준편차가 < 0.005 인지 확인\n",
    "\n",
    "    # 각 실행의 평가지표를 저장할 리스트 초기화\n",
    "    mse_scores = []\n",
    "    rmse_scores = []\n",
    "    mae_scores = []\n",
    "    mape_scores = []\n",
    "\n",
    "    # 총 실행 횟수\n",
    "    num_runs = 5\n",
    "    for i in range(num_runs):\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(f\"                   실험 {i+1}/{num_runs} 시작\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "        user_input = keras.Input(shape=(1,), name=\"user_id_input\")\n",
    "        business_input = keras.Input(shape=(1,), name=\"business_id_input\")\n",
    "        gemini_input = keras.Input(\n",
    "            shape=(gemini_embedding_dim,), name=\"gemini_embedding_input\"\n",
    "        )\n",
    "\n",
    "        user_embedding_layer = layers.Embedding(\n",
    "            num_users, user_business_embedding_dim, name=\"user_embedding\"\n",
    "        )\n",
    "        business_embedding_layer = layers.Embedding(\n",
    "            num_businesses, user_business_embedding_dim, name=\"business_embedding\"\n",
    "        )\n",
    "        user_vec = layers.Flatten()(user_embedding_layer(user_input))\n",
    "        business_vec = layers.Flatten()(business_embedding_layer(business_input))\n",
    "        combined_vec = layers.concatenate([user_vec, business_vec])\n",
    "        interaction_features = combined_vec\n",
    "        for dim in user_biz_mlp_dims:\n",
    "            interaction_features = layers.Dense(dim, activation=\"relu\")(\n",
    "                interaction_features\n",
    "            )\n",
    "\n",
    "        review_features = layers.Dense(1536, activation=\"relu\")(gemini_input)\n",
    "        review_features = layers.Dense(768, activation=\"relu\")(review_features)\n",
    "        review_features = layers.Dense(512, activation=\"relu\")(review_features)\n",
    "\n",
    "        final_combined_features = layers.concatenate(\n",
    "            [interaction_features, review_features]\n",
    "        )\n",
    "        predicted_rating = final_combined_features\n",
    "        for dim in final_mlp_dims:\n",
    "            predicted_rating = layers.Dense(dim, activation=\"relu\")(predicted_rating)\n",
    "        output_rating = layers.Dense(1, activation=\"linear\", name=\"output_rating\")(\n",
    "            predicted_rating\n",
    "        )\n",
    "\n",
    "        run_model = models.Model(\n",
    "            inputs=[user_input, business_input, gemini_input], outputs=output_rating\n",
    "        )\n",
    "        run_model.compile(\n",
    "            optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"rmse\"), \"mae\"],\n",
    "        )\n",
    "\n",
    "        ########\n",
    "\n",
    "        run_ckpt_path = f\"{final_model_base_path}_run{i+1}.keras\"\n",
    "        run_es = callbacks.EarlyStopping(\n",
    "            monitor=\"val_rmse\",\n",
    "            patience=10,\n",
    "            min_delta=0.0005,\n",
    "            mode=\"min\",\n",
    "            restore_best_weights=True,\n",
    "        )\n",
    "        run_ckpt = callbacks.ModelCheckpoint(\n",
    "            filepath=run_ckpt_path,\n",
    "            monitor=\"val_rmse\",\n",
    "            save_best_only=True,\n",
    "            mode=\"min\",\n",
    "            verbose=0,\n",
    "        )\n",
    "\n",
    "        ########\n",
    "\n",
    "        run_model.fit(\n",
    "            {\n",
    "                \"user_id_input\": train_df[\"user_encoded\"],\n",
    "                \"business_id_input\": train_df[\"business_encoded\"],\n",
    "                \"gemini_embedding_input\": train_embeddings,\n",
    "            },\n",
    "            train_df[\"review_stars\"],\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            validation_data=(\n",
    "                {\n",
    "                    \"user_id_input\": val_df[\"user_encoded\"],\n",
    "                    \"business_id_input\": val_df[\"business_encoded\"],\n",
    "                    \"gemini_embedding_input\": val_embeddings,\n",
    "                },\n",
    "                val_df[\"review_stars\"],\n",
    "            ),\n",
    "            callbacks=[run_es, run_ckpt],\n",
    "            verbose=0,\n",
    "        )\n",
    "        print(f\"실험 {i+1}: 모델 학습 완료.\")\n",
    "\n",
    "        best_model = keras.models.load_model(run_ckpt_path)\n",
    "\n",
    "        predictions = best_model.predict(\n",
    "            {\n",
    "                \"user_id_input\": test_df[\"user_encoded\"],\n",
    "                \"business_id_input\": test_df[\"business_encoded\"],\n",
    "                \"gemini_embedding_input\": test_embeddings,\n",
    "            }\n",
    "        ).flatten()\n",
    "\n",
    "        true_ratings = test_df[\"review_stars\"].values\n",
    "        mse = mean_squared_error(true_ratings, predictions)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae = mean_absolute_error(true_ratings, predictions)\n",
    "        mape = mean_absolute_percentage_error(true_ratings, predictions) * 100\n",
    "\n",
    "        # 결과 저장\n",
    "        mse_scores.append(mse)\n",
    "        rmse_scores.append(rmse)\n",
    "        mae_scores.append(mae)\n",
    "        mape_scores.append(mape)\n",
    "\n",
    "        print(f\"실험 {i+1} 결과 - RMSE: {rmse:.4f}, MAE: {mae:.4f}, MAPE: {mape:.2f}%\")\n",
    "\n",
    "        ####\n",
    "\n",
    "        del run_model\n",
    "        del best_model\n",
    "        del predictions\n",
    "\n",
    "        import gc\n",
    "\n",
    "        gc.collect()\n",
    "\n",
    "        tf.keras.backend.clear_session()\n",
    "\n",
    "    # mse 평가지표의 평균과 표준편차 계산\n",
    "    avg_mse = np.mean(mse_scores)\n",
    "    std_mse = np.std(mse_scores)\n",
    "\n",
    "    # rmse 평가지표의 평균과 표준편차 계산\n",
    "    avg_rmse = np.mean(rmse_scores)\n",
    "    std_rmse = np.std(rmse_scores)\n",
    "\n",
    "    # mae 평가지표의 평균과 표준편차 계산\n",
    "    avg_mae = np.mean(mae_scores)\n",
    "    std_mae = np.std(mae_scores)\n",
    "\n",
    "    # mape 평가지표의 평균과 표준편차 계산\n",
    "    avg_mape = np.mean(mape_scores)\n",
    "    std_mape = np.std(mape_scores)\n",
    "\n",
    "    # --- 최종 결과 보고 ---\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(f\"{task}버전 모델 성능 통계 (5회 실행 평균)\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"평균 MSE: {avg_mse:.4f} (표준편차: {std_mse:.4f})\")\n",
    "    print(f\"평균 RMSE: {avg_rmse:.4f} (표준편차: {std_rmse:.4f})\")\n",
    "    print(f\"평균 MAE : {avg_mae:.4f} (표준편차: {std_mae:.4f})\")\n",
    "    print(f\"평균 MAPE: {avg_mape:.2f}% (표준편차: {std_mape:.2f})\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # 결과 데이터를 딕셔너리 형태로 구성\n",
    "    # 각 평가지표에 대한 5회의 실행 결과, 평균, 표준편차를 정리\n",
    "    summary_data = {\n",
    "        \"Metric\": [\"MSE\", \"RMSE\", \"MAE\", \"MAPE (%)\"],\n",
    "        \"Run 1\": [mse_scores[0], rmse_scores[0], mae_scores[0], mape_scores[0]],\n",
    "        \"Run 2\": [mse_scores[1], rmse_scores[1], mae_scores[1], mape_scores[1]],\n",
    "        \"Run 3\": [mse_scores[2], rmse_scores[2], mae_scores[2], mape_scores[2]],\n",
    "        \"Run 4\": [mse_scores[3], rmse_scores[3], mae_scores[3], mape_scores[3]],\n",
    "        \"Run 5\": [mse_scores[4], rmse_scores[4], mae_scores[4], mape_scores[4]],\n",
    "        \"Average\": [avg_mse, avg_rmse, avg_mae, avg_mape],\n",
    "        \"Std. Deviation\": [std_mse, std_rmse, std_mae, std_mape],\n",
    "    }\n",
    "\n",
    "    # 딕셔너리를 DataFrame으로 변환\n",
    "    results_df = pd.DataFrame(summary_data)\n",
    "\n",
    "    # 가독성을 위해 소수점 자리수를 정리\n",
    "    results_df = results_df.round(\n",
    "        {\n",
    "            \"Run 1\": 4,\n",
    "            \"Run 2\": 4,\n",
    "            \"Run 3\": 4,\n",
    "            \"Run 4\": 4,\n",
    "            \"Run 5\": 4,\n",
    "            \"Average\": 4,\n",
    "            \"Std. Deviation\": 4,\n",
    "        }\n",
    "    )\n",
    "    # MAPE는 % 단위이므로 소수점 2자리로 별도 처리\n",
    "    results_df.loc[results_df[\"Metric\"] == \"MAPE (%)\"] = results_df.loc[\n",
    "        results_df[\"Metric\"] == \"MAPE (%)\"\n",
    "    ].round(2)\n",
    "\n",
    "    print(f\"--- [{task}] 버전 최종 성능 요약 테이블 ---\")\n",
    "\n",
    "    results_df.to_csv(\n",
    "        \"../performance/model_performance_\" + task + \".csv\",\n",
    "        index=False,\n",
    "        encoding=\"utf-8-sig\",\n",
    "    )\n",
    "    print(\"csv로 저장 완료\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
