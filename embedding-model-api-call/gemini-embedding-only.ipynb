{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51efefd4",
   "metadata": {},
   "source": [
    "### 임베딩 데이터셋에서 필요없는 컬럼 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16accb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bb23fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 경로\n",
    "input_file_path = \"Dataset/3states/dataset_pa_with_embeddings.jsonl\"\n",
    "output_file_path = \"Dataset/3states/dataset_pa_with_embeddings_vector.jsonl\"\n",
    "\n",
    "# 청크사이즈\n",
    "chunk_size = 5000\n",
    "\n",
    "#임베딩 벡터 들어있는 컬럼\n",
    "embedding_column = \"embedding\"\n",
    "\n",
    "# 드랍할 컬럼명\n",
    "review_text = \"text\"\n",
    "review_useful = \"review_useful\"\n",
    "review_date = \"date\"\n",
    "\n",
    "# 예상 임베딩 차원, 다르면 알림\n",
    "expected_dimension = 3072"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486d4b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Dataset/3states/dataset_pa_with_embeddings.jsonl' 파일 처리를 시작합니다...\n",
      "1번째 청크 처리 완료. (누적 5000 라인)\n",
      "2번째 청크 처리 완료. (누적 10000 라인)\n",
      "3번째 청크 처리 완료. (누적 15000 라인)\n",
      "4번째 청크 처리 완료. (누적 20000 라인)\n",
      "5번째 청크 처리 완료. (누적 25000 라인)\n",
      "6번째 청크 처리 완료. (누적 30000 라인)\n",
      "7번째 청크 처리 완료. (누적 35000 라인)\n",
      "8번째 청크 처리 완료. (누적 40000 라인)\n",
      "9번째 청크 처리 완료. (누적 45000 라인)\n",
      "10번째 청크 처리 완료. (누적 50000 라인)\n",
      "11번째 청크 처리 완료. (누적 55000 라인)\n",
      "12번째 청크 처리 완료. (누적 60000 라인)\n",
      "13번째 청크 처리 완료. (누적 65000 라인)\n",
      "14번째 청크 처리 완료. (누적 70000 라인)\n",
      "15번째 청크 처리 완료. (누적 75000 라인)\n",
      "16번째 청크 처리 완료. (누적 80000 라인)\n",
      "17번째 청크 처리 완료. (누적 85000 라인)\n",
      "18번째 청크 처리 완료. (누적 90000 라인)\n",
      "19번째 청크 처리 완료. (누적 95000 라인)\n",
      "20번째 청크 처리 완료. (누적 100000 라인)\n",
      "21번째 청크 처리 완료. (누적 105000 라인)\n",
      "22번째 청크 처리 완료. (누적 110000 라인)\n",
      "23번째 청크 처리 완료. (누적 115000 라인)\n",
      "24번째 청크 처리 완료. (누적 120000 라인)\n",
      "25번째 청크 처리 완료. (누적 125000 라인)\n",
      "26번째 청크 처리 완료. (누적 130000 라인)\n",
      "27번째 청크 처리 완료. (누적 135000 라인)\n",
      "28번째 청크 처리 완료. (누적 140000 라인)\n",
      "29번째 청크 처리 완료. (누적 145000 라인)\n",
      "30번째 청크 처리 완료. (누적 150000 라인)\n",
      "31번째 청크 처리 완료. (누적 155000 라인)\n",
      "32번째 청크 처리 완료. (누적 160000 라인)\n",
      "33번째 청크 처리 완료. (누적 165000 라인)\n",
      "34번째 청크 처리 완료. (누적 170000 라인)\n",
      "35번째 청크 처리 완료. (누적 175000 라인)\n",
      "36번째 청크 처리 완료. (누적 180000 라인)\n",
      "37번째 청크 처리 완료. (누적 185000 라인)\n",
      "38번째 청크 처리 완료. (누적 190000 라인)\n",
      "39번째 청크 처리 완료. (누적 195000 라인)\n",
      "40번째 청크 처리 완료. (누적 200000 라인)\n",
      "41번째 청크 처리 완료. (누적 205000 라인)\n",
      "42번째 청크 처리 완료. (누적 210000 라인)\n",
      "43번째 청크 처리 완료. (누적 215000 라인)\n",
      "44번째 청크 처리 완료. (누적 220000 라인)\n",
      "45번째 청크 처리 완료. (누적 225000 라인)\n",
      "46번째 청크 처리 완료. (누적 230000 라인)\n",
      "47번째 청크 처리 완료. (누적 235000 라인)\n",
      "48번째 청크 처리 완료. (누적 240000 라인)\n",
      "49번째 청크 처리 완료. (누적 245000 라인)\n",
      "50번째 청크 처리 완료. (누적 250000 라인)\n",
      "51번째 청크 처리 완료. (누적 255000 라인)\n",
      "52번째 청크 처리 완료. (누적 260000 라인)\n",
      "53번째 청크 처리 완료. (누적 265000 라인)\n",
      "54번째 청크 처리 완료. (누적 270000 라인)\n",
      "55번째 청크 처리 완료. (누적 275000 라인)\n",
      "56번째 청크 처리 완료. (누적 280000 라인)\n",
      "57번째 청크 처리 완료. (누적 285000 라인)\n",
      "58번째 청크 처리 완료. (누적 290000 라인)\n",
      "59번째 청크 처리 완료. (누적 295000 라인)\n",
      "60번째 청크 처리 완료. (누적 300000 라인)\n",
      "61번째 청크 처리 완료. (누적 305000 라인)\n",
      "62번째 청크 처리 완료. (누적 310000 라인)\n",
      "63번째 청크 처리 완료. (누적 315000 라인)\n",
      "64번째 청크 처리 완료. (누적 320000 라인)\n",
      "65번째 청크 처리 완료. (누적 325000 라인)\n",
      "66번째 청크 처리 완료. (누적 330000 라인)\n",
      "67번째 청크 처리 완료. (누적 335000 라인)\n",
      "68번째 청크 처리 완료. (누적 340000 라인)\n",
      "69번째 청크 처리 완료. (누적 345000 라인)\n",
      "70번째 청크 처리 완료. (누적 350000 라인)\n",
      "71번째 청크 처리 완료. (누적 355000 라인)\n",
      "72번째 청크 처리 완료. (누적 360000 라인)\n",
      "73번째 청크 처리 완료. (누적 365000 라인)\n",
      "74번째 청크 처리 완료. (누적 370000 라인)\n",
      "75번째 청크 처리 완료. (누적 375000 라인)\n",
      "76번째 청크 처리 완료. (누적 380000 라인)\n",
      "77번째 청크 처리 완료. (누적 385000 라인)\n",
      "78번째 청크 처리 완료. (누적 390000 라인)\n",
      "79번째 청크 처리 완료. (누적 395000 라인)\n",
      "80번째 청크 처리 완료. (누적 400000 라인)\n",
      "81번째 청크 처리 완료. (누적 405000 라인)\n",
      "82번째 청크 처리 완료. (누적 410000 라인)\n",
      "83번째 청크 처리 완료. (누적 415000 라인)\n",
      "84번째 청크 처리 완료. (누적 420000 라인)\n",
      "85번째 청크 처리 완료. (누적 425000 라인)\n",
      "86번째 청크 처리 완료. (누적 430000 라인)\n",
      "87번째 청크 처리 완료. (누적 435000 라인)\n",
      "88번째 청크 처리 완료. (누적 440000 라인)\n",
      "89번째 청크 처리 완료. (누적 445000 라인)\n",
      "90번째 청크 처리 완료. (누적 450000 라인)\n",
      "91번째 청크 처리 완료. (누적 455000 라인)\n",
      "92번째 청크 처리 완료. (누적 460000 라인)\n",
      "93번째 청크 처리 완료. (누적 465000 라인)\n",
      "94번째 청크 처리 완료. (누적 470000 라인)\n",
      "95번째 청크 처리 완료. (누적 475000 라인)\n",
      "96번째 청크 처리 완료. (누적 480000 라인)\n",
      "97번째 청크 처리 완료. (누적 485000 라인)\n",
      "98번째 청크 처리 완료. (누적 490000 라인)\n",
      "99번째 청크 처리 완료. (누적 495000 라인)\n",
      "100번째 청크 처리 완료. (누적 500000 라인)\n",
      "101번째 청크 처리 완료. (누적 505000 라인)\n",
      "102번째 청크 처리 완료. (누적 510000 라인)\n",
      "103번째 청크 처리 완료. (누적 515000 라인)\n",
      "104번째 청크 처리 완료. (누적 520000 라인)\n",
      "105번째 청크 처리 완료. (누적 525000 라인)\n",
      "106번째 청크 처리 완료. (누적 530000 라인)\n",
      "107번째 청크 처리 완료. (누적 535000 라인)\n",
      "108번째 청크 처리 완료. (누적 540000 라인)\n",
      "109번째 청크 처리 완료. (누적 545000 라인)\n",
      "110번째 청크 처리 완료. (누적 550000 라인)\n",
      "111번째 청크 처리 완료. (누적 555000 라인)\n",
      "112번째 청크 처리 완료. (누적 560000 라인)\n",
      "113번째 청크 처리 완료. (누적 565000 라인)\n",
      "114번째 청크 처리 완료. (누적 570000 라인)\n",
      "115번째 청크 처리 완료. (누적 575000 라인)\n",
      "116번째 청크 처리 완료. (누적 580000 라인)\n",
      "117번째 청크 처리 완료. (누적 585000 라인)\n",
      "118번째 청크 처리 완료. (누적 590000 라인)\n",
      "119번째 청크 처리 완료. (누적 595000 라인)\n",
      "120번째 청크 처리 완료. (누적 600000 라인)\n",
      "121번째 청크 처리 완료. (누적 605000 라인)\n",
      "122번째 청크 처리 완료. (누적 610000 라인)\n",
      "123번째 청크 처리 완료. (누적 615000 라인)\n",
      "124번째 청크 처리 완료. (누적 620000 라인)\n",
      "125번째 청크 처리 완료. (누적 625000 라인)\n",
      "126번째 청크 처리 완료. (누적 630000 라인)\n",
      "127번째 청크 처리 완료. (누적 635000 라인)\n",
      "128번째 청크 처리 완료. (누적 640000 라인)\n",
      "129번째 청크 처리 완료. (누적 645000 라인)\n",
      "130번째 청크 처리 완료. (누적 650000 라인)\n",
      "131번째 청크 처리 완료. (누적 655000 라인)\n",
      "132번째 청크 처리 완료. (누적 660000 라인)\n",
      "133번째 청크 처리 완료. (누적 665000 라인)\n",
      "134번째 청크 처리 완료. (누적 670000 라인)\n",
      "135번째 청크 처리 완료. (누적 675000 라인)\n",
      "136번째 청크 처리 완료. (누적 680000 라인)\n",
      "137번째 청크 처리 완료. (누적 685000 라인)\n",
      "138번째 청크 처리 완료. (누적 690000 라인)\n",
      "139번째 청크 처리 완료. (누적 695000 라인)\n",
      "140번째 청크 처리 완료. (누적 700000 라인)\n",
      "141번째 청크 처리 완료. (누적 705000 라인)\n",
      "142번째 청크 처리 완료. (누적 710000 라인)\n",
      "143번째 청크 처리 완료. (누적 715000 라인)\n",
      "144번째 청크 처리 완료. (누적 720000 라인)\n",
      "145번째 청크 처리 완료. (누적 725000 라인)\n",
      "146번째 청크 처리 완료. (누적 730000 라인)\n",
      "147번째 청크 처리 완료. (누적 735000 라인)\n",
      "148번째 청크 처리 완료. (누적 740000 라인)\n",
      "149번째 청크 처리 완료. (누적 745000 라인)\n",
      "150번째 청크 처리 완료. (누적 750000 라인)\n",
      "151번째 청크 처리 완료. (누적 750446 라인)\n",
      "\n",
      "🎉 모든 작업이 완료되었습니다!\n",
      "최종 결과가 'Dataset/3states/dataset_pa_with_embeddings_vector.jsonl' 파일에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# 이전에 실행해서 파일이 남아있다면 삭제\n",
    "if os.path.exists(output_file_path):\n",
    "    os.remove(output_file_path)\n",
    "    print(f\"기존 '{output_file_path}' 파일을 삭제했습니다.\")\n",
    "\n",
    "try:\n",
    "    # 임베딩 데이터셋 청크단위로 읽음\n",
    "    json_reader = pd.read_json(input_file_path, lines=True, chunksize=chunk_size)\n",
    "\n",
    "    print(f\"'{input_file_path}' 파일 처리를 시작합니다...\")\n",
    "    total_lines = 0\n",
    "\n",
    "    # 각 청크마다\n",
    "    for i, chunk in enumerate(json_reader):\n",
    "\n",
    "        # embedding 컬럼 차원 확인\n",
    "        if embedding_column in chunk.columns:\n",
    "            # 각 임베딩 벡터의 길이를 계산\n",
    "            dimensions = chunk[embedding_column].apply(len)\n",
    "            # 예상 차원과 다른 행이 있는지 확인\n",
    "            mismatched_rows = chunk[dimensions != expected_dimension]\n",
    "            # 문제가 있는 행이 하나라도 있다면 경고 메시지 출력\n",
    "            if not mismatched_rows.empty:\n",
    "                print(\n",
    "                    f\"{i+1}번째 청크에서 차원이 {expected_dimension}이(가) 아닌 데이터가 발견되었습니다.\"\n",
    "                )\n",
    "                print(\n",
    "                    f\"   -> 문제가 있는 행의 인덱스: {mismatched_rows.index.tolist()}\"\n",
    "                )\n",
    "        else:\n",
    "            print(f\"{i+1}번째 청크에 '{embedding_column}' 컬럼이 없습니다.\")\n",
    "\n",
    "        # 필요없는 컬럼 드랍\n",
    "        chunk_modified = chunk.drop(\n",
    "            columns=[review_text, review_useful, review_date], errors=\"ignore\"\n",
    "        )\n",
    "\n",
    "        # 수정된 청크 append\n",
    "        chunk_modified.to_json(\n",
    "            output_file_path,\n",
    "            orient=\"records\",\n",
    "            lines=True,\n",
    "            mode=\"a\",\n",
    "        )\n",
    "\n",
    "        total_lines += len(chunk)\n",
    "        print(f\"{i+1}번째 청크 처리 완료. (누적 {total_lines} 라인)\")\n",
    "    print(f\"최종 결과가 '{output_file_path}' 파일에 저장되었습니다.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"입력 파일 '{input_file_path}'를 찾을 수 없습니다.\")\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생 : {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
