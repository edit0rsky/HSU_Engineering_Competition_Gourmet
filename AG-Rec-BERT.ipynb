{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6NItGCfVGlp",
        "outputId": "18d84830-aa91-40e8-cf2d-17ee8c3b21fc"
      },
      "id": "I6NItGCfVGlp",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a914c52a-4cfb-4113-908e-2118452e8ba7",
      "metadata": {
        "id": "a914c52a-4cfb-4113-908e-2118452e8ba7"
      },
      "source": [
        "라이브러리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "3b38ca08-2950-45f2-aba9-bbcb59c0065b",
      "metadata": {
        "id": "3b38ca08-2950-45f2-aba9-bbcb59c0065b"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models, callbacks\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d83d9c16-4e3c-43a6-87a7-bb1e76d56f0e",
      "metadata": {
        "id": "d83d9c16-4e3c-43a6-87a7-bb1e76d56f0e"
      },
      "source": [
        "파라미터"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "9c48a4fb-12c8-40c3-bb21-4397658a417a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9c48a4fb-12c8-40c3-bb21-4397658a417a",
        "outputId": "6550314d-3b2f-4cc4-fe22-6b3a9bbeedef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "데이터 로드 중...\n",
            " 데이터 로드 완료.\n",
            " 데이터 전처리 완료.\n"
          ]
        }
      ],
      "source": [
        "# ====== 파일 경로 및 모델 설정 변경 ======\n",
        "JSONL_PATH = '/content/drive/MyDrive/dataset_la_emd.jsonl'\n",
        "MODEL_SAVE_PATH = '/content/drive/MyDrive/final_best_hybrid_bert_model.keras'\n",
        "\n",
        "# BERT 임베딩 차원에 맞게 파라미터 수정\n",
        "best_params = {\n",
        "    'user_embedding_dim': 128,\n",
        "    'business_embedding_dim': 32,\n",
        "    'bert_mlp_dims': [768, 384, 192], # BERT 임베딩 차원(768)에 맞춰 시작\n",
        "    'user_biz_mlp_dims': [128, 64],\n",
        "    'final_mlp_dims': [64, 32],\n",
        "    'learning_rate': 0.0001,\n",
        "    'batch_size': 256\n",
        "}\n",
        "\n",
        "# ====== 2. 데이터 로드 및 전처리 ======\n",
        "# JSONL 파일에서 데이터 로드\n",
        "print(\"데이터 로드 중...\")\n",
        "records = []\n",
        "with open(JSONL_PATH, 'r', encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        records.append(json.loads(line))\n",
        "\n",
        "df = pd.DataFrame(records)\n",
        "print(\" 데이터 로드 완료.\")\n",
        "\n",
        "# 필요한 필드만 선택하고 임베딩 열의 이름을 'embedding'으로 변경\n",
        "df_processed = df[['user_id', 'business_id', 'stars', 'bert_embedding']].copy()\n",
        "df_processed.rename(columns={'bert_embedding': 'embedding'}, inplace=True)\n",
        "\n",
        "# 임베딩 데이터 타입을 NumPy 배열로 변환 (추후 모델 학습에 필요)\n",
        "df_processed['embedding'] = df_processed['embedding'].apply(np.array)\n",
        "\n",
        "print(\" 데이터 전처리 완료.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7be44d46-947c-420c-89ca-7c0a94d8c496",
      "metadata": {
        "id": "7be44d46-947c-420c-89ca-7c0a94d8c496"
      },
      "source": [
        "모델"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "8372b8f6-7b5c-4fd9-bb55-fc7aae873b97",
      "metadata": {
        "id": "8372b8f6-7b5c-4fd9-bb55-fc7aae873b97"
      },
      "outputs": [],
      "source": [
        "def build_hybrid_bert_model(num_users, num_businesses, user_embedding_dim, business_embedding_dim,\n",
        "                             bert_embedding_dim, user_biz_mlp_dims, bert_mlp_dims, final_mlp_dims):\n",
        "\n",
        "    # 사용자-비즈니스 상호작용 모듈\n",
        "    user_input = keras.Input(shape=(1,), name='user_id')\n",
        "    business_input = keras.Input(shape=(1,), name='business_id')\n",
        "\n",
        "    user_embedding = layers.Embedding(num_users, user_embedding_dim, name='user_embedding')(user_input)\n",
        "    user_vec = layers.Flatten()(user_embedding)\n",
        "\n",
        "    business_embedding = layers.Embedding(num_businesses, business_embedding_dim, name='business_embedding')(business_input)\n",
        "    business_vec = layers.Flatten()(business_embedding)\n",
        "\n",
        "    combined_vec = layers.concatenate([user_vec, business_vec], axis=1)\n",
        "    interaction_features = combined_vec\n",
        "    for dim in user_biz_mlp_dims:\n",
        "        interaction_features = layers.Dense(dim, activation='relu')(interaction_features)\n",
        "\n",
        "    # BERT 임베딩 모듈\n",
        "    bert_input = keras.Input(shape=(bert_embedding_dim,), name='bert_embedding')\n",
        "    bert_features = bert_input\n",
        "    for dim in bert_mlp_dims:\n",
        "        bert_features = layers.Dense(dim, activation='relu')(bert_features)\n",
        "\n",
        "    # 최종 예측 모듈\n",
        "    final_combined_features = layers.concatenate([interaction_features, bert_features], axis=1)\n",
        "\n",
        "    predicted_rating = final_combined_features\n",
        "    for dim in final_mlp_dims:\n",
        "        predicted_rating = layers.Dense(dim, activation='relu')(predicted_rating)\n",
        "    predicted_rating = layers.Dense(1, activation='linear', name='output_rating')(predicted_rating)\n",
        "\n",
        "    model = models.Model(inputs=[user_input, business_input, bert_input],\n",
        "                         outputs=predicted_rating)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ecce5f55-f715-4ac8-8208-975a0b54513a",
      "metadata": {
        "id": "ecce5f55-f715-4ac8-8208-975a0b54513a"
      },
      "source": [
        "데이터 분할 / 5회 반복"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "78df1c1f-75a0-4f97-96d8-828787a3478c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78df1c1f-75a0-4f97-96d8-828787a3478c",
        "outputId": "ef2d1129-67f0-46c7-cb06-8f3914e484d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1번째\n",
            "\n",
            "Epoch 1/50\n",
            "\u001b[1m760/760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - loss: 1.9941 - mae: 1.0797 - rmse: 1.3791 - val_loss: 1.2712 - val_mae: 0.8853 - val_rmse: 1.1275\n",
            "Epoch 2/50\n",
            "\u001b[1m760/760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 1.1531 - mae: 0.8454 - rmse: 1.0738 - val_loss: 1.1868 - val_mae: 0.8648 - val_rmse: 1.0894\n",
            "Epoch 3/50\n",
            "\u001b[1m760/760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.9991 - mae: 0.7729 - rmse: 0.9995 - val_loss: 1.1794 - val_mae: 0.8460 - val_rmse: 1.0860\n",
            "Epoch 4/50\n",
            "\u001b[1m760/760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.9327 - mae: 0.7421 - rmse: 0.9657 - val_loss: 1.1820 - val_mae: 0.8410 - val_rmse: 1.0872\n",
            "Epoch 5/50\n",
            "\u001b[1m760/760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.8973 - mae: 0.7245 - rmse: 0.9472 - val_loss: 1.2068 - val_mae: 0.8428 - val_rmse: 1.0985\n",
            "Epoch 6/50\n",
            "\u001b[1m760/760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.8697 - mae: 0.7091 - rmse: 0.9325 - val_loss: 1.2208 - val_mae: 0.8301 - val_rmse: 1.1049\n",
            "Epoch 7/50\n",
            "\u001b[1m760/760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.8423 - mae: 0.6945 - rmse: 0.9177 - val_loss: 1.2327 - val_mae: 0.8415 - val_rmse: 1.1103\n",
            "Epoch 8/50\n",
            "\u001b[1m760/760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.8038 - mae: 0.6731 - rmse: 0.8965 - val_loss: 1.2394 - val_mae: 0.8456 - val_rmse: 1.1133\n",
            "\u001b[1m1737/1737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
            " 1번째 - MSE: 1.1724, RMSE: 1.0828, MAE: 0.8440, MAPE: 0.3417\n",
            "2번째\n",
            "\n",
            "Epoch 1/50\n",
            "\u001b[1m760/760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 2.0994 - mae: 1.1046 - rmse: 1.4108 - val_loss: 1.2608 - val_mae: 0.9008 - val_rmse: 1.1229\n",
            "Epoch 2/50\n",
            "\u001b[1m760/760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 1.1471 - mae: 0.8434 - rmse: 1.0710 - val_loss: 1.1802 - val_mae: 0.8378 - val_rmse: 1.0864\n",
            "Epoch 3/50\n",
            "\u001b[1m760/760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.9986 - mae: 0.7729 - rmse: 0.9993 - val_loss: 1.1754 - val_mae: 0.8324 - val_rmse: 1.0842\n",
            "Epoch 4/50\n",
            "\u001b[1m760/760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.9372 - mae: 0.7426 - rmse: 0.9680 - val_loss: 1.1756 - val_mae: 0.8309 - val_rmse: 1.0843\n",
            "Epoch 5/50\n",
            "\u001b[1m760/760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.9033 - mae: 0.7264 - rmse: 0.9504 - val_loss: 1.1917 - val_mae: 0.8381 - val_rmse: 1.0917\n",
            "Epoch 6/50\n",
            "\u001b[1m760/760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.8735 - mae: 0.7096 - rmse: 0.9345 - val_loss: 1.1969 - val_mae: 0.8518 - val_rmse: 1.0940\n",
            "Epoch 7/50\n",
            "\u001b[1m760/760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.8493 - mae: 0.6968 - rmse: 0.9215 - val_loss: 1.2021 - val_mae: 0.8437 - val_rmse: 1.0964\n",
            "Epoch 8/50\n",
            "\u001b[1m760/760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.8185 - mae: 0.6812 - rmse: 0.9046 - val_loss: 1.2177 - val_mae: 0.8422 - val_rmse: 1.1035\n",
            "\u001b[1m1737/1737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
            " 2번째 - MSE: 1.1906, RMSE: 1.0912, MAE: 0.8346, MAPE: 0.3519\n",
            "3번째\n",
            "\n",
            "Epoch 1/50\n",
            "\u001b[1m760/760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 2.2780 - mae: 1.1358 - rmse: 1.4583 - val_loss: 1.2526 - val_mae: 0.8886 - val_rmse: 1.1192\n",
            "Epoch 2/50\n",
            "\u001b[1m760/760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 1.1540 - mae: 0.8459 - rmse: 1.0742 - val_loss: 1.1652 - val_mae: 0.8444 - val_rmse: 1.0794\n",
            "Epoch 3/50\n",
            "\u001b[1m760/760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.9909 - mae: 0.7700 - rmse: 0.9954 - val_loss: 1.1694 - val_mae: 0.8269 - val_rmse: 1.0814\n",
            "Epoch 4/50\n",
            "\u001b[1m760/760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.9311 - mae: 0.7391 - rmse: 0.9649 - val_loss: 1.1889 - val_mae: 0.8234 - val_rmse: 1.0904\n",
            "Epoch 5/50\n",
            "\u001b[1m760/760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.8957 - mae: 0.7218 - rmse: 0.9464 - val_loss: 1.1728 - val_mae: 0.8364 - val_rmse: 1.0830\n",
            "Epoch 6/50\n",
            "\u001b[1m760/760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.8679 - mae: 0.7065 - rmse: 0.9316 - val_loss: 1.2011 - val_mae: 0.8232 - val_rmse: 1.0960\n",
            "Epoch 7/50\n",
            "\u001b[1m760/760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.8310 - mae: 0.6883 - rmse: 0.9116 - val_loss: 1.2037 - val_mae: 0.8343 - val_rmse: 1.0971\n",
            "\u001b[1m1737/1737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
            " 3번째 - MSE: 1.1750, RMSE: 1.0840, MAE: 0.8470, MAPE: 0.3498\n",
            "4번째\n",
            "\n",
            "Epoch 1/50\n",
            "\u001b[1m760/760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 2.0098 - mae: 1.0806 - rmse: 1.3834 - val_loss: 1.2627 - val_mae: 0.8987 - val_rmse: 1.1237\n",
            "Epoch 2/50\n",
            "\u001b[1m760/760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 1.1424 - mae: 0.8411 - rmse: 1.0688 - val_loss: 1.1766 - val_mae: 0.8436 - val_rmse: 1.0847\n",
            "Epoch 3/50\n",
            "\u001b[1m760/760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.9903 - mae: 0.7705 - rmse: 0.9951 - val_loss: 1.1731 - val_mae: 0.8464 - val_rmse: 1.0831\n",
            "Epoch 4/50\n",
            "\u001b[1m760/760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.9403 - mae: 0.7464 - rmse: 0.9697 - val_loss: 1.1703 - val_mae: 0.8356 - val_rmse: 1.0818\n",
            "Epoch 5/50\n",
            "\u001b[1m760/760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.9061 - mae: 0.7293 - rmse: 0.9519 - val_loss: 1.1935 - val_mae: 0.8565 - val_rmse: 1.0925\n",
            "Epoch 6/50\n",
            "\u001b[1m760/760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.8757 - mae: 0.7133 - rmse: 0.9357 - val_loss: 1.2084 - val_mae: 0.8548 - val_rmse: 1.0993\n",
            "Epoch 7/50\n",
            "\u001b[1m760/760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.8438 - mae: 0.6969 - rmse: 0.9186 - val_loss: 1.2030 - val_mae: 0.8278 - val_rmse: 1.0968\n",
            "Epoch 8/50\n",
            "\u001b[1m760/760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.8067 - mae: 0.6770 - rmse: 0.8981 - val_loss: 1.2157 - val_mae: 0.8325 - val_rmse: 1.1026\n",
            "Epoch 9/50\n",
            "\u001b[1m760/760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.7567 - mae: 0.6499 - rmse: 0.8698 - val_loss: 1.2595 - val_mae: 0.8353 - val_rmse: 1.1223\n",
            "\u001b[1m1737/1737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
            " 4번째 - MSE: 1.1849, RMSE: 1.0885, MAE: 0.8420, MAPE: 0.3400\n",
            "5번째\n",
            "\n",
            "Epoch 1/50\n",
            "\u001b[1m760/760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 2.5139 - mae: 1.1828 - rmse: 1.5227 - val_loss: 1.2992 - val_mae: 0.9018 - val_rmse: 1.1398\n",
            "Epoch 2/50\n",
            "\u001b[1m760/760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 1.1598 - mae: 0.8491 - rmse: 1.0769 - val_loss: 1.1887 - val_mae: 0.8597 - val_rmse: 1.0903\n",
            "Epoch 3/50\n",
            "\u001b[1m760/760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.9930 - mae: 0.7704 - rmse: 0.9965 - val_loss: 1.1898 - val_mae: 0.8435 - val_rmse: 1.0908\n",
            "Epoch 4/50\n",
            "\u001b[1m760/760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.9360 - mae: 0.7422 - rmse: 0.9674 - val_loss: 1.1879 - val_mae: 0.8437 - val_rmse: 1.0899\n",
            "Epoch 5/50\n",
            "\u001b[1m760/760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.8971 - mae: 0.7235 - rmse: 0.9471 - val_loss: 1.2099 - val_mae: 0.8512 - val_rmse: 1.1000\n",
            "Epoch 6/50\n",
            "\u001b[1m760/760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.8827 - mae: 0.7134 - rmse: 0.9395 - val_loss: 1.2109 - val_mae: 0.8289 - val_rmse: 1.1004\n",
            "Epoch 7/50\n",
            "\u001b[1m760/760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.8420 - mae: 0.6936 - rmse: 0.9176 - val_loss: 1.2313 - val_mae: 0.8313 - val_rmse: 1.1097\n",
            "\u001b[1m1737/1737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step\n",
            " 5번째 - MSE: 1.1768, RMSE: 1.0848, MAE: 0.8580, MAPE: 0.3499\n"
          ]
        }
      ],
      "source": [
        "all_rmse = []\n",
        "all_mae = []\n",
        "all_mape = []\n",
        "all_mse = []\n",
        "\n",
        "for i in range(5):\n",
        "    keras.backend.clear_session()\n",
        "    print(f\"{i+1}번째\\n\")\n",
        "\n",
        "    # 1. 데이터를 'random_state=i'로 분할 (매번 다른 분할)\n",
        "    train_val_df, test_df = train_test_split(df_processed, test_size=0.2, random_state=42 + i)\n",
        "    val_size_ratio = 1 / 8\n",
        "    train_df, val_df = train_test_split(train_val_df, test_size=val_size_ratio, random_state=42 + i)\n",
        "\n",
        "    user_encoder = LabelEncoder()\n",
        "    business_encoder = LabelEncoder()\n",
        "    train_df.loc[:, 'user_encoded'] = user_encoder.fit_transform(train_df['user_id'])\n",
        "    train_df.loc[:, 'business_encoded'] = business_encoder.fit_transform(train_df['business_id'])\n",
        "\n",
        "    user_mapping = {label: i for i, label in enumerate(user_encoder.classes_)}\n",
        "    business_mapping = {label: i for i, label in enumerate(business_encoder.classes_)}\n",
        "    val_df.loc[:, 'user_encoded'] = val_df['user_id'].map(user_mapping).fillna(-1).astype(int)\n",
        "    test_df.loc[:, 'user_encoded'] = test_df['user_id'].map(user_mapping).fillna(-1).astype(int)\n",
        "    val_df.loc[:, 'business_encoded'] = val_df['business_id'].map(business_mapping).fillna(-1).astype(int)\n",
        "    test_df.loc[:, 'business_encoded'] = test_df['business_id'].map(business_mapping).fillna(-1).astype(int)\n",
        "\n",
        "    num_users = len(user_encoder.classes_)\n",
        "    num_businesses = len(business_encoder.classes_)\n",
        "\n",
        "    train_embeddings = np.vstack(train_df['embedding'].values)\n",
        "    val_embeddings = np.vstack(val_df['embedding'].values)\n",
        "    test_embeddings = np.vstack(test_df['embedding'].values)\n",
        "\n",
        "    # BERT 임베딩 차원은 768로 고정\n",
        "    bert_embedding_dim = 768\n",
        "\n",
        "    # 모델 빌드 함수와 파라미터 업데이트\n",
        "    final_model = build_hybrid_bert_model(\n",
        "        num_users, num_businesses,\n",
        "        best_params['user_embedding_dim'], best_params['business_embedding_dim'],\n",
        "        bert_embedding_dim,\n",
        "        best_params['user_biz_mlp_dims'], best_params['bert_mlp_dims'],\n",
        "        best_params['final_mlp_dims'])\n",
        "\n",
        "    final_model.compile(optimizer=keras.optimizers.Adam(learning_rate=best_params['learning_rate']),\n",
        "                        loss='mse',\n",
        "                        metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse'), 'mae'])\n",
        "\n",
        "    early_stopping_callback = callbacks.EarlyStopping(\n",
        "        monitor='val_rmse',\n",
        "        patience=5,\n",
        "        min_delta=0.0005,\n",
        "        mode='min',\n",
        "        restore_best_weights=True)\n",
        "\n",
        "    # 모델 저장 경로 업데이트\n",
        "    model_save_path = f'final_best_hybrid_bert_model_fold_{i+1}.keras'\n",
        "    model_checkpoint_callback = callbacks.ModelCheckpoint(\n",
        "        filepath=model_save_path,\n",
        "        monitor='val_rmse',\n",
        "        save_best_only=True,\n",
        "        mode='min',\n",
        "        verbose=0)\n",
        "\n",
        "    # 모델 학습 데이터셋 입력 이름 업데이트\n",
        "    history = final_model.fit(\n",
        "        {'user_id': train_df['user_encoded'],\n",
        "         'business_id': train_df['business_encoded'],\n",
        "         'bert_embedding': train_embeddings},\n",
        "        train_df['stars'],\n",
        "        batch_size=best_params['batch_size'],\n",
        "        epochs=50,\n",
        "        validation_data=(\n",
        "            {'user_id': val_df['user_encoded'],\n",
        "             'business_id': val_df['business_encoded'],\n",
        "             'bert_embedding': val_embeddings},\n",
        "            val_df['stars']\n",
        "        ),\n",
        "        callbacks=[early_stopping_callback, model_checkpoint_callback],\n",
        "        verbose=1)\n",
        "\n",
        "    # 테스트셋 예측 입력 이름 업데이트\n",
        "    test_predictions = final_model.predict(\n",
        "        {'user_id': test_df['user_encoded'],\n",
        "         'business_id': test_df['business_encoded'],\n",
        "         'bert_embedding': test_embeddings}\n",
        "    ).flatten()\n",
        "\n",
        "    true_ratings = test_df['stars'].values\n",
        "\n",
        "    # 평가 지표 계산\n",
        "    mse = mean_squared_error(true_ratings, test_predictions)\n",
        "    rmse = np.sqrt(mse)\n",
        "    mae = mean_absolute_error(true_ratings, test_predictions)\n",
        "\n",
        "    # MAPE 계산은 NaN 또는 inf가 나올 수 있으므로, 0으로 나누기 오류를 방지합니다.\n",
        "    try:\n",
        "        mape = mean_absolute_percentage_error(true_ratings, test_predictions)\n",
        "    except (ValueError, ZeroDivisionError):\n",
        "        mape = np.nan\n",
        "\n",
        "    all_mse.append(mse)\n",
        "    all_rmse.append(rmse)\n",
        "    all_mae.append(mae)\n",
        "    all_mape.append(mape)\n",
        "\n",
        "    print(f\" {i+1}번째 - MSE: {mse:.4f}, RMSE: {rmse:.4f}, MAE: {mae:.4f}, MAPE: {mape:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7f8af5c-96f6-49aa-ae96-a965ec8a5ddd",
      "metadata": {
        "id": "e7f8af5c-96f6-49aa-ae96-a965ec8a5ddd"
      },
      "source": [
        "최종 결과"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "fee70fba-a0af-400a-982c-babd86e2c266",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fee70fba-a0af-400a-982c-babd86e2c266",
        "outputId": "2bab9829-7936-4e19-b690-bcc2971a72f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5회 실험 최종 결과 요약\n",
            "\n",
            "평균 MSE: 1.1799\n",
            "MSE 표준편차: 0.00679\n",
            "평균 RMSE: 1.0862\n",
            "RMSE 표준편차: 0.00312\n",
            "평균 MAE: 0.8451\n",
            "MAE 표준편차: 0.00762\n",
            "평균 MAPE: 0.3466\n",
            "MAPE 표준편차: 0.00484\n"
          ]
        }
      ],
      "source": [
        "print(\"5회 실험 최종 결과 요약\\n\")\n",
        "\n",
        "mean_rmse = np.mean(all_rmse)\n",
        "std_rmse = np.std(all_rmse)\n",
        "mean_mae = np.mean(all_mae)\n",
        "std_mae = np.std(all_mae)\n",
        "mean_mape = np.mean(all_mape)\n",
        "std_mape = np.std(all_mape)\n",
        "all_mse = [x**2 for x in all_rmse]\n",
        "mean_mse = np.mean(all_mse)\n",
        "std_mse = np.std(all_mse)\n",
        "\n",
        "print(f\"평균 MSE: {mean_mse:.4f}\")\n",
        "print(f\"MSE 표준편차: {std_mse:.5f}\")\n",
        "\n",
        "print(f\"평균 RMSE: {mean_rmse:.4f}\")\n",
        "print(f\"RMSE 표준편차: {std_rmse:.5f}\")\n",
        "\n",
        "print(f\"평균 MAE: {mean_mae:.4f}\")\n",
        "print(f\"MAE 표준편차: {std_mae:.5f}\")\n",
        "\n",
        "print(f\"평균 MAPE: {mean_mape:.4f}\")\n",
        "print(f\"MAPE 표준편차: {std_mape:.5f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2199a2a4-646e-4b7c-95a6-ee5c14265ad8",
      "metadata": {
        "id": "2199a2a4-646e-4b7c-95a6-ee5c14265ad8"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}