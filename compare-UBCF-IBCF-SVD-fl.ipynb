{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea65edb6-2fe1-455c-950d-a4c48985b714",
   "metadata": {},
   "source": [
    "전처리 dataset_la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81505feb-8b23-4411-9c31-4f04d1021822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 데이터 로딩 완료. 전체 데이터 수: 500892\n",
      "✅ Surprise Dataset 객체 생성 완료.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from surprise import Reader, Dataset, KNNBasic, SVD, accuracy\n",
    "from surprise.model_selection import KFold, GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# -------------------- 1. 평가 지표 함수 정의 --------------------\n",
    "def calculate_metrics(true_ratings, predicted_ratings):\n",
    "    \"\"\"\n",
    "    평가 지표 (RMSE, MAE)를 계산하는 함수.\n",
    "    \"\"\"\n",
    "    true_ratings = np.array(true_ratings)\n",
    "    predicted_ratings = np.array(predicted_ratings)\n",
    "    \n",
    "    # MSE를 직접 계산하여 RMSE를 구합니다.\n",
    "    rmse = np.sqrt(mean_squared_error(true_ratings, predicted_ratings))\n",
    "    mae = mean_absolute_error(true_ratings, predicted_ratings)\n",
    "    \n",
    "    return rmse, mae\n",
    "\n",
    "# -------------------- 2. 데이터 로딩 및 Surprise용 데이터셋 준비 --------------------\n",
    "# 파일 로드\n",
    "df = pd.read_parquet('review_data_optimized_fl.parquet')\n",
    "\n",
    "# 필요한 컬럼 추출\n",
    "df_processed = df[['user_id', 'business_id', 'review_stars']].copy()\n",
    "\n",
    "print(f\"✅ 데이터 로딩 완료. 전체 데이터 수: {len(df_processed)}\")\n",
    "\n",
    "# Surprise 라이브러리를 위한 데이터셋 준비\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(df_processed, reader)\n",
    "\n",
    "print(f\"✅ Surprise Dataset 객체 생성 완료.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74122a5-37a5-477b-80c0-c9f448c40e9a",
   "metadata": {},
   "source": [
    "UBCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1a22a76-55c0-4381-a6c3-e997fbe0de41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ k 값을 100로 고정하여 UBCF 평가를 진행합니다.\n",
      "\n",
      "--- UBCF 모델 5회 반복 학습 및 평가 시작 ---\n",
      "\n",
      "[1/5] Iteration with random_state = 42\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "  > Test Set Performance (k=100): RMSE = 1.2693, MAE = 0.9929\n",
      "\n",
      "[2/5] Iteration with random_state = 43\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "  > Test Set Performance (k=100): RMSE = 1.2640, MAE = 0.9907\n",
      "\n",
      "[3/5] Iteration with random_state = 44\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "  > Test Set Performance (k=100): RMSE = 1.2658, MAE = 0.9895\n",
      "\n",
      "[4/5] Iteration with random_state = 45\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "  > Test Set Performance (k=100): RMSE = 1.2666, MAE = 0.9908\n",
      "\n",
      "[5/5] Iteration with random_state = 46\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "  > Test Set Performance (k=100): RMSE = 1.2692, MAE = 0.9923\n",
      "\n",
      "==================================================\n",
      "--- 최종 UBCF 모델 성능 (5회 반복) ---\n",
      "평균 RMSE: 1.2670 (표준편차: 0.0020)\n",
      "평균 MAE: 0.9913 (표준편차: 0.0012)\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# --- 2. UBCF (User-Based Collaborative Filtering) 모델 ---\n",
    "\n",
    "# k 값을 100으로 고정\n",
    "best_k_ubcf = 100\n",
    "print(f\"✅ k 값을 {best_k_ubcf}로 고정하여 UBCF 평가를 진행합니다.\")\n",
    "\n",
    "# 반복 횟수 및 초기 random_state 설정\n",
    "n_iterations = 5\n",
    "start_random_state = 42\n",
    "\n",
    "# 결과를 저장할 리스트\n",
    "test_rmse_scores_ubcf = []\n",
    "test_mae_scores_ubcf = []\n",
    "\n",
    "print(\"\\n--- UBCF 모델 5회 반복 학습 및 평가 시작 ---\")\n",
    "\n",
    "for i in range(n_iterations):\n",
    "    current_random_state = start_random_state + i\n",
    "    print(f\"\\n[{i+1}/{n_iterations}] Iteration with random_state = {current_random_state}\")\n",
    "\n",
    "    # 매 반복마다 새로운 데이터 분할\n",
    "    train_val_df, test_df = train_test_split(df_processed, test_size=0.2, random_state=current_random_state)\n",
    "    val_size_ratio = 1/8\n",
    "    train_df, val_df = train_test_split(train_val_df, test_size=val_size_ratio, random_state=current_random_state)\n",
    "    \n",
    "    # Surprise 라이브러리용 데이터셋으로 변환\n",
    "    reader = Reader(rating_scale=(1, 5))\n",
    "    train_set_for_surprise = train_df[['user_id', 'business_id', 'review_stars']]\n",
    "    data_for_train = Dataset.load_from_df(train_set_for_surprise, reader)\n",
    "    train_set = data_for_train.build_full_trainset()\n",
    "    test_set = [(row['user_id'], row['business_id'], row['review_stars']) for _, row in test_df.iterrows()]\n",
    "    \n",
    "    # 고정된 k 값으로 UBCF 모델 학습 및 평가\n",
    "    ubcf_model = KNNBasic(sim_options={'name': 'cosine', 'user_based': True}, k=best_k_ubcf)\n",
    "    ubcf_model.fit(train_set)\n",
    "    predictions_ubcf = ubcf_model.test(test_set)\n",
    "    \n",
    "    # 성능 지표 계산\n",
    "    true_ratings_ubcf = [pred.r_ui for pred in predictions_ubcf]\n",
    "    predicted_ratings_ubcf = [pred.est for pred in predictions_ubcf]\n",
    "    rmse, mae = calculate_metrics(true_ratings_ubcf, predicted_ratings_ubcf)\n",
    "    \n",
    "    test_rmse_scores_ubcf.append(rmse)\n",
    "    test_mae_scores_ubcf.append(mae)\n",
    "    \n",
    "    print(f\"  > Test Set Performance (k={best_k_ubcf}): RMSE = {rmse:.4f}, MAE = {mae:.4f}\")\n",
    "\n",
    "# 결과 평균 및 표준편차 계산\n",
    "mean_rmse_ubcf = np.mean(test_rmse_scores_ubcf)\n",
    "std_rmse_ubcf = np.std(test_rmse_scores_ubcf)\n",
    "mean_mae_ubcf = np.mean(test_mae_scores_ubcf)\n",
    "std_mae_ubcf = np.std(test_mae_scores_ubcf)\n",
    "\n",
    "# 최종 결과 출력\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"--- 최종 UBCF 모델 성능 (5회 반복) ---\")\n",
    "print(f\"평균 RMSE: {mean_rmse_ubcf:.4f} (표준편차: {std_rmse_ubcf:.4f})\")\n",
    "print(f\"평균 MAE: {mean_mae_ubcf:.4f} (표준편차: {std_mae_ubcf:.4f})\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b04eb0-ee3f-43fc-b32d-29fba1b3b39f",
   "metadata": {},
   "source": [
    "IBCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2aff416-200d-4aec-9ae5-ff62f7f49b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ k 값을 100로 고정하여 IBCF 평가를 진행합니다.\n",
      "\n",
      "--- IBCF 모델 5회 반복 학습 및 평가 시작 ---\n",
      "\n",
      "[1/5] Iteration with random_state = 42\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "  > Test Set Performance (k=100): RMSE = 1.2936, MAE = 0.9651\n",
      "\n",
      "[2/5] Iteration with random_state = 43\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "  > Test Set Performance (k=100): RMSE = 1.2957, MAE = 0.9671\n",
      "\n",
      "[3/5] Iteration with random_state = 44\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "  > Test Set Performance (k=100): RMSE = 1.2930, MAE = 0.9631\n",
      "\n",
      "[4/5] Iteration with random_state = 45\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "  > Test Set Performance (k=100): RMSE = 1.2954, MAE = 0.9660\n",
      "\n",
      "[5/5] Iteration with random_state = 46\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "  > Test Set Performance (k=100): RMSE = 1.2979, MAE = 0.9685\n",
      "\n",
      "==================================================\n",
      "--- 최종 IBCF 모델 성능 (5회 반복) ---\n",
      "평균 RMSE: 1.2951 (표준편차: 0.0017)\n",
      "평균 MAE: 0.9659 (표준편차: 0.0018)\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# --- 3. IBCF (Item-Based Collaborative Filtering) 모델 ---\n",
    "\n",
    "# k 값을 100으로 고정\n",
    "best_k_ibcf = 100\n",
    "print(f\"✅ k 값을 {best_k_ibcf}로 고정하여 IBCF 평가를 진행합니다.\")\n",
    "\n",
    "# 반복 횟수 및 초기 random_state 설정\n",
    "n_iterations = 5\n",
    "start_random_state = 42\n",
    "\n",
    "# 결과를 저장할 리스트\n",
    "test_rmse_scores_ibcf = []\n",
    "test_mae_scores_ibcf = []\n",
    "\n",
    "print(\"\\n--- IBCF 모델 5회 반복 학습 및 평가 시작 ---\")\n",
    "\n",
    "for i in range(n_iterations):\n",
    "    current_random_state = start_random_state + i\n",
    "    print(f\"\\n[{i+1}/{n_iterations}] Iteration with random_state = {current_random_state}\")\n",
    "\n",
    "    # 매 반복마다 새로운 데이터 분할\n",
    "    train_val_df, test_df = train_test_split(df_processed, test_size=0.2, random_state=current_random_state)\n",
    "    val_size_ratio = 1/8\n",
    "    train_df, val_df = train_test_split(train_val_df, test_size=val_size_ratio, random_state=current_random_state)\n",
    "    \n",
    "    # Surprise 라이브러리용 데이터셋으로 변환\n",
    "    reader = Reader(rating_scale=(1, 5))\n",
    "    train_set_for_surprise = train_df[['user_id', 'business_id', 'review_stars']]\n",
    "    data_for_train = Dataset.load_from_df(train_set_for_surprise, reader)\n",
    "    train_set = data_for_train.build_full_trainset()\n",
    "    test_set = [(row['user_id'], row['business_id'], row['review_stars']) for _, row in test_df.iterrows()]\n",
    "    \n",
    "    # 고정된 k 값으로 IBCF 모델 학습 및 평가\n",
    "    ibcf_model = KNNBasic(sim_options={'name': 'cosine', 'user_based': False}, k=best_k_ibcf)\n",
    "    ibcf_model.fit(train_set)\n",
    "    predictions_ibcf = ibcf_model.test(test_set)\n",
    "    \n",
    "    # 성능 지표 계산\n",
    "    true_ratings_ibcf = [pred.r_ui for pred in predictions_ibcf]\n",
    "    predicted_ratings_ibcf = [pred.est for pred in predictions_ibcf]\n",
    "    rmse, mae = calculate_metrics(true_ratings_ibcf, predicted_ratings_ibcf)\n",
    "    \n",
    "    test_rmse_scores_ibcf.append(rmse)\n",
    "    test_mae_scores_ibcf.append(mae)\n",
    "    \n",
    "    print(f\"  > Test Set Performance (k={best_k_ibcf}): RMSE = {rmse:.4f}, MAE = {mae:.4f}\")\n",
    "\n",
    "# 결과 평균 및 표준편차 계산\n",
    "mean_rmse_ibcf = np.mean(test_rmse_scores_ibcf)\n",
    "std_rmse_ibcf = np.std(test_rmse_scores_ibcf)\n",
    "mean_mae_ibcf = np.mean(test_mae_scores_ibcf)\n",
    "std_mae_ibcf = np.std(test_mae_scores_ibcf)\n",
    "\n",
    "# 최종 결과 출력\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"--- 최종 IBCF 모델 성능 (5회 반복) ---\")\n",
    "print(f\"평균 RMSE: {mean_rmse_ibcf:.4f} (표준편차: {std_rmse_ibcf:.4f})\")\n",
    "print(f\"평균 MAE: {mean_mae_ibcf:.4f} (표준편차: {std_mae_ibcf:.4f})\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337c0448-f18d-4557-9a2c-905196f67623",
   "metadata": {},
   "source": [
    "SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49f917b4-b117-4535-b51c-bae0b88f5d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [1단계] SVD 하이퍼파라미터 튜닝 시작 ---\n",
      "\n",
      "✅ 최적 SVD 파라미터: {'n_factors': 1, 'n_epochs': 30, 'lr_all': 0.005, 'reg_all': 0.05}\n",
      "최적 파라미터의 교차 검증 RMSE: 1.1414\n",
      "\n",
      "--- [2단계] 최적 SVD 모델 5회 반복 학습 및 평가 시작 ---\n",
      "\n",
      "[1/5] Iteration with random_state = 42\n",
      "  > Test Set Performance: RMSE = 1.1374, MAE = 0.8889\n",
      "\n",
      "[2/5] Iteration with random_state = 43\n",
      "  > Test Set Performance: RMSE = 1.1356, MAE = 0.8884\n",
      "\n",
      "[3/5] Iteration with random_state = 44\n",
      "  > Test Set Performance: RMSE = 1.1389, MAE = 0.8892\n",
      "\n",
      "[4/5] Iteration with random_state = 45\n",
      "  > Test Set Performance: RMSE = 1.1367, MAE = 0.8883\n",
      "\n",
      "[5/5] Iteration with random_state = 46\n",
      "  > Test Set Performance: RMSE = 1.1401, MAE = 0.8911\n",
      "\n",
      "==================================================\n",
      "--- 최종 SVD 모델 성능 (5회 반복) ---\n",
      "평균 RMSE: 1.1377 (표준편차: 0.0016)\n",
      "평균 MAE: 0.8892 (표준편차: 0.0010)\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# --- 4. SVD (Singular Value Decomposition) 모델 ---\n",
    "\n",
    "# 1. GridSearchCV로 최적의 하이퍼파라미터를 찾습니다.\n",
    "print(\"--- [1단계] SVD 하이퍼파라미터 튜닝 시작 ---\")\n",
    "param_grid_svd = {\n",
    "    'n_factors': [1, 30, 50, 100],\n",
    "    'n_epochs': [20, 30],\n",
    "    'lr_all': [0.005, 0.007],\n",
    "    'reg_all': [0.02, 0.05]\n",
    "}\n",
    "\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "full_data_for_tuning = Dataset.load_from_df(df_processed, reader)\n",
    "gs = GridSearchCV(SVD, param_grid_svd, measures=['rmse'], cv=3, n_jobs=-1)\n",
    "gs.fit(full_data_for_tuning)\n",
    "\n",
    "best_params_svd = gs.best_params['rmse']\n",
    "print(f\"\\n✅ 최적 SVD 파라미터: {best_params_svd}\")\n",
    "print(f\"최적 파라미터의 교차 검증 RMSE: {gs.best_score['rmse']:.4f}\")\n",
    "\n",
    "# 2. 찾은 최적 파라미터로 5회 반복 최종 평가\n",
    "print(\"\\n--- [2단계] 최적 SVD 모델 5회 반복 학습 및 평가 시작 ---\")\n",
    "n_iterations = 5\n",
    "start_random_state = 42\n",
    "\n",
    "test_rmse_scores_svd = []\n",
    "test_mae_scores_svd = []\n",
    "\n",
    "for i in range(n_iterations):\n",
    "    current_random_state = start_random_state + i\n",
    "    print(f\"\\n[{i+1}/{n_iterations}] Iteration with random_state = {current_random_state}\")\n",
    "\n",
    "    train_val_df, test_df = train_test_split(df_processed, test_size=0.2, random_state=current_random_state)\n",
    "    val_size_ratio = 1/8\n",
    "    train_df, val_df = train_test_split(train_val_df, test_size=val_size_ratio, random_state=current_random_state)\n",
    "    \n",
    "    reader = Reader(rating_scale=(1, 5))\n",
    "    train_set_for_surprise = train_df[['user_id', 'business_id', 'review_stars']]\n",
    "    data_for_train = Dataset.load_from_df(train_set_for_surprise, reader)\n",
    "    train_set = data_for_train.build_full_trainset()\n",
    "    test_set = [(row['user_id'], row['business_id'], row['review_stars']) for _, row in test_df.iterrows()]\n",
    "    \n",
    "    svd_model = SVD(n_factors=best_params_svd['n_factors'],\n",
    "                    n_epochs=best_params_svd['n_epochs'],\n",
    "                    lr_all=best_params_svd['lr_all'],\n",
    "                    reg_all=best_params_svd['reg_all'])\n",
    "    svd_model.fit(train_set)\n",
    "    predictions_svd = svd_model.test(test_set)\n",
    "\n",
    "    true_ratings_svd = [pred.r_ui for pred in predictions_svd]\n",
    "    predicted_ratings_svd = [pred.est for pred in predictions_svd]\n",
    "    rmse, mae = calculate_metrics(true_ratings_svd, predicted_ratings_svd)\n",
    "    \n",
    "    test_rmse_scores_svd.append(rmse)\n",
    "    test_mae_scores_svd.append(mae)\n",
    "    \n",
    "    print(f\"  > Test Set Performance: RMSE = {rmse:.4f}, MAE = {mae:.4f}\")\n",
    "\n",
    "mean_rmse_svd = np.mean(test_rmse_scores_svd)\n",
    "std_rmse_svd = np.std(test_rmse_scores_svd)\n",
    "mean_mae_svd = np.mean(test_mae_scores_svd)\n",
    "std_mae_svd = np.std(test_mae_scores_svd)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"--- 최종 SVD 모델 성능 (5회 반복) ---\")\n",
    "print(f\"평균 RMSE: {mean_rmse_svd:.4f} (표준편차: {std_rmse_svd:.4f})\")\n",
    "print(f\"평균 MAE: {mean_mae_svd:.4f} (표준편차: {std_mae_svd:.4f})\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0271191-8deb-49d4-9bfd-ed2ca499ca3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
