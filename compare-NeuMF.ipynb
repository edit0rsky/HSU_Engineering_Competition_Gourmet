{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cbafdf3-c8d6-45fb-8c27-2b00cc3c3a03",
   "metadata": {},
   "source": [
    "dataset_fl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8eb599de-8bef-4085-868a-642d5bd65dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "✅ 데이터 로딩 및 전처리 완료. 사용자 수: 33779, 비즈니스 수: 9422\n",
      "\n",
      "--- 1단계: 하이퍼파라미터 랜덤 서치 (10회) 시작 ---\n",
      "\n",
      "--- 시도 1/10 ---\n",
      "--- 실행 search_1 시작, 파라미터: {'mf_dim': 64, 'mlp_dims': [256, 128, 64], 'learning_rate': 0.001, 'batch_size': 512}\n",
      "조기 종료 발생. (실행 search_1)\n",
      "    --> 시도 1 검증 RMSE: 1.1971\n",
      "    --> 새로운 최적 RMSE 발견: 1.1971 (파라미터: {'mf_dim': 64, 'mlp_dims': [256, 128, 64], 'learning_rate': 0.001, 'batch_size': 512})\n",
      "\n",
      "--- 시도 2/10 ---\n",
      "--- 실행 search_2 시작, 파라미터: {'mf_dim': 16, 'mlp_dims': [256, 128, 64], 'learning_rate': 0.0005, 'batch_size': 512}\n",
      "조기 종료 발생. (실행 search_2)\n",
      "    --> 시도 2 검증 RMSE: 1.1982\n",
      "\n",
      "--- 시도 3/10 ---\n",
      "--- 실행 search_3 시작, 파라미터: {'mf_dim': 32, 'mlp_dims': [128, 64, 32], 'learning_rate': 0.001, 'batch_size': 512}\n",
      "조기 종료 발생. (실행 search_3)\n",
      "    --> 시도 3 검증 RMSE: 1.1965\n",
      "    --> 새로운 최적 RMSE 발견: 1.1965 (파라미터: {'mf_dim': 32, 'mlp_dims': [128, 64, 32], 'learning_rate': 0.001, 'batch_size': 512})\n",
      "\n",
      "--- 시도 4/10 ---\n",
      "--- 실행 search_4 시작, 파라미터: {'mf_dim': 32, 'mlp_dims': [64, 32, 16], 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "조기 종료 발생. (실행 search_4)\n",
      "    --> 시도 4 검증 RMSE: 1.2184\n",
      "\n",
      "--- 시도 5/10 ---\n",
      "--- 실행 search_5 시작, 파라미터: {'mf_dim': 32, 'mlp_dims': [128, 64, 32], 'learning_rate': 0.002, 'batch_size': 128}\n",
      "조기 종료 발생. (실행 search_5)\n",
      "    --> 시도 5 검증 RMSE: 1.1839\n",
      "    --> 새로운 최적 RMSE 발견: 1.1839 (파라미터: {'mf_dim': 32, 'mlp_dims': [128, 64, 32], 'learning_rate': 0.002, 'batch_size': 128})\n",
      "\n",
      "--- 시도 6/10 ---\n",
      "--- 실행 search_6 시작, 파라미터: {'mf_dim': 32, 'mlp_dims': [256, 128, 64], 'learning_rate': 0.001, 'batch_size': 128}\n",
      "조기 종료 발생. (실행 search_6)\n",
      "    --> 시도 6 검증 RMSE: 1.1977\n",
      "\n",
      "--- 시도 7/10 ---\n",
      "--- 실행 search_7 시작, 파라미터: {'mf_dim': 32, 'mlp_dims': [64, 32, 16], 'learning_rate': 0.002, 'batch_size': 512}\n",
      "조기 종료 발생. (실행 search_7)\n",
      "    --> 시도 7 검증 RMSE: 1.1980\n",
      "\n",
      "--- 시도 8/10 ---\n",
      "--- 실행 search_8 시작, 파라미터: {'mf_dim': 32, 'mlp_dims': [64, 32, 16], 'learning_rate': 0.002, 'batch_size': 128}\n",
      "조기 종료 발생. (실행 search_8)\n",
      "    --> 시도 8 검증 RMSE: 1.1858\n",
      "\n",
      "--- 시도 9/10 ---\n",
      "--- 실행 search_9 시작, 파라미터: {'mf_dim': 64, 'mlp_dims': [256, 128, 64], 'learning_rate': 0.001, 'batch_size': 128}\n",
      "조기 종료 발생. (실행 search_9)\n",
      "    --> 시도 9 검증 RMSE: 1.1953\n",
      "\n",
      "--- 시도 10/10 ---\n",
      "--- 실행 search_10 시작, 파라미터: {'mf_dim': 32, 'mlp_dims': [256, 128, 64], 'learning_rate': 0.002, 'batch_size': 128}\n",
      "조기 종료 발생. (실행 search_10)\n",
      "    --> 시도 10 검증 RMSE: 1.1848\n",
      "\n",
      "✅ 1단계 완료. 최적 파라미터: {'mf_dim': 32, 'mlp_dims': [128, 64, 32], 'learning_rate': 0.002, 'batch_size': 128}\n",
      "\n",
      "--- 2단계: 최적 파라미터로 5회 반복 평가 시작 ---\n",
      "--- 실행 final_1 시작, 파라미터: {'mf_dim': 32, 'mlp_dims': [128, 64, 32], 'learning_rate': 0.002, 'batch_size': 128}\n",
      "조기 종료 발생. (실행 final_1)\n",
      "\n",
      "✅ [NeuMF] 1번째 테스트 결과: RMSE=1.1867, MAE=0.9324\n",
      "--- 실행 final_2 시작, 파라미터: {'mf_dim': 32, 'mlp_dims': [128, 64, 32], 'learning_rate': 0.002, 'batch_size': 128}\n",
      "조기 종료 발생. (실행 final_2)\n",
      "\n",
      "✅ [NeuMF] 2번째 테스트 결과: RMSE=1.1886, MAE=0.9289\n",
      "--- 실행 final_3 시작, 파라미터: {'mf_dim': 32, 'mlp_dims': [128, 64, 32], 'learning_rate': 0.002, 'batch_size': 128}\n",
      "조기 종료 발생. (실행 final_3)\n",
      "\n",
      "✅ [NeuMF] 3번째 테스트 결과: RMSE=1.1898, MAE=0.9489\n",
      "--- 실행 final_4 시작, 파라미터: {'mf_dim': 32, 'mlp_dims': [128, 64, 32], 'learning_rate': 0.002, 'batch_size': 128}\n",
      "조기 종료 발생. (실행 final_4)\n",
      "\n",
      "✅ [NeuMF] 4번째 테스트 결과: RMSE=1.1882, MAE=0.9393\n",
      "--- 실행 final_5 시작, 파라미터: {'mf_dim': 32, 'mlp_dims': [128, 64, 32], 'learning_rate': 0.002, 'batch_size': 128}\n",
      "조기 종료 발생. (실행 final_5)\n",
      "\n",
      "✅ [NeuMF] 5번째 테스트 결과: RMSE=1.1885, MAE=0.9454\n",
      "\n",
      "\n",
      "==================== 최종 5회 반복 평균 결과 ====================\n",
      " - 평균 RMSE : 1.1883 +/- 0.0010\n",
      " - 평균 MAE  : 0.9390 +/- 0.0076\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import random\n",
    "import json\n",
    "\n",
    "# --- 장치 설정 (GPU 사용 가능 시) ---\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# -------------------- 데이터 로딩 및 전처리 --------------------\n",
    "# 'dataset_fl.json' 파일을 읽어옵니다.\n",
    "try:\n",
    "    df = pd.read_json('dataset_fl.json', lines=True)\n",
    "except ValueError:\n",
    "    print(\"Trying to read JSON without lines=True (assuming a single JSON object or array of objects).\")\n",
    "    df = pd.read_json('dataset_fl.json')\n",
    "\n",
    "df_processed = df[['user_id', 'business_id', 'review_stars']].copy()\n",
    "\n",
    "# Label Encoding을 사용하여 user_id와 business_id를 정수형으로 변환합니다.\n",
    "user_encoder = LabelEncoder()\n",
    "business_encoder = LabelEncoder()\n",
    "df_processed['user_encoded'] = user_encoder.fit_transform(df_processed['user_id'])\n",
    "df_processed['business_encoded'] = business_encoder.fit_transform(df_processed['business_id'])\n",
    "\n",
    "num_users = len(user_encoder.classes_)\n",
    "num_businesses = len(business_encoder.classes_)\n",
    "print(f\"✅ 데이터 로딩 및 전처리 완료. 사용자 수: {num_users}, 비즈니스 수: {num_businesses}\")\n",
    "\n",
    "# -------------------- Dataset 정의 --------------------\n",
    "class NeuMFDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.user_ids = torch.tensor(df['user_encoded'].values, dtype=torch.long)\n",
    "        self.item_ids = torch.tensor(df['business_encoded'].values, dtype=torch.long)\n",
    "        self.ratings = torch.tensor(df['review_stars'].values, dtype=torch.float)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ratings)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.user_ids[idx], self.item_ids[idx], self.ratings[idx]\n",
    "\n",
    "# -------------------- 모델 정의 --------------------\n",
    "class NeuMF(nn.Module):\n",
    "    def __init__(self, num_users, num_items, mf_dim, mlp_dims):\n",
    "        super(NeuMF, self).__init__()\n",
    "        self.user_embedding_gmf = nn.Embedding(num_users, mf_dim)\n",
    "        self.item_embedding_gmf = nn.Embedding(num_items, mf_dim)\n",
    "        \n",
    "        self.user_embedding_mlp = nn.Embedding(num_users, mlp_dims[0] // 2)\n",
    "        self.item_embedding_mlp = nn.Embedding(num_items, mlp_dims[0] // 2)\n",
    "\n",
    "        mlp_layers = []\n",
    "        input_dim = mlp_dims[0]\n",
    "        for dim in mlp_dims[1:]:\n",
    "            mlp_layers.append(nn.Linear(input_dim, dim))\n",
    "            mlp_layers.append(nn.ReLU())\n",
    "            input_dim = dim\n",
    "        self.mlp = nn.Sequential(*mlp_layers)\n",
    "\n",
    "        self.final_layer = nn.Linear(mf_dim + mlp_dims[-1], 1)\n",
    "\n",
    "    def forward(self, user_ids, item_ids):\n",
    "        gmf_user = self.user_embedding_gmf(user_ids)\n",
    "        gmf_item = self.item_embedding_gmf(item_ids)\n",
    "        gmf_output = gmf_user * gmf_item\n",
    "\n",
    "        mlp_user = self.user_embedding_mlp(user_ids)\n",
    "        mlp_item = self.item_embedding_mlp(item_ids)\n",
    "        mlp_input = torch.cat((mlp_user, mlp_item), dim=1)\n",
    "        mlp_output = self.mlp(mlp_input)\n",
    "\n",
    "        concat = torch.cat((gmf_output, mlp_output), dim=1)\n",
    "        prediction = self.final_layer(concat)\n",
    "        return prediction.view(-1)\n",
    "\n",
    "# -------------------- 평가 지표 함수 정의 --------------------\n",
    "def evaluate_model(model, data_loader, device):\n",
    "    model.eval()\n",
    "    preds, targets = [], []\n",
    "    with torch.no_grad():\n",
    "        for user_ids, item_ids, ratings in data_loader:\n",
    "            user_ids, item_ids, ratings = user_ids.to(device), item_ids.to(device), ratings.to(device)\n",
    "            output = model(user_ids, item_ids)\n",
    "            preds.extend(output.cpu().numpy())\n",
    "            targets.extend(ratings.cpu().numpy())\n",
    "    \n",
    "    preds = np.array(preds)\n",
    "    targets = np.array(targets)\n",
    "    \n",
    "    mae = mean_absolute_error(targets, preds)\n",
    "    rmse = np.sqrt(mean_squared_error(targets, preds))\n",
    "    \n",
    "    return mae, rmse\n",
    "\n",
    "# -------------------- 학습 및 평가 함수 (단일 실행) --------------------\n",
    "def train_and_evaluate_run(params, train_df, val_df, test_df, run_num):\n",
    "    print(f\"--- 실행 {run_num} 시작, 파라미터: {params}\")\n",
    "\n",
    "    train_dataset = NeuMFDataset(train_df)\n",
    "    val_dataset = NeuMFDataset(val_df)\n",
    "    test_dataset = NeuMFDataset(test_df)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=params['batch_size'], shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=params['batch_size'], shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=params['batch_size'], shuffle=False)\n",
    "    \n",
    "    model = NeuMF(num_users, num_businesses, mf_dim=params['mf_dim'], mlp_dims=params['mlp_dims']).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=params['learning_rate'])\n",
    "    model_path = f'best_model_run_{run_num}.pt'\n",
    "\n",
    "    best_val_rmse = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "    patience = 5\n",
    "    min_delta = 0.0001\n",
    "    epochs = 50\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for user_ids, item_ids, ratings in train_loader:\n",
    "            user_ids, item_ids, ratings = user_ids.to(device), item_ids.to(device), ratings.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            predictions = model(user_ids, item_ids)\n",
    "            loss = criterion(predictions, ratings)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        val_mae, val_rmse = evaluate_model(model, val_loader, device)\n",
    "\n",
    "        if val_rmse < best_val_rmse - min_delta:\n",
    "            best_val_rmse = val_rmse\n",
    "            epochs_no_improve = 0\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve == patience:\n",
    "                print(f\"조기 종료 발생. (실행 {run_num})\")\n",
    "                break\n",
    "    \n",
    "    if os.path.exists(model_path):\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "    else:\n",
    "        print(f\"최적 모델을 찾지 못해 현재 모델을 사용합니다. (실행 {run_num})\")\n",
    "\n",
    "    test_mae, test_rmse = evaluate_model(model, test_loader, device)\n",
    "    \n",
    "    if os.path.exists(model_path):\n",
    "        os.remove(model_path)\n",
    "\n",
    "    return test_mae, test_rmse, best_val_rmse\n",
    "\n",
    "# -------------------- 메인 실행 루틴 --------------------\n",
    "def main():\n",
    "    # -------------------- 1. 하이퍼파라미터 랜덤 서치 --------------------\n",
    "    param_grid = {\n",
    "        'mf_dim': [16, 32, 64],\n",
    "        'mlp_dims': [[64, 32, 16], [128, 64, 32], [256, 128, 64]],\n",
    "        'learning_rate': [0.0005, 0.001, 0.002],\n",
    "        'batch_size': [128, 256, 512]\n",
    "    }\n",
    "    num_trials = 10\n",
    "    best_params = None\n",
    "    best_val_rmse_search = float('inf')\n",
    "\n",
    "    print(f\"\\n--- 1단계: 하이퍼파라미터 랜덤 서치 ({num_trials}회) 시작 ---\")\n",
    "    \n",
    "    # 랜덤 서치를 위한 데이터 분할 (테스트 셋을 따로 떼어 놓음)\n",
    "    train_val_df_search, test_df_for_final = train_test_split(df_processed, test_size=0.2, random_state=42)\n",
    "    train_df_search, val_df_search = train_test_split(train_val_df_search, test_size=1/8, random_state=42)\n",
    "\n",
    "    for i in range(num_trials):\n",
    "        current_params = {k: random.choice(v) for k, v in param_grid.items()}\n",
    "        print(f\"\\n--- 시도 {i+1}/{num_trials} ---\")\n",
    "        \n",
    "        # 임시 실행으로 최적의 검증 RMSE를 찾음\n",
    "        _, _, current_val_rmse = train_and_evaluate_run(current_params, train_df_search, val_df_search, test_df_for_final, f'search_{i+1}')\n",
    "        \n",
    "        print(f\"    --> 시도 {i+1} 검증 RMSE: {current_val_rmse:.4f}\")\n",
    "        \n",
    "        if current_val_rmse < best_val_rmse_search:\n",
    "            best_val_rmse_search = current_val_rmse\n",
    "            best_params = current_params\n",
    "            print(f\"    --> 새로운 최적 RMSE 발견: {best_val_rmse_search:.4f} (파라미터: {best_params})\")\n",
    "\n",
    "    print(f\"\\n✅ 1단계 완료. 최적 파라미터: {best_params}\")\n",
    "\n",
    "    # -------------------- 2. 최적 파라미터로 5회 반복 최종 평가 --------------------\n",
    "    if best_params:\n",
    "        all_rmse, all_mae = [], []\n",
    "        num_runs = 5\n",
    "        print(f\"\\n--- 2단계: 최적 파라미터로 {num_runs}회 반복 평가 시작 ---\")\n",
    "\n",
    "        for i in range(num_runs):\n",
    "            # 매번 새로운 무작위 데이터 분할 사용\n",
    "            random_state = 42 + i\n",
    "            train_val_df_final, test_df_final = train_test_split(df_processed, test_size=0.2, random_state=random_state)\n",
    "            train_df_final, val_df_final = train_test_split(train_val_df_final, test_size=1/8, random_state=random_state)\n",
    "\n",
    "            test_mae, test_rmse, _ = train_and_evaluate_run(best_params, train_df_final, val_df_final, test_df_final, f'final_{i+1}')\n",
    "            \n",
    "            print(f\"\\n✅ [NeuMF] {i+1}번째 테스트 결과: RMSE={test_rmse:.4f}, MAE={test_mae:.4f}\")\n",
    "            \n",
    "            all_rmse.append(test_rmse)\n",
    "            all_mae.append(test_mae)\n",
    "\n",
    "        # 최종 평균 계산 및 출력\n",
    "        avg_rmse = np.mean(all_rmse)\n",
    "        std_rmse = np.std(all_rmse)\n",
    "        avg_mae = np.mean(all_mae)\n",
    "        std_mae = np.std(all_mae)\n",
    "\n",
    "        print(\"\\n\\n==================== 최종 5회 반복 평균 결과 ====================\")\n",
    "        print(f\" - 평균 RMSE : {avg_rmse:.4f} +/- {std_rmse:.4f}\")\n",
    "        print(f\" - 평균 MAE  : {avg_mae:.4f} +/- {std_mae:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3d5f6c-5bcd-4de4-bef7-afbf78e2a276",
   "metadata": {},
   "source": [
    "dataset_la"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ef6017-d7db-4181-9436-eb24f37be37c",
   "metadata": {},
   "source": [
    "dataset_la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fb79e0a-02de-41cf-8ac1-32923b6d99b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "✅ 데이터 로딩 및 전처리 완료. 사용자 수: 23621, 비즈니스 수: 3897\n",
      "\n",
      "--- 1단계: 하이퍼파라미터 랜덤 서치 (10회) 시작 ---\n",
      "\n",
      "--- 시도 1/10 ---\n",
      "--- 실행 search_1 시작, 파라미터: {'mf_dim': 16, 'mlp_dims': [64, 32, 16], 'learning_rate': 0.0005, 'batch_size': 256}\n",
      "조기 종료 발생. (실행 search_1)\n",
      "    --> 시도 1 검증 RMSE: 1.1374\n",
      "    --> 새로운 최적 RMSE 발견: 1.1374 (파라미터: {'mf_dim': 16, 'mlp_dims': [64, 32, 16], 'learning_rate': 0.0005, 'batch_size': 256})\n",
      "\n",
      "--- 시도 2/10 ---\n",
      "--- 실행 search_2 시작, 파라미터: {'mf_dim': 16, 'mlp_dims': [128, 64, 32], 'learning_rate': 0.002, 'batch_size': 512}\n",
      "조기 종료 발생. (실행 search_2)\n",
      "    --> 시도 2 검증 RMSE: 1.1220\n",
      "    --> 새로운 최적 RMSE 발견: 1.1220 (파라미터: {'mf_dim': 16, 'mlp_dims': [128, 64, 32], 'learning_rate': 0.002, 'batch_size': 512})\n",
      "\n",
      "--- 시도 3/10 ---\n",
      "--- 실행 search_3 시작, 파라미터: {'mf_dim': 64, 'mlp_dims': [256, 128, 64], 'learning_rate': 0.001, 'batch_size': 256}\n",
      "조기 종료 발생. (실행 search_3)\n",
      "    --> 시도 3 검증 RMSE: 1.1224\n",
      "\n",
      "--- 시도 4/10 ---\n",
      "--- 실행 search_4 시작, 파라미터: {'mf_dim': 32, 'mlp_dims': [128, 64, 32], 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "조기 종료 발생. (실행 search_4)\n",
      "    --> 시도 4 검증 RMSE: 1.1301\n",
      "\n",
      "--- 시도 5/10 ---\n",
      "--- 실행 search_5 시작, 파라미터: {'mf_dim': 16, 'mlp_dims': [256, 128, 64], 'learning_rate': 0.001, 'batch_size': 512}\n",
      "조기 종료 발생. (실행 search_5)\n",
      "    --> 시도 5 검증 RMSE: 1.1227\n",
      "\n",
      "--- 시도 6/10 ---\n",
      "--- 실행 search_6 시작, 파라미터: {'mf_dim': 16, 'mlp_dims': [256, 128, 64], 'learning_rate': 0.0005, 'batch_size': 512}\n",
      "조기 종료 발생. (실행 search_6)\n",
      "    --> 시도 6 검증 RMSE: 1.1264\n",
      "\n",
      "--- 시도 7/10 ---\n",
      "--- 실행 search_7 시작, 파라미터: {'mf_dim': 32, 'mlp_dims': [256, 128, 64], 'learning_rate': 0.001, 'batch_size': 256}\n",
      "조기 종료 발생. (실행 search_7)\n",
      "    --> 시도 7 검증 RMSE: 1.1247\n",
      "\n",
      "--- 시도 8/10 ---\n",
      "--- 실행 search_8 시작, 파라미터: {'mf_dim': 16, 'mlp_dims': [64, 32, 16], 'learning_rate': 0.001, 'batch_size': 256}\n",
      "조기 종료 발생. (실행 search_8)\n",
      "    --> 시도 8 검증 RMSE: 1.1292\n",
      "\n",
      "--- 시도 9/10 ---\n",
      "--- 실행 search_9 시작, 파라미터: {'mf_dim': 16, 'mlp_dims': [128, 64, 32], 'learning_rate': 0.002, 'batch_size': 512}\n",
      "조기 종료 발생. (실행 search_9)\n",
      "    --> 시도 9 검증 RMSE: 1.1214\n",
      "    --> 새로운 최적 RMSE 발견: 1.1214 (파라미터: {'mf_dim': 16, 'mlp_dims': [128, 64, 32], 'learning_rate': 0.002, 'batch_size': 512})\n",
      "\n",
      "--- 시도 10/10 ---\n",
      "--- 실행 search_10 시작, 파라미터: {'mf_dim': 64, 'mlp_dims': [64, 32, 16], 'learning_rate': 0.002, 'batch_size': 256}\n",
      "조기 종료 발생. (실행 search_10)\n",
      "    --> 시도 10 검증 RMSE: 1.1337\n",
      "\n",
      "✅ 1단계 완료. 최적 파라미터: {'mf_dim': 16, 'mlp_dims': [128, 64, 32], 'learning_rate': 0.002, 'batch_size': 512}\n",
      "\n",
      "--- 2단계: 최적 파라미터로 5회 반복 평가 시작 ---\n",
      "--- 실행 final_1 시작, 파라미터: {'mf_dim': 16, 'mlp_dims': [128, 64, 32], 'learning_rate': 0.002, 'batch_size': 512}\n",
      "조기 종료 발생. (실행 final_1)\n",
      "\n",
      "✅ [NeuMF] 1번째 테스트 결과: RMSE=1.1174, MAE=0.8765\n",
      "--- 실행 final_2 시작, 파라미터: {'mf_dim': 16, 'mlp_dims': [128, 64, 32], 'learning_rate': 0.002, 'batch_size': 512}\n",
      "조기 종료 발생. (실행 final_2)\n",
      "\n",
      "✅ [NeuMF] 2번째 테스트 결과: RMSE=1.1264, MAE=0.8897\n",
      "--- 실행 final_3 시작, 파라미터: {'mf_dim': 16, 'mlp_dims': [128, 64, 32], 'learning_rate': 0.002, 'batch_size': 512}\n",
      "조기 종료 발생. (실행 final_3)\n",
      "\n",
      "✅ [NeuMF] 3번째 테스트 결과: RMSE=1.1191, MAE=0.8862\n",
      "--- 실행 final_4 시작, 파라미터: {'mf_dim': 16, 'mlp_dims': [128, 64, 32], 'learning_rate': 0.002, 'batch_size': 512}\n",
      "조기 종료 발생. (실행 final_4)\n",
      "\n",
      "✅ [NeuMF] 4번째 테스트 결과: RMSE=1.1199, MAE=0.8846\n",
      "--- 실행 final_5 시작, 파라미터: {'mf_dim': 16, 'mlp_dims': [128, 64, 32], 'learning_rate': 0.002, 'batch_size': 512}\n",
      "조기 종료 발생. (실행 final_5)\n",
      "\n",
      "✅ [NeuMF] 5번째 테스트 결과: RMSE=1.1171, MAE=0.8787\n",
      "\n",
      "\n",
      "==================== 최종 5회 반복 평균 결과 ====================\n",
      " - 평균 RMSE : 1.1200 +/- 0.0034\n",
      " - 평균 MAE  : 0.8832 +/- 0.0049\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import random\n",
    "import json\n",
    "\n",
    "# --- 장치 설정 (GPU 사용 가능 시) ---\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# -------------------- 데이터 로딩 및 전처리 --------------------\n",
    "# 'dataset_fl.json' 파일을 읽어옵니다.\n",
    "try:\n",
    "    df = pd.read_json('dataset_la.json', lines=True)\n",
    "except ValueError:\n",
    "    print(\"Trying to read JSON without lines=True (assuming a single JSON object or array of objects).\")\n",
    "    df = pd.read_json('dataset_la.json')\n",
    "\n",
    "df_processed = df[['user_id', 'business_id', 'review_stars']].copy()\n",
    "\n",
    "# Label Encoding을 사용하여 user_id와 business_id를 정수형으로 변환합니다.\n",
    "user_encoder = LabelEncoder()\n",
    "business_encoder = LabelEncoder()\n",
    "df_processed['user_encoded'] = user_encoder.fit_transform(df_processed['user_id'])\n",
    "df_processed['business_encoded'] = business_encoder.fit_transform(df_processed['business_id'])\n",
    "\n",
    "num_users = len(user_encoder.classes_)\n",
    "num_businesses = len(business_encoder.classes_)\n",
    "print(f\"✅ 데이터 로딩 및 전처리 완료. 사용자 수: {num_users}, 비즈니스 수: {num_businesses}\")\n",
    "\n",
    "# -------------------- Dataset 정의 --------------------\n",
    "class NeuMFDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.user_ids = torch.tensor(df['user_encoded'].values, dtype=torch.long)\n",
    "        self.item_ids = torch.tensor(df['business_encoded'].values, dtype=torch.long)\n",
    "        self.ratings = torch.tensor(df['review_stars'].values, dtype=torch.float)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ratings)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.user_ids[idx], self.item_ids[idx], self.ratings[idx]\n",
    "\n",
    "# -------------------- 모델 정의 --------------------\n",
    "class NeuMF(nn.Module):\n",
    "    def __init__(self, num_users, num_items, mf_dim, mlp_dims):\n",
    "        super(NeuMF, self).__init__()\n",
    "        self.user_embedding_gmf = nn.Embedding(num_users, mf_dim)\n",
    "        self.item_embedding_gmf = nn.Embedding(num_items, mf_dim)\n",
    "        \n",
    "        self.user_embedding_mlp = nn.Embedding(num_users, mlp_dims[0] // 2)\n",
    "        self.item_embedding_mlp = nn.Embedding(num_items, mlp_dims[0] // 2)\n",
    "\n",
    "        mlp_layers = []\n",
    "        input_dim = mlp_dims[0]\n",
    "        for dim in mlp_dims[1:]:\n",
    "            mlp_layers.append(nn.Linear(input_dim, dim))\n",
    "            mlp_layers.append(nn.ReLU())\n",
    "            input_dim = dim\n",
    "        self.mlp = nn.Sequential(*mlp_layers)\n",
    "\n",
    "        self.final_layer = nn.Linear(mf_dim + mlp_dims[-1], 1)\n",
    "\n",
    "    def forward(self, user_ids, item_ids):\n",
    "        gmf_user = self.user_embedding_gmf(user_ids)\n",
    "        gmf_item = self.item_embedding_gmf(item_ids)\n",
    "        gmf_output = gmf_user * gmf_item\n",
    "\n",
    "        mlp_user = self.user_embedding_mlp(user_ids)\n",
    "        mlp_item = self.item_embedding_mlp(item_ids)\n",
    "        mlp_input = torch.cat((mlp_user, mlp_item), dim=1)\n",
    "        mlp_output = self.mlp(mlp_input)\n",
    "\n",
    "        concat = torch.cat((gmf_output, mlp_output), dim=1)\n",
    "        prediction = self.final_layer(concat)\n",
    "        return prediction.view(-1)\n",
    "\n",
    "# -------------------- 평가 지표 함수 정의 --------------------\n",
    "def evaluate_model(model, data_loader, device):\n",
    "    model.eval()\n",
    "    preds, targets = [], []\n",
    "    with torch.no_grad():\n",
    "        for user_ids, item_ids, ratings in data_loader:\n",
    "            user_ids, item_ids, ratings = user_ids.to(device), item_ids.to(device), ratings.to(device)\n",
    "            output = model(user_ids, item_ids)\n",
    "            preds.extend(output.cpu().numpy())\n",
    "            targets.extend(ratings.cpu().numpy())\n",
    "    \n",
    "    preds = np.array(preds)\n",
    "    targets = np.array(targets)\n",
    "    \n",
    "    mae = mean_absolute_error(targets, preds)\n",
    "    rmse = np.sqrt(mean_squared_error(targets, preds))\n",
    "    \n",
    "    return mae, rmse\n",
    "\n",
    "# -------------------- 학습 및 평가 함수 (단일 실행) --------------------\n",
    "def train_and_evaluate_run(params, train_df, val_df, test_df, run_num):\n",
    "    print(f\"--- 실행 {run_num} 시작, 파라미터: {params}\")\n",
    "\n",
    "    train_dataset = NeuMFDataset(train_df)\n",
    "    val_dataset = NeuMFDataset(val_df)\n",
    "    test_dataset = NeuMFDataset(test_df)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=params['batch_size'], shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=params['batch_size'], shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=params['batch_size'], shuffle=False)\n",
    "    \n",
    "    model = NeuMF(num_users, num_businesses, mf_dim=params['mf_dim'], mlp_dims=params['mlp_dims']).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=params['learning_rate'])\n",
    "    model_path = f'best_model_run_{run_num}.pt'\n",
    "\n",
    "    best_val_rmse = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "    patience = 5\n",
    "    min_delta = 0.0001\n",
    "    epochs = 50\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for user_ids, item_ids, ratings in train_loader:\n",
    "            user_ids, item_ids, ratings = user_ids.to(device), item_ids.to(device), ratings.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            predictions = model(user_ids, item_ids)\n",
    "            loss = criterion(predictions, ratings)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        val_mae, val_rmse = evaluate_model(model, val_loader, device)\n",
    "\n",
    "        if val_rmse < best_val_rmse - min_delta:\n",
    "            best_val_rmse = val_rmse\n",
    "            epochs_no_improve = 0\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve == patience:\n",
    "                print(f\"조기 종료 발생. (실행 {run_num})\")\n",
    "                break\n",
    "    \n",
    "    if os.path.exists(model_path):\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "    else:\n",
    "        print(f\"최적 모델을 찾지 못해 현재 모델을 사용합니다. (실행 {run_num})\")\n",
    "\n",
    "    test_mae, test_rmse = evaluate_model(model, test_loader, device)\n",
    "    \n",
    "    if os.path.exists(model_path):\n",
    "        os.remove(model_path)\n",
    "\n",
    "    return test_mae, test_rmse, best_val_rmse\n",
    "\n",
    "# -------------------- 메인 실행 루틴 --------------------\n",
    "def main():\n",
    "    # -------------------- 1. 하이퍼파라미터 랜덤 서치 --------------------\n",
    "    param_grid = {\n",
    "        'mf_dim': [16, 32, 64],\n",
    "        'mlp_dims': [[64, 32, 16], [128, 64, 32], [256, 128, 64]],\n",
    "        'learning_rate': [0.0005, 0.001, 0.002],\n",
    "        'batch_size': [128, 256, 512]\n",
    "    }\n",
    "    num_trials = 10\n",
    "    best_params = None\n",
    "    best_val_rmse_search = float('inf')\n",
    "\n",
    "    print(f\"\\n--- 1단계: 하이퍼파라미터 랜덤 서치 ({num_trials}회) 시작 ---\")\n",
    "    \n",
    "    # 랜덤 서치를 위한 데이터 분할 (테스트 셋을 따로 떼어 놓음)\n",
    "    train_val_df_search, test_df_for_final = train_test_split(df_processed, test_size=0.2, random_state=42)\n",
    "    train_df_search, val_df_search = train_test_split(train_val_df_search, test_size=1/8, random_state=42)\n",
    "\n",
    "    for i in range(num_trials):\n",
    "        current_params = {k: random.choice(v) for k, v in param_grid.items()}\n",
    "        print(f\"\\n--- 시도 {i+1}/{num_trials} ---\")\n",
    "        \n",
    "        # 임시 실행으로 최적의 검증 RMSE를 찾음\n",
    "        _, _, current_val_rmse = train_and_evaluate_run(current_params, train_df_search, val_df_search, test_df_for_final, f'search_{i+1}')\n",
    "        \n",
    "        print(f\"    --> 시도 {i+1} 검증 RMSE: {current_val_rmse:.4f}\")\n",
    "        \n",
    "        if current_val_rmse < best_val_rmse_search:\n",
    "            best_val_rmse_search = current_val_rmse\n",
    "            best_params = current_params\n",
    "            print(f\"    --> 새로운 최적 RMSE 발견: {best_val_rmse_search:.4f} (파라미터: {best_params})\")\n",
    "\n",
    "    print(f\"\\n✅ 1단계 완료. 최적 파라미터: {best_params}\")\n",
    "\n",
    "    # -------------------- 2. 최적 파라미터로 5회 반복 최종 평가 --------------------\n",
    "    if best_params:\n",
    "        all_rmse, all_mae = [], []\n",
    "        num_runs = 5\n",
    "        print(f\"\\n--- 2단계: 최적 파라미터로 {num_runs}회 반복 평가 시작 ---\")\n",
    "\n",
    "        for i in range(num_runs):\n",
    "            # 매번 새로운 무작위 데이터 분할 사용\n",
    "            random_state = 42 + i\n",
    "            train_val_df_final, test_df_final = train_test_split(df_processed, test_size=0.2, random_state=random_state)\n",
    "            train_df_final, val_df_final = train_test_split(train_val_df_final, test_size=1/8, random_state=random_state)\n",
    "\n",
    "            test_mae, test_rmse, _ = train_and_evaluate_run(best_params, train_df_final, val_df_final, test_df_final, f'final_{i+1}')\n",
    "            \n",
    "            print(f\"\\n✅ [NeuMF] {i+1}번째 테스트 결과: RMSE={test_rmse:.4f}, MAE={test_mae:.4f}\")\n",
    "            \n",
    "            all_rmse.append(test_rmse)\n",
    "            all_mae.append(test_mae)\n",
    "\n",
    "        # 최종 평균 계산 및 출력\n",
    "        avg_rmse = np.mean(all_rmse)\n",
    "        std_rmse = np.std(all_rmse)\n",
    "        avg_mae = np.mean(all_mae)\n",
    "        std_mae = np.std(all_mae)\n",
    "\n",
    "        print(\"\\n\\n==================== 최종 5회 반복 평균 결과 ====================\")\n",
    "        print(f\" - 평균 RMSE : {avg_rmse:.4f} +/- {std_rmse:.4f}\")\n",
    "        print(f\" - 평균 MAE  : {avg_mae:.4f} +/- {std_mae:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
