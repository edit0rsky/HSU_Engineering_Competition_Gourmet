{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcba9251",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import matplotlib.font_manager as fm\n",
    "import IPython.display as disp\n",
    "import squarify"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18e6828",
   "metadata": {},
   "source": [
    "# Business"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8452845c",
   "metadata": {},
   "source": [
    "파일 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cf728b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading businesses: 100%|██████████| 150346/150346 [00:01<00:00, 106377.51it/s]\n"
     ]
    }
   ],
   "source": [
    "file_path_business = \"../yelp_dataset/yelp_academic_dataset_business.json\"\n",
    "\n",
    "# total lines 미리 세기 (tqdm 활용)\n",
    "with open(file_path_business, 'r', encoding='utf-8') as f:\n",
    "    total_lines = sum(1 for _ in f)\n",
    "\n",
    "data = []\n",
    "with open(file_path_business, 'r', encoding='utf-8') as f:\n",
    "    for line in tqdm(f, total=total_lines, desc=\"Loading businesses\"):\n",
    "        data.append(json.loads(line))\n",
    "\n",
    "df_business = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63dd67a4",
   "metadata": {},
   "source": [
    "필요 없는 칼럼 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6d0baea",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols_business = ['name','address','postal_code','latitude','longitude','is_open','attributes','hours']\n",
    "df_business = df_business.drop(columns=drop_cols_business)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255df3b9",
   "metadata": {},
   "source": [
    "음식관련 업종만 필터링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0a1cdf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_categories(fp):\n",
    "    with open(fp,'r',encoding='utf-8') as f:\n",
    "        return set(line.strip().lower() for line in f if line.strip())\n",
    "food_categories = load_categories('../src/food.txt')\n",
    "restaurant_categories = load_categories('../src/restaurant.txt')\n",
    "target_categories = food_categories.union(restaurant_categories)\n",
    "\n",
    "def category_match(row):\n",
    "    if isinstance(row, str) and row.strip():  # 빈 문자열도 고려하여 추가\n",
    "        biz_categories = set(cat.strip().lower() for cat in row.split(','))\n",
    "        return bool(biz_categories & target_categories)\n",
    "    return False\n",
    "\n",
    "df_business = df_business[df_business['categories'].apply(category_match)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "076c48a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_business.rename(columns={'stars': 'business_stars', 'review_count': 'business_review_count'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab73862",
   "metadata": {},
   "source": [
    "## DataFrame Information\n",
    "\n",
    "- **Index**: 63,199 entries (from 3 to 150340)\n",
    "- **Columns**: 6\n",
    "\n",
    "| #   | Column        | Non-Null Count | Dtype  |\n",
    "|-----|---------------|----------------|--------|\n",
    "| 0   | business_id   | 63,199         | object |\n",
    "| 1   | city          | 63,199         | object |\n",
    "| 2   | state         | 63,199         | object |\n",
    "| 3   | business_stars         | 63,199         | float64|\n",
    "| 4   | business_review_count  | 63,199         | int64  |\n",
    "| 5   | categories    | 63,199         | object |\n",
    "\n",
    "**Memory Usage**: 3.4+ MB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8fca09",
   "metadata": {},
   "source": [
    "# User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f8678aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading users: 100%|██████████| 1987897/1987897 [00:15<00:00, 131217.81it/s]\n"
     ]
    }
   ],
   "source": [
    "file_path_user = \"../yelp_dataset/yelp_academic_dataset_user.json\"\n",
    "\n",
    "# total lines 미리 세기 (tqdm 활용)\n",
    "with open(file_path_user, 'r', encoding='utf-8') as f:\n",
    "    total_lines = sum(1 for _ in f)\n",
    "\n",
    "data = []\n",
    "with open(file_path_user, 'r', encoding='utf-8') as f:\n",
    "    for line in tqdm(f, total=total_lines, desc=\"Loading users\"):\n",
    "        data.append(json.loads(line))\n",
    "\n",
    "df_user = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a89b9614",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols_user = ['name', 'yelping_since', 'funny', 'cool', 'elite', 'friends', 'fans', 'compliment_hot', 'compliment_more', 'compliment_profile', 'compliment_cute', 'compliment_list', 'compliment_note', 'compliment_plain', 'compliment_cool', 'compliment_funny', 'compliment_writer', 'compliment_photos']\n",
    "df_user = df_user.drop(columns=drop_cols_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d816841d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user.rename(columns={'average_stars': 'user_average_stars', 'useful': 'user_useful', 'review_count': 'user_review_count'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e7e35c",
   "metadata": {},
   "source": [
    "## DataFrame Information\n",
    "\n",
    "- **Index**: 1,987,897 entries (from 0 to 1,987,896)\n",
    "- **Columns**: 4\n",
    "\n",
    "| #   | Column             | Dtype   |\n",
    "|-----|--------------------|---------|\n",
    "| 0   | user_id            | object  |\n",
    "| 1   | user_review_count  | int64   |\n",
    "| 2   | user_useful        | int64   |\n",
    "| 3   | user_average_stars | float64 |\n",
    "\n",
    "**Memory Usage**: 60.7+ MB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cde507",
   "metadata": {},
   "source": [
    "# review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a702c4e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading reviews: 100%|██████████| 6990280/6990280 [00:25<00:00, 274091.16it/s]\n"
     ]
    }
   ],
   "source": [
    "file_path_review = \"../yelp_dataset/yelp_academic_dataset_review.json\"\n",
    "\n",
    "# total lines 미리 세기 (tqdm 활용)\n",
    "with open(file_path_review, 'r', encoding='utf-8') as f:\n",
    "    total_lines = sum(1 for _ in f)\n",
    "\n",
    "data = []\n",
    "with open(file_path_review, 'r', encoding='utf-8') as f:\n",
    "    for line in tqdm(f, total=total_lines, desc=\"Loading reviews\"):\n",
    "        data.append(json.loads(line))\n",
    "\n",
    "df_review = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9930fe87",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols_review = ['funny', 'cool']\n",
    "df_review = df_review.drop(columns=drop_cols_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e02057da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_review.rename(columns={'stars': 'review_stars', 'useful': 'review_useful'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0335af7",
   "metadata": {},
   "source": [
    "## DataFrame Information\n",
    "\n",
    "- **Index**: 6,990,280 entries (from 0 to 6,990,279)\n",
    "- **Columns**: 7\n",
    "\n",
    "| #   | Column         | Dtype   |\n",
    "|-----|----------------|---------|\n",
    "| 0   | review_id      | object  |\n",
    "| 1   | user_id        | object  |\n",
    "| 2   | business_id    | object  |\n",
    "| 3   | review_stars   | float64 |\n",
    "| 4   | review_useful  | int64   |\n",
    "| 5   | text           | object  |\n",
    "| 6   | date           | object  |\n",
    "\n",
    "**Memory Usage**: 373.3+ MB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f2111a",
   "metadata": {},
   "source": [
    "# Combine data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63dfa387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_review와 df_user를 user_id 기준으로 합침\n",
    "df_dataset = pd.merge(df_review, df_user, on='user_id', how='inner')\n",
    "\n",
    "# df_review와 df_business를 business_id 기준으로 합침\n",
    "df_dataset = pd.merge(df_dataset, df_business, on='business_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4bed17ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 청크 크기 설정\n",
    "chunk_size = 100000  # 원하는 청크 크기 (예: 10만 행씩)\n",
    "\n",
    "# 파일 저장\n",
    "with open('../output/dataset_1.json', 'w', encoding='utf-8') as f:\n",
    "    for i in range(0, len(df_dataset), chunk_size):\n",
    "        # 청크 단위로 데이터를 가져오기\n",
    "        chunk = df_dataset.iloc[i:i+chunk_size]\n",
    "        # 첫 번째 청크에는 '[' 추가, 이후 청크에는 ','로 이어서 추가\n",
    "        if i == 0:\n",
    "            chunk.to_json(f, orient='records', lines=True, force_ascii=False)\n",
    "        else:\n",
    "            chunk.to_json(f, orient='records', lines=True, force_ascii=False, date_format='iso')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c83b35",
   "metadata": {},
   "source": [
    "## DataFrame Information\n",
    "\n",
    "- **Index**: 5,069,533 entries (from 0 to 5,069,532)\n",
    "- **Columns**: 15\n",
    "\n",
    "| #   | Column                    | Dtype   |\n",
    "|-----|---------------------------|---------|\n",
    "| 0   | review_id                 | object  |\n",
    "| 1   | user_id                   | object  |\n",
    "| 2   | business_id               | object  |\n",
    "| 3   | review_stars              | float64 |\n",
    "| 4   | review_useful             | int64   |\n",
    "| 5   | text                      | object  |\n",
    "| 6   | date                      | object  |\n",
    "| 7   | user_review_count         | int64   |\n",
    "| 8   | user_useful               | int64   |\n",
    "| 9   | user_average_stars        | float64 |\n",
    "| 10  | city                      | object  |\n",
    "| 11  | state                     | object  |\n",
    "| 12  | business_stars            | float64 |\n",
    "| 13  | business_review_count     | int64   |\n",
    "| 14  | categories                | object  |\n",
    "\n",
    "**Memory Usage**: 580.2+ MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31e93ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "review_id                0\n",
      "user_id                  0\n",
      "business_id              0\n",
      "review_stars             0\n",
      "review_useful            0\n",
      "text                     0\n",
      "date                     0\n",
      "user_review_count        0\n",
      "user_useful              0\n",
      "user_average_stars       0\n",
      "city                     0\n",
      "state                    0\n",
      "business_stars           0\n",
      "business_review_count    0\n",
      "categories               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# df_dataset의 각 컬럼별 결측치 수 확인\n",
    "missing_data = df_dataset.isnull().sum()\n",
    "print(missing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb9608e",
   "metadata": {},
   "source": [
    "# Step 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26574bf8",
   "metadata": {},
   "source": [
    "- 로딩 시간 : 1차 약 4m 50s | 2차 6m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76d871a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_dataset_1 = \"../output/dataset_1.json\"\n",
    "\n",
    "# 데이터를 읽어들여 DataFrame으로 변환\n",
    "data = []\n",
    "with open(file_path_dataset_1, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))\n",
    "\n",
    "# DataFrame 생성\n",
    "df_dataset_1 = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e14c623",
   "metadata": {},
   "source": [
    "필요 없는 칼럼 제거\n",
    "- 소요 시간 : 1m 40s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba42709b",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols_dataset_1 = ['user_review_count','user_useful','user_average_stars','city','business_stars','business_review_count','categories']\n",
    "df_dataset_1 = df_dataset_1.drop(columns=drop_cols_dataset_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17463b15",
   "metadata": {},
   "source": [
    "date 타임스탬프로 변환\n",
    "- 소요 시간 : 53s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f11423fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'date' 컬럼을 pandas datetime으로 변환\n",
    "df_dataset_1['date'] = pd.to_datetime(df_dataset_1['date'])\n",
    "\n",
    "# 밀리초 단위의 타임스탬프로 변환\n",
    "df_dataset_1['date'] = df_dataset_1['date'].apply(lambda x: int(x.timestamp() * 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c10151",
   "metadata": {},
   "source": [
    "별점 형식 float64 -> int64로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d6e4683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 소수점을 반올림하여 int64로 변환\n",
    "df_dataset_1['review_stars'] = df_dataset_1['review_stars'].round().astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9de2eee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5069533 entries, 0 to 5069532\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Dtype \n",
      "---  ------         ----- \n",
      " 0   review_id      object\n",
      " 1   user_id        object\n",
      " 2   business_id    object\n",
      " 3   review_stars   int64 \n",
      " 4   review_useful  int64 \n",
      " 5   text           object\n",
      " 6   date           int64 \n",
      " 7   state          object\n",
      "dtypes: int64(3), object(5)\n",
      "memory usage: 309.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_dataset_1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bae2cf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 청크 크기 설정\n",
    "chunk_size = 100000  # 원하는 청크 크기 (예: 10만 행씩)\n",
    "\n",
    "# 파일 저장\n",
    "with open('../output/dataset_2.json', 'w', encoding='utf-8') as f:\n",
    "    for i in range(0, len(df_dataset_1), chunk_size):\n",
    "        # 청크 단위로 데이터를 가져오기\n",
    "        chunk = df_dataset.iloc[i:i+chunk_size]\n",
    "        # 첫 번째 청크에는 '[' 추가, 이후 청크에는 ','로 이어서 추가\n",
    "        if i == 0:\n",
    "            chunk.to_json(f, orient='records', lines=True, force_ascii=False)\n",
    "        else:\n",
    "            chunk.to_json(f, orient='records', lines=True, force_ascii=False, date_format='iso')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdcbddd",
   "metadata": {},
   "source": [
    "## DataFrame Information\n",
    "\n",
    "- **Index**: 5,069,533 entries (from 0 to 5,069,532)\n",
    "- **Columns**: 8\n",
    "\n",
    "| #   | Column         | Dtype   |\n",
    "|-----|----------------|---------|\n",
    "| 0   | review_id      | object  |\n",
    "| 1   | user_id        | object  |\n",
    "| 2   | business_id    | object  |\n",
    "| 3   | review_stars   | int64   |\n",
    "| 4   | review_useful  | int64   |\n",
    "| 5   | text           | object  |\n",
    "| 6   | date           | int64   |\n",
    "| 7   | state          | object  |\n",
    "\n",
    "**Memory Usage**: 309.4+ MB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd8b9c8",
   "metadata": {},
   "source": [
    "# Step 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13327a95",
   "metadata": {},
   "source": [
    "로딩 시간 : 1차 1m 30s | 2차 3m 59s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09569ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_dataset_2 = \"../output/dataset_2.json\"\n",
    "\n",
    "# 데이터를 읽어들여 DataFrame으로 변환\n",
    "data = []\n",
    "with open(file_path_dataset_2, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))\n",
    "\n",
    "# DataFrame 생성\n",
    "df_dataset_2 = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae4820cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5069533 entries, 0 to 5069532\n",
      "Data columns (total 15 columns):\n",
      " #   Column                 Dtype  \n",
      "---  ------                 -----  \n",
      " 0   review_id              object \n",
      " 1   user_id                object \n",
      " 2   business_id            object \n",
      " 3   review_stars           float64\n",
      " 4   review_useful          int64  \n",
      " 5   text                   object \n",
      " 6   date                   object \n",
      " 7   user_review_count      int64  \n",
      " 8   user_useful            int64  \n",
      " 9   user_average_stars     float64\n",
      " 10  city                   object \n",
      " 11  state                  object \n",
      " 12  business_stars         float64\n",
      " 13  business_review_count  int64  \n",
      " 14  categories             object \n",
      "dtypes: float64(3), int64(4), object(8)\n",
      "memory usage: 580.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_dataset_2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6754f913",
   "metadata": {},
   "source": [
    "- 시간 : 1차 55.4s | 2차 3m 10s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87d57e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터프레임을 state 기준으로 나누기\n",
    "df_pa = df_dataset_2[df_dataset_2['state'] == 'PA'].copy()\n",
    "df_fl = df_dataset_2[df_dataset_2['state'] == 'FL'].copy()\n",
    "df_la = df_dataset_2[df_dataset_2['state'] == 'LA'].copy()\n",
    "\n",
    "# 각 df에서 state 컬럼 삭제\n",
    "df_pa.drop(columns=['state'], inplace=True)\n",
    "df_fl.drop(columns=['state'], inplace=True)\n",
    "df_la.drop(columns=['state'], inplace=True)\n",
    "\n",
    "# 상태 확인용: 초기 데이터 수\n",
    "initial_pa = len(df_pa)\n",
    "initial_fl = len(df_fl)\n",
    "initial_la = len(df_la)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584ad6e0",
   "metadata": {},
   "source": [
    "- 시간 : 3m 48s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfd1c705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 반복 작업: 유저와 비즈니스 리뷰 수가 5개 이상인 것만 남기기\n",
    "def filter_data(df):\n",
    "    total_deleted = 0\n",
    "    while True:\n",
    "        # 리뷰가 5개 이상인 유저만 남기기\n",
    "        user_counts = df['user_id'].value_counts()\n",
    "        filtered_users = user_counts[user_counts >= 5].index\n",
    "        df_filtered = df[df['user_id'].isin(filtered_users)]\n",
    "\n",
    "        # 리뷰가 5개 이상인 비즈니스만 남기기\n",
    "        business_counts = df_filtered['business_id'].value_counts()\n",
    "        filtered_businesses = business_counts[business_counts >= 5].index\n",
    "        df_filtered = df_filtered[df_filtered['business_id'].isin(filtered_businesses)]\n",
    "\n",
    "        # 조건 만족할 때까지 반복\n",
    "        deleted_rows = len(df) - len(df_filtered)  # 삭제된 데이터 수 계산\n",
    "        total_deleted += deleted_rows\n",
    "\n",
    "        if len(df_filtered) == len(df):\n",
    "            break\n",
    "        else:\n",
    "            df = df_filtered\n",
    "\n",
    "    return df, len(df), total_deleted\n",
    "\n",
    "# 각 데이터프레임에 필터링 적용\n",
    "df_pa_filtered, final_pa, deleted_pa = filter_data(df_pa)\n",
    "df_fl_filtered, final_fl, deleted_fl = filter_data(df_fl)\n",
    "df_la_filtered, final_la, deleted_la = filter_data(df_la)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ada668e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State  Initial Rows  Remaining Rows  Deleted Rows  Remaining Percentage\n",
      "   PA       1176504          750446        426058             63.786098\n",
      "   FL        851457          500892        350565             58.827633\n",
      "   LA        584475          277766        306709             47.524017\n"
     ]
    }
   ],
   "source": [
    "# 각 데이터프레임의 결과를 딕셔너리로 정리\n",
    "data = {\n",
    "    \"State\": [\"PA\", \"FL\", \"LA\"],\n",
    "    \"Initial Rows\": [initial_pa, initial_fl, initial_la],\n",
    "    \"Remaining Rows\": [final_pa, final_fl, final_la],\n",
    "    \"Deleted Rows\": [deleted_pa, deleted_fl, deleted_la]\n",
    "}\n",
    "\n",
    "# DataFrame 생성\n",
    "df_summary = pd.DataFrame(data)\n",
    "\n",
    "# 남은 데이터 비율 계산\n",
    "df_summary[\"Remaining Percentage\"] = (df_summary[\"Remaining Rows\"] / df_summary[\"Initial Rows\"]) * 100\n",
    "\n",
    "# 결과 출력\n",
    "print(df_summary.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9801d8cc",
   "metadata": {},
   "source": [
    "- 3개 지역 데이터 저장\n",
    "- 시간 : 1차 31.5s | 2차 1m 14s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a29c1e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_pa_filtered 저장\n",
    "df_pa_filtered.to_json('../output/dataset_pa.json', orient='records', lines=True, force_ascii=False)\n",
    "\n",
    "# df_fl_filtered 저장\n",
    "df_fl_filtered.to_json('../output/dataset_fl.json', orient='records', lines=True, force_ascii=False)\n",
    "\n",
    "# df_la_filtered 저장\n",
    "df_la_filtered.to_json('../output/dataset_la.json', orient='records', lines=True, force_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "25bigdata",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
