{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OyMWMRvAcWMM",
        "outputId": "0864e03f-9208-4132-b6fb-0fac7d6994c7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "dMf2-GClcCqd",
        "outputId": "913276d2-9f01-4394-f0c1-40fec0a2ec29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Î°úÎìú ÏôÑÎ£å: 500892Í∞ú Î†àÏΩîÎìú\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Encoding (CLS):   0%|          | 0/7827 [00:00<?, ?batch/s]/tmp/ipython-input-234703463.py:127: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast_ctx():\n",
            "Encoding (CLS):  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 4310/7827 [03:37<02:57, 19.85batch/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-234703463.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    137\u001b[0m                     \u001b[0;34m\"bert_embedding\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m                 }\n\u001b[0;32m--> 139\u001b[0;31m                 \u001b[0mwf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_ascii\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"‚úÖ ÏôÑÎ£å: {OUTPUT_JSONL}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/json/__init__.py\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0mcheck_circular\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_circular\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_nan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0mseparators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseparators\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         **kw).encode(obj)\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/json/encoder.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;31m# exceptions aren't as detailed.  The list call should be roughly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;31m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_one_shot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/json/encoder.py\u001b[0m in \u001b[0;36miterencode\u001b[0;34m(self, o, _one_shot)\u001b[0m\n\u001b[1;32m    256\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m                 self.skipkeys, _one_shot)\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m def _make_iterencode(markers, _default, _encoder, _indent, _floatstr,\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "from typing import List, Dict\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from contextlib import nullcontext\n",
        "\n",
        "# ====== ÏÑ§Ï†ï ======\n",
        "INPUT_JSON = \"/content/gdrive/MyDrive/dataset_fl.json\"\n",
        "OUTPUT_JSONL = \"/content/gdrive/MyDrive/dataset_fl_emd.jsonl\"\n",
        "\n",
        "MODEL_NAME = \"bert-base-uncased\"\n",
        "BATCH_SIZE = 64\n",
        "MAX_LENGTH = 256\n",
        "USE_FP16 = True\n",
        "NUM_WORKERS = 0\n",
        "PIN_MEMORY = False\n",
        "\n",
        "# ====== 0) ÏûÖÎ†• ÌååÏùº Î°úÎçî (ÌòïÏãù ÏûêÎèô ÌåêÎ≥Ñ) ======\n",
        "def load_records_any(path: str) -> List[Dict]:\n",
        "\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        head = f.read(2048)\n",
        "    head_stripped = head.lstrip()\n",
        "\n",
        "    # ÏºÄÏù¥Ïä§ 1: Î¶¨Ïä§Ìä∏ JSON\n",
        "    if head_stripped.startswith('['):\n",
        "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "            return json.load(f)\n",
        "\n",
        "    # ÏºÄÏù¥Ïä§ 2: JSONL ÏãúÎèÑ\n",
        "    recs = []\n",
        "    failed_jsonl = False\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        for i, line in enumerate(f, 1):\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "            try:\n",
        "                recs.append(json.loads(line))\n",
        "            except json.JSONDecodeError:\n",
        "                failed_jsonl = True\n",
        "                break\n",
        "    if not failed_jsonl and recs:\n",
        "        return recs\n",
        "\n",
        "    # ÏºÄÏù¥Ïä§ 3: Concatenated JSON Î≥¥Ï†ï\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        raw = f.read().strip()\n",
        "    fixed = \"[\" + raw.replace(\"}\\n{\", \"},{\").replace(\"}{\", \"},{\") + \"]\"\n",
        "    try:\n",
        "        return json.loads(fixed)\n",
        "    except json.JSONDecodeError as e:\n",
        "        preview = raw[:800]\n",
        "        raise RuntimeError(\n",
        "            \"ÏûÖÎ†• ÌååÏùº ÌååÏã± Ïã§Ìå®: JSON, JSONL, concat JSON Î™®Îëê Î∂àÍ∞Ä. \"\n",
        "            f\"ÏõêÏù∏: {e}\\nÌååÏùº ÏïûÎ∂ÄÎ∂Ñ ÎØ∏Î¶¨Î≥¥Í∏∞:\\n{preview}\"\n",
        "        )\n",
        "\n",
        "# ====== 1) Dataset / Collate ======\n",
        "class ReviewDataset(Dataset):\n",
        "    def __init__(self, records: List[Dict]):\n",
        "        self.records = records\n",
        "    def __len__(self):\n",
        "        return len(self.records)\n",
        "    def __getitem__(self, idx):\n",
        "        r = self.records[idx]\n",
        "        return {\n",
        "            \"review_id\": r[\"review_id\"],\n",
        "            \"user_id\": r.get(\"user_id\"),\n",
        "            \"business_id\": r.get(\"business_id\"),\n",
        "            \"rating\": r.get(\"review_stars\"),  # 'stars' ÌïÑÎìúÏóêÏÑú Í∞í Í∞ÄÏ†∏Ïò§Í∏∞\n",
        "            \"review_text\": r.get(\"review_text\", \"\")\n",
        "        }\n",
        "\n",
        "def make_collate_fn(tokenizer):\n",
        "    def collate(batch: List[Dict]):\n",
        "        texts = [b.get(\"review_text\") or \"\" for b in batch]\n",
        "        enc = tokenizer(\n",
        "            texts,\n",
        "            return_tensors=\"pt\",\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=MAX_LENGTH\n",
        "        )\n",
        "        enc = {k: v.cpu() for k, v in enc.items()}\n",
        "        meta = [{k: v for k, v in b.items() if k != \"review_text\"} for b in batch]\n",
        "        return {\"meta\": meta, \"inputs\": enc}\n",
        "    return collate\n",
        "\n",
        "# ====== 2) Îç∞Ïù¥ÌÑ∞ Î°úÎìú ======\n",
        "data = load_records_any(INPUT_JSON)\n",
        "print(f\"Î°úÎìú ÏôÑÎ£å: {len(data)}Í∞ú Î†àÏΩîÎìú\")\n",
        "\n",
        "# ====== 3) Î™®Îç∏ Ï§ÄÎπÑ ======\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "model = AutoModel.from_pretrained(MODEL_NAME).to(device).eval()\n",
        "\n",
        "ds = ReviewDataset(data)\n",
        "dl = DataLoader(\n",
        "    ds,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=NUM_WORKERS,\n",
        "    pin_memory=PIN_MEMORY,\n",
        "    collate_fn=make_collate_fn(tokenizer)\n",
        ")\n",
        "\n",
        "# ====== 4) Ï∂îÎ°† & Ï†ÄÏû•(JSONL) ======\n",
        "if os.path.exists(OUTPUT_JSONL):\n",
        "    os.remove(OUTPUT_JSONL)\n",
        "\n",
        "if device.type == \"cuda\" and USE_FP16:\n",
        "    autocast_ctx = torch.cuda.amp.autocast\n",
        "else:\n",
        "    autocast_ctx = nullcontext\n",
        "\n",
        "with torch.no_grad():\n",
        "    with open(OUTPUT_JSONL, \"a\", encoding=\"utf-8\") as wf:\n",
        "        pbar = tqdm(dl, desc=\"Encoding (CLS)\", unit=\"batch\", dynamic_ncols=True)\n",
        "        for batch in pbar:\n",
        "            inputs = {k: v.to(device) for k, v in batch[\"inputs\"].items()}\n",
        "\n",
        "            with autocast_ctx():\n",
        "                out = model(**inputs)\n",
        "                cls = out.last_hidden_state[:, 0, :]\n",
        "\n",
        "            cls = cls.detach().cpu().tolist()\n",
        "            for meta, vec in zip(batch[\"meta\"], cls):\n",
        "                rec = {\n",
        "                    \"user_id\": meta.get(\"user_id\"),\n",
        "                    \"business_id\": meta.get(\"business_id\"),\n",
        "                    \"stars\": meta.get(\"rating\"),\n",
        "                    \"bert_embedding\": vec\n",
        "                }\n",
        "                wf.write(json.dumps(rec, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "print(f\"‚úÖ ÏôÑÎ£å: {OUTPUT_JSONL}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "N = 5 # ÌôïÏù∏Ìï† Ï§Ñ Ïàò\n",
        "\n",
        "record_count = 0\n",
        "with open(\"/content/gdrive/MyDrive/dataset_fl.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    # 1. ÌååÏùº Ï†ÑÏ≤¥Î•º ÏàúÌöåÌïòÎ©∞ Í∞úÏàò Ïπ¥Ïö¥Ìä∏\n",
        "    for line in f:\n",
        "        record_count += 1\n",
        "\n",
        "    # 2. ÌååÏùº Ìè¨Ïù∏ÌÑ∞Î•º Îã§Ïãú Îß® ÏïûÏúºÎ°ú Ïù¥Îèô\n",
        "    f.seek(0)\n",
        "\n",
        "    print(f\"‚úÖ Ï†ÑÏ≤¥ Î¶¨Î∑∞ Í∞úÏàò: {record_count}Í∞ú\")\n",
        "    print(\"-\" * 30)\n",
        "    print(f\"üìÑ Ï≤òÏùå {N}Í∞ú Î†àÏΩîÎìú ÎØ∏Î¶¨Î≥¥Í∏∞:\")\n",
        "\n",
        "    # 3. Ï≤òÏùå NÍ∞ú Î†àÏΩîÎìú Ï∂úÎ†•\n",
        "    for i, line in enumerate(f):\n",
        "        if i >= N:\n",
        "            break\n",
        "        try:\n",
        "            # JSON ÌòïÏãùÏù∏ÏßÄ ÌôïÏù∏ÌïòÎ©∞ Ï∂úÎ†• (ÏÑ†ÌÉù ÏÇ¨Ìï≠)\n",
        "            record = json.loads(line)\n",
        "            print(json.dumps(record, indent=2, ensure_ascii=False))\n",
        "        except json.JSONDecodeError:\n",
        "            print(f\"Ïò§Î•ò: {i+1}Î≤àÏß∏ Ï§ÑÏùÄ Ïò¨Î∞îÎ•∏ JSON ÌòïÏãùÏù¥ ÏïÑÎãôÎãàÎã§.\")\n",
        "            print(line.strip())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5--vL7rB63p",
        "outputId": "97fdccf7-6360-4f4c-de93-155240d38825"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Ï†ÑÏ≤¥ Î¶¨Î∑∞ Í∞úÏàò: 500892Í∞ú\n",
            "------------------------------\n",
            "üìÑ Ï≤òÏùå 5Í∞ú Î†àÏΩîÎìú ÎØ∏Î¶¨Î≥¥Í∏∞:\n",
            "{\n",
            "  \"review_id\": \"OAhBYw8IQ6wlfw1owXWRWw\",\n",
            "  \"user_id\": \"1C2lxzUo1Hyye4RFIXly3g\",\n",
            "  \"business_id\": \"BVndHaLihEYbr76Z0CMEGw\",\n",
            "  \"review_stars\": 5,\n",
            "  \"review_useful\": 0,\n",
            "  \"text\": \"Great place for breakfast! I had the waffle, which was fluffy and perfect, and home fries which were nice and smashed and crunchy. Friendly waitstaff. Will definitely be back!\",\n",
            "  \"date\": 1413044526000\n",
            "}\n",
            "{\n",
            "  \"review_id\": \"mO398Ed5dpv1H5ZsKc8KXw\",\n",
            "  \"user_id\": \"yobeeTUBfaTBcnk26mXNuA\",\n",
            "  \"business_id\": \"hKameFsaXh9g8WQbv593UA\",\n",
            "  \"review_stars\": 4,\n",
            "  \"review_useful\": 0,\n",
            "  \"text\": \"Food was good- atmosphere/decor is like a fishing lodge- menu is someplace between outback & bonefish. Went on a Groupon & all 3 of our meals & calamari appetizer that we ordered were cooked perfectly- we will def be back.\",\n",
            "  \"date\": 1429111848000\n",
            "}\n",
            "{\n",
            "  \"review_id\": \"PPgbLBvi34A6m7bKJfTwhw\",\n",
            "  \"user_id\": \"3TL6HZ1JrKcNTvGDWKlrow\",\n",
            "  \"business_id\": \"GyC36Pn0Q1-qHnqXys6yFg\",\n",
            "  \"review_stars\": 1,\n",
            "  \"review_useful\": 0,\n",
            "  \"text\": \"Service and management terrible... After messing up all 4 of our orders the waiter got mad and started cursing... The manager offered our drinks to be free.. What a mess. The food was cold and nasty didn't even eat half of it and waited over an hour... I will never dine in any cracker barrel again after this experience...\",\n",
            "  \"date\": 1386422233000\n",
            "}\n",
            "{\n",
            "  \"review_id\": \"LnKr0hwejzl71QmoQyTRDQ\",\n",
            "  \"user_id\": \"7RU_xK1tEGlUvXfe0GvtEg\",\n",
            "  \"business_id\": \"hAmuto6UndVroyd_DaD-TA\",\n",
            "  \"review_stars\": 5,\n",
            "  \"review_useful\": 1,\n",
            "  \"text\": \"Not sure why it took until now for us to find this place. We started out going to the chain lobster restaurant but wanted something more authentic. A friend recommended Lobster Haven and I checked it out online. Looked like a type of place we would eat at in Massachusetts when we visit family. We were not disappointed! Service was great, fast and very friendly. Huge selection of all of the favorites. You have to visit this place if you want authentic New England seafood. You can also purchase live lobster and fresh seafood to go and cook it yourself.\",\n",
            "  \"date\": 1520122824000\n",
            "}\n",
            "{\n",
            "  \"review_id\": \"RMho6HMpdec1YgIypwWQrQ\",\n",
            "  \"user_id\": \"SNngOVGTkD34B3FAFnMv5A\",\n",
            "  \"business_id\": \"ab3pRv-b0o-BwMK2jVbH3Q\",\n",
            "  \"review_stars\": 5,\n",
            "  \"review_useful\": 0,\n",
            "  \"text\": \"My husband and I come here often. We love the food here, it's always fresh and the service is great. We highly recommend this place to anyone who loves sushi & hibachi.\",\n",
            "  \"date\": 1535071933000\n",
            "}\n"
          ]
        }
      ]
    }
  ]
}