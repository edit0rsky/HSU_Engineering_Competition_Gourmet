{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "dMf2-GClcCqd",
        "outputId": "913276d2-9f01-4394-f0c1-40fec0a2ec29"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "from typing import List, Dict\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from contextlib import nullcontext\n",
        "\n",
        "# ====== ì„¤ì • ======\n",
        "INPUT_JSON = \"dataset_fl.json\"\n",
        "OUTPUT_JSONL = \"dataset_fl_emd.jsonl\"\n",
        "\n",
        "MODEL_NAME = \"bert-base-uncased\"\n",
        "BATCH_SIZE = 64\n",
        "MAX_LENGTH = 256\n",
        "USE_FP16 = True\n",
        "NUM_WORKERS = 0\n",
        "PIN_MEMORY = False\n",
        "\n",
        "# ====== 0) ì…ë ¥ íŒŒì¼ ë¡œë” (í˜•ì‹ ìë™ íŒë³„) ======\n",
        "def load_records_any(path: str) -> List[Dict]:\n",
        "\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        head = f.read(2048)\n",
        "    head_stripped = head.lstrip()\n",
        "\n",
        "    # ì¼€ì´ìŠ¤ 1: ë¦¬ìŠ¤íŠ¸ JSON\n",
        "    if head_stripped.startswith('['):\n",
        "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "            return json.load(f)\n",
        "\n",
        "    # ì¼€ì´ìŠ¤ 2: JSONL ì‹œë„\n",
        "    recs = []\n",
        "    failed_jsonl = False\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        for i, line in enumerate(f, 1):\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "            try:\n",
        "                recs.append(json.loads(line))\n",
        "            except json.JSONDecodeError:\n",
        "                failed_jsonl = True\n",
        "                break\n",
        "    if not failed_jsonl and recs:\n",
        "        return recs\n",
        "\n",
        "    # ì¼€ì´ìŠ¤ 3: Concatenated JSON ë³´ì •\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        raw = f.read().strip()\n",
        "    fixed = \"[\" + raw.replace(\"}\\n{\", \"},{\").replace(\"}{\", \"},{\") + \"]\"\n",
        "    try:\n",
        "        return json.loads(fixed)\n",
        "    except json.JSONDecodeError as e:\n",
        "        preview = raw[:800]\n",
        "        raise RuntimeError(\n",
        "            \"ì…ë ¥ íŒŒì¼ íŒŒì‹± ì‹¤íŒ¨: JSON, JSONL, concat JSON ëª¨ë‘ ë¶ˆê°€. \"\n",
        "            f\"ì›ì¸: {e}\\níŒŒì¼ ì•ë¶€ë¶„ ë¯¸ë¦¬ë³´ê¸°:\\n{preview}\"\n",
        "        )\n",
        "\n",
        "# ====== 1) Dataset / Collate ======\n",
        "class ReviewDataset(Dataset):\n",
        "    def __init__(self, records: List[Dict]):\n",
        "        self.records = records\n",
        "    def __len__(self):\n",
        "        return len(self.records)\n",
        "    def __getitem__(self, idx):\n",
        "        r = self.records[idx]\n",
        "        return {\n",
        "            \"review_id\": r[\"review_id\"],\n",
        "            \"user_id\": r.get(\"user_id\"),\n",
        "            \"business_id\": r.get(\"business_id\"),\n",
        "            \"rating\": r.get(\"review_stars\"), \n",
        "            \"review_text\": r.get(\"review_text\", \"\")\n",
        "        }\n",
        "\n",
        "def make_collate_fn(tokenizer):\n",
        "    def collate(batch: List[Dict]):\n",
        "        texts = [b.get(\"review_text\") or \"\" for b in batch]\n",
        "        enc = tokenizer(\n",
        "            texts,\n",
        "            return_tensors=\"pt\",\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=MAX_LENGTH\n",
        "        )\n",
        "        enc = {k: v.cpu() for k, v in enc.items()}\n",
        "        meta = [{k: v for k, v in b.items() if k != \"review_text\"} for b in batch]\n",
        "        return {\"meta\": meta, \"inputs\": enc}\n",
        "    return collate\n",
        "\n",
        "# ====== 2) ë°ì´í„° ë¡œë“œ ======\n",
        "data = load_records_any(INPUT_JSON)\n",
        "print(f\"ë¡œë“œ ì™„ë£Œ: {len(data)}ê°œ ë ˆì½”ë“œ\")\n",
        "\n",
        "# ====== 3) ëª¨ë¸ ì¤€ë¹„ ======\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "model = AutoModel.from_pretrained(MODEL_NAME).to(device).eval()\n",
        "\n",
        "ds = ReviewDataset(data)\n",
        "dl = DataLoader(\n",
        "    ds,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=NUM_WORKERS,\n",
        "    pin_memory=PIN_MEMORY,\n",
        "    collate_fn=make_collate_fn(tokenizer)\n",
        ")\n",
        "\n",
        "# ====== 4) ì¶”ë¡  & ì €ì¥(JSONL) ======\n",
        "if os.path.exists(OUTPUT_JSONL):\n",
        "    os.remove(OUTPUT_JSONL)\n",
        "\n",
        "if device.type == \"cuda\" and USE_FP16:\n",
        "    autocast_ctx = torch.cuda.amp.autocast\n",
        "else:\n",
        "    autocast_ctx = nullcontext\n",
        "\n",
        "with torch.no_grad():\n",
        "    with open(OUTPUT_JSONL, \"a\", encoding=\"utf-8\") as wf:\n",
        "        pbar = tqdm(dl, desc=\"Encoding (CLS)\", unit=\"batch\", dynamic_ncols=True)\n",
        "        for batch in pbar:\n",
        "            inputs = {k: v.to(device) for k, v in batch[\"inputs\"].items()}\n",
        "\n",
        "            with autocast_ctx():\n",
        "                out = model(**inputs)\n",
        "                cls = out.last_hidden_state[:, 0, :]\n",
        "\n",
        "            cls = cls.detach().cpu().tolist()\n",
        "            for meta, vec in zip(batch[\"meta\"], cls):\n",
        "                rec = {\n",
        "                    \"user_id\": meta.get(\"user_id\"),\n",
        "                    \"business_id\": meta.get(\"business_id\"),\n",
        "                    \"stars\": meta.get(\"rating\"),\n",
        "                    \"bert_embedding\": vec\n",
        "                }\n",
        "                wf.write(json.dumps(rec, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "print(f\"âœ… ì™„ë£Œ: {OUTPUT_JSONL}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5--vL7rB63p",
        "outputId": "97fdccf7-6360-4f4c-de93-155240d38825"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "N = 5 # í™•ì¸í•  ì¤„ ìˆ˜\n",
        "\n",
        "record_count = 0\n",
        "with open(\"dataset_fl.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        record_count += 1\n",
        "\n",
        "    f.seek(0)\n",
        "\n",
        "    print(f\"âœ… ì „ì²´ ë¦¬ë·° ê°œìˆ˜: {record_count}ê°œ\")\n",
        "    print(\"-\" * 30)\n",
        "    print(f\"ğŸ“„ ì²˜ìŒ {N}ê°œ ë ˆì½”ë“œ ë¯¸ë¦¬ë³´ê¸°:\")\n",
        "\n",
        "    # 3. ì²˜ìŒ Nê°œ ë ˆì½”ë“œ ì¶œë ¥\n",
        "    for i, line in enumerate(f):\n",
        "        if i >= N:\n",
        "            break\n",
        "        try:\n",
        "            record = json.loads(line)\n",
        "            print(json.dumps(record, indent=2, ensure_ascii=False))\n",
        "        except json.JSONDecodeError:\n",
        "            print(f\"ì˜¤ë¥˜: {i+1}ë²ˆì§¸ ì¤„ì€ ì˜¬ë°”ë¥¸ JSON í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.\")\n",
        "            print(line.strip())"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
