{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "dMf2-GClcCqd",
        "outputId": "913276d2-9f01-4394-f0c1-40fec0a2ec29"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "from typing import List, Dict\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from contextlib import nullcontext\n",
        "\n",
        "# ====== 설정 ======\n",
        "INPUT_JSON = \"dataset_fl.json\"\n",
        "OUTPUT_JSONL = \"dataset_fl_emd.jsonl\"\n",
        "\n",
        "MODEL_NAME = \"bert-base-uncased\"\n",
        "BATCH_SIZE = 64\n",
        "MAX_LENGTH = 256\n",
        "USE_FP16 = True\n",
        "NUM_WORKERS = 0\n",
        "PIN_MEMORY = False\n",
        "\n",
        "# ====== 0) 입력 파일 로더 (형식 자동 판별) ======\n",
        "def load_records_any(path: str) -> List[Dict]:\n",
        "\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        head = f.read(2048)\n",
        "    head_stripped = head.lstrip()\n",
        "\n",
        "    # 케이스 1: 리스트 JSON\n",
        "    if head_stripped.startswith('['):\n",
        "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "            return json.load(f)\n",
        "\n",
        "    # 케이스 2: JSONL 시도\n",
        "    recs = []\n",
        "    failed_jsonl = False\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        for i, line in enumerate(f, 1):\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "            try:\n",
        "                recs.append(json.loads(line))\n",
        "            except json.JSONDecodeError:\n",
        "                failed_jsonl = True\n",
        "                break\n",
        "    if not failed_jsonl and recs:\n",
        "        return recs\n",
        "\n",
        "    # 케이스 3: Concatenated JSON 보정\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        raw = f.read().strip()\n",
        "    fixed = \"[\" + raw.replace(\"}\\n{\", \"},{\").replace(\"}{\", \"},{\") + \"]\"\n",
        "    try:\n",
        "        return json.loads(fixed)\n",
        "    except json.JSONDecodeError as e:\n",
        "        preview = raw[:800]\n",
        "        raise RuntimeError(\n",
        "            \"입력 파일 파싱 실패: JSON, JSONL, concat JSON 모두 불가. \"\n",
        "            f\"원인: {e}\\n파일 앞부분 미리보기:\\n{preview}\"\n",
        "        )\n",
        "\n",
        "# ====== 1) Dataset / Collate ======\n",
        "class ReviewDataset(Dataset):\n",
        "    def __init__(self, records: List[Dict]):\n",
        "        self.records = records\n",
        "    def __len__(self):\n",
        "        return len(self.records)\n",
        "    def __getitem__(self, idx):\n",
        "        r = self.records[idx]\n",
        "        return {\n",
        "            \"review_id\": r[\"review_id\"],\n",
        "            \"user_id\": r.get(\"user_id\"),\n",
        "            \"business_id\": r.get(\"business_id\"),\n",
        "            \"rating\": r.get(\"review_stars\"), \n",
        "            \"review_text\": r.get(\"review_text\", \"\")\n",
        "        }\n",
        "\n",
        "def make_collate_fn(tokenizer):\n",
        "    def collate(batch: List[Dict]):\n",
        "        texts = [b.get(\"review_text\") or \"\" for b in batch]\n",
        "        enc = tokenizer(\n",
        "            texts,\n",
        "            return_tensors=\"pt\",\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=MAX_LENGTH\n",
        "        )\n",
        "        enc = {k: v.cpu() for k, v in enc.items()}\n",
        "        meta = [{k: v for k, v in b.items() if k != \"review_text\"} for b in batch]\n",
        "        return {\"meta\": meta, \"inputs\": enc}\n",
        "    return collate\n",
        "\n",
        "# ====== 2) 데이터 로드 ======\n",
        "data = load_records_any(INPUT_JSON)\n",
        "print(f\"로드 완료: {len(data)}개 레코드\")\n",
        "\n",
        "# ====== 3) 모델 준비 ======\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "model = AutoModel.from_pretrained(MODEL_NAME).to(device).eval()\n",
        "\n",
        "ds = ReviewDataset(data)\n",
        "dl = DataLoader(\n",
        "    ds,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=NUM_WORKERS,\n",
        "    pin_memory=PIN_MEMORY,\n",
        "    collate_fn=make_collate_fn(tokenizer)\n",
        ")\n",
        "\n",
        "# ====== 4) 추론 & 저장(JSONL) ======\n",
        "if os.path.exists(OUTPUT_JSONL):\n",
        "    os.remove(OUTPUT_JSONL)\n",
        "\n",
        "if device.type == \"cuda\" and USE_FP16:\n",
        "    autocast_ctx = torch.cuda.amp.autocast\n",
        "else:\n",
        "    autocast_ctx = nullcontext\n",
        "\n",
        "with torch.no_grad():\n",
        "    with open(OUTPUT_JSONL, \"a\", encoding=\"utf-8\") as wf:\n",
        "        pbar = tqdm(dl, desc=\"Encoding (CLS)\", unit=\"batch\", dynamic_ncols=True)\n",
        "        for batch in pbar:\n",
        "            inputs = {k: v.to(device) for k, v in batch[\"inputs\"].items()}\n",
        "\n",
        "            with autocast_ctx():\n",
        "                out = model(**inputs)\n",
        "                cls = out.last_hidden_state[:, 0, :]\n",
        "\n",
        "            cls = cls.detach().cpu().tolist()\n",
        "            for meta, vec in zip(batch[\"meta\"], cls):\n",
        "                rec = {\n",
        "                    \"user_id\": meta.get(\"user_id\"),\n",
        "                    \"business_id\": meta.get(\"business_id\"),\n",
        "                    \"stars\": meta.get(\"rating\"),\n",
        "                    \"bert_embedding\": vec\n",
        "                }\n",
        "                wf.write(json.dumps(rec, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "print(f\"✅ 완료: {OUTPUT_JSONL}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5--vL7rB63p",
        "outputId": "97fdccf7-6360-4f4c-de93-155240d38825"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "N = 5 # 확인할 줄 수\n",
        "\n",
        "record_count = 0\n",
        "with open(\"dataset_fl.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        record_count += 1\n",
        "\n",
        "    f.seek(0)\n",
        "\n",
        "    print(f\"✅ 전체 리뷰 개수: {record_count}개\")\n",
        "    print(\"-\" * 30)\n",
        "    print(f\"📄 처음 {N}개 레코드 미리보기:\")\n",
        "\n",
        "    # 3. 처음 N개 레코드 출력\n",
        "    for i, line in enumerate(f):\n",
        "        if i >= N:\n",
        "            break\n",
        "        try:\n",
        "            record = json.loads(line)\n",
        "            print(json.dumps(record, indent=2, ensure_ascii=False))\n",
        "        except json.JSONDecodeError:\n",
        "            print(f\"오류: {i+1}번째 줄은 올바른 JSON 형식이 아닙니다.\")\n",
        "            print(line.strip())"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
