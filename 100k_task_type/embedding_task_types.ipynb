{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d426616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOOGLE_APPLICATION_CREDENTIALS: /root/project/Gourmet-with-GeminiEmbedding/secrets/vertex.json\n",
      "Exists: True\n"
     ]
    }
   ],
   "source": [
    "# 환경 변수와 자격증명 파일 경로 확인\n",
    "import os, pathlib\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "cred = os.getenv(\"GOOGLE_APPLICATION_CREDENTIALS_PATH\") or os.getenv(\n",
    "    \"GOOGLE_APPLICATION_CREDENTIALS\"\n",
    ")\n",
    "print(\"GOOGLE_APPLICATION_CREDENTIALS:\", cred)\n",
    "print(\"Exists:\", pathlib.Path(cred).exists() if cred else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "320a9866",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/project/HSU_Engineering_Competition_Gourmet/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89a5e57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import vertexai\n",
    "from vertexai.language_models import TextEmbeddingModel, TextEmbeddingInput\n",
    "from google.api_core import exceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96f938c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .env 로드\n",
    "load_dotenv()\n",
    "\n",
    "# .env 파일에서 Vertex AI 설정 값 로드\n",
    "service_account_key_path = os.getenv(\"GOOGLE_APPLICATION_CREDENTIALS_PATH\")\n",
    "project_id = os.getenv(\"PROJECT_ID\")\n",
    "location = os.getenv(\"LOCATION\")\n",
    "\n",
    "# 에러 유무 확인\n",
    "if not all([service_account_key_path, project_id, location]):\n",
    "    raise ValueError(\n",
    "        \"GOOGLE_APPLICATION_CREDENTIALS_PATH, PROJECT_ID, LOCATION 환경 변수를 .env 파일에 설정해주세요.\"\n",
    "    )\n",
    "\n",
    "# 서비스 계정 키를 환경 변수에 설정하여 인증\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = service_account_key_path\n",
    "\n",
    "# Vertex AI 객체 초기화\n",
    "vertexai.init(project=project_id, location=location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "191f9ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불러올 모델명 설정\n",
    "model_name = \"gemini-embedding-001\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "984dcd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 경로\n",
    "input_file = \"../Dataset/states/dataset_fl_split100k.jsonl\"\n",
    "output_file = \"../Dataset/states/fl_split100k\"\n",
    "\n",
    "# vertexAI api call 시 batch크기\n",
    "BATCH_SIZE = 250\n",
    "# api call 시 대기 시간(1초)\n",
    "DELAY_BETWEEN_REQUESTS = 0\n",
    "# 에러 발생시 대기시간\n",
    "RETRY_DELAY = 60\n",
    "# 같은 요청에 대한 최대 재시도 횟수\n",
    "MAX_RETRIES = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2247ed91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 파일에서 데이터를 로드합니다: ../Dataset/states/dataset_fl_split100k.jsonl\n",
      "총 100000개의 리뷰를 로드했습니다.\n"
     ]
    }
   ],
   "source": [
    "# Vertex AI API 호출 함수\n",
    "print(f\"입력 파일에서 데이터를 로드합니다: {input_file}\")\n",
    "try:\n",
    "    df_reviews = pd.read_json(input_file, lines=True)\n",
    "    review_texts = df_reviews[\"text\"].astype(str).tolist()\n",
    "    total_reviews = len(review_texts)\n",
    "    print(f\"총 {total_reviews}개의 리뷰를 로드했습니다.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"오류: 입력 파일 '{input_file}'을 찾을 수 없습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20a73c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이어하기 기능\n",
    "start_index = 0\n",
    "if os.path.exists(output_file):\n",
    "    try:\n",
    "        with open(output_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            processed_count = sum(1 for line in f)\n",
    "        if processed_count > 0:\n",
    "            start_index = processed_count\n",
    "            print(\n",
    "                f\"기존 파일 '{output_file}'에 {processed_count}개의 임베딩이 저장되어 있습니다.\"\n",
    "            )\n",
    "            print(f\"{processed_count}번째 리뷰부터 이어합니다.\")\n",
    "    except Exception as e:\n",
    "        print(f\"기존 출력 파일 처리 중 오류 발생: {e}. 처음부터 다시 시작합니다.\")\n",
    "        start_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76b46f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vertex AI 임베딩 모델을 로드합니다: gemini-embedding-001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/project/HSU_Engineering_Competition_Gourmet/.venv/lib/python3.12/site-packages/vertexai/_model_garden/_model_garden_models.py:278: UserWarning: This feature is deprecated as of June 24, 2025 and will be removed on June 24, 2026. For details, see https://cloud.google.com/vertex-ai/generative-ai/docs/deprecations/genai-vertexai-sdk.\n",
      "  warning_logs.show_deprecation_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'임베딩 모델 'gemini-embedding-001'을 로드했습니다.\n"
     ]
    }
   ],
   "source": [
    "# Vertex AI 모델 로드\n",
    "print(f\"Vertex AI 임베딩 모델을 로드합니다: {model_name}\")\n",
    "model = TextEmbeddingModel.from_pretrained(model_name)\n",
    "print(f\"\\n'임베딩 모델 '{model_name}'을 로드했습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e425bf1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RETRIEVAL_DOCUMENT', 'QUESTION_ANSWERING', 'FACT_VERIFICATION', 'CODE_RETRIEVAL_QUERY', 'RETRIEVAL_QUERY', 'CLASSIFICATION', 'CLUSTERING', 'SEMANTIC_SIMILARITY']\n"
     ]
    }
   ],
   "source": [
    "# TASK 리스트\n",
    "TASK = [\n",
    "    \"RETRIEVAL_DOCUMENT\",\n",
    "    \"QUESTION_ANSWERING\",\n",
    "    \"FACT_VERIFICATION\",\n",
    "    \"CODE_RETRIEVAL_QUERY\",\n",
    "    \"RETRIEVAL_QUERY\",\n",
    "    \"CLASSIFICATION\",\n",
    "    \"CLUSTERING\",\n",
    "    \"SEMANTIC_SIMILARITY\",\n",
    "]\n",
    "print(TASK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6faa94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "임베딩 결과를 '../Dataset/states/fl_split100k_RETRIEVAL_DOCUMENT.jsonl' 파일에 저장합니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[RETRIEVAL_DOCUMENT] 임베딩 진행률:   0%|          | 343/100000 [33:56<169:32:05,  6.12s/it]"
     ]
    }
   ],
   "source": [
    "# 임베딩 진행\n",
    "# file_mode = \"a\" if start_index > 0 else \"w\"\n",
    "\n",
    "base_file = \"../Dataset/states/fl_split100k\"\n",
    "\n",
    "for task in TASK:\n",
    "    file_mode = \"w\"\n",
    "    start_index = 0\n",
    "    output_file = f\"{base_file}_{task}.jsonl\"\n",
    "    print(f\"\\n임베딩 결과를 '{output_file}' 파일에 저장합니다.\")\n",
    "\n",
    "    with open(output_file, file_mode, encoding=\"utf-8\") as f_out:\n",
    "        for i in tqdm(\n",
    "            range(start_index, total_reviews, BATCH_SIZE),\n",
    "            initial=start_index,\n",
    "            total=total_reviews,\n",
    "            desc=f\"[{task}] 임베딩 진행률\",\n",
    "        ):\n",
    "            batch_texts = review_texts[i : i + BATCH_SIZE]\n",
    "            retries = 0\n",
    "\n",
    "            while retries < MAX_RETRIES:\n",
    "                try:\n",
    "                    req = [TextEmbeddingInput(text, task) for text in batch_texts]\n",
    "\n",
    "                    # 임베딩 모델 call 시 파라미터 지정\n",
    "                    response = model.get_embeddings(\n",
    "                        req,\n",
    "                        auto_truncate=False,\n",
    "                        output_dimensionality=3072,\n",
    "                    )\n",
    "\n",
    "                    # 임베딩 값만 추출\n",
    "                    embeddings = [embedding.values for embedding in response]\n",
    "\n",
    "                    # 임베딩 결과를 데이터프레임에 추가\n",
    "                    batch_df = df_reviews.iloc[i : i + BATCH_SIZE].copy()\n",
    "                    batch_df[\"embedding\"] = embeddings[: len(batch_df)]\n",
    "\n",
    "                    json_lines = batch_df.to_json(\n",
    "                        orient=\"records\", lines=True, force_ascii=False\n",
    "                    )\n",
    "                    f_out.write(json_lines)\n",
    "                    f_out.flush()\n",
    "\n",
    "                    break\n",
    "\n",
    "                # api call 장애발생 핸들링\n",
    "                except exceptions.ResourceExhausted as e:\n",
    "                    retries += 1\n",
    "                    # 할당량 초과시 대기\n",
    "                    print(\n",
    "                        f\"\\n[경고] Quota 초과 (429 에러) (배치 인덱스: {i}). {retries}/{MAX_RETRIES}번째 재시도. {RETRY_DELAY}초 후 다시 시도합니다.\"\n",
    "                    )\n",
    "                    time.sleep(RETRY_DELAY)\n",
    "                except Exception as e:\n",
    "                    # 문제가 있는 배치는 건너뜀\n",
    "                    print(f\"\\n[오류] 처리 불가 (배치 인덱스: {i}): {e}\")\n",
    "                    break\n",
    "\n",
    "            # 재시도 횟수 초과 시 건너뜀\n",
    "            if retries == MAX_RETRIES:\n",
    "                print(f\"[실패] 배치 인덱스 {i}를 {MAX_RETRIES}번 재시도 후 건너뜁니다.\")\n",
    "\n",
    "            time.sleep(DELAY_BETWEEN_REQUESTS)\n",
    "\n",
    "    print(f\"\\n임베딩 결과가 '{output_file}' 파일에 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f218934",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
