{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9718f91e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 20:03:25.602955: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-30 20:03:25.936373: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-08-30 20:03:27.332655: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error,\n",
    "    mean_absolute_error,\n",
    "    mean_absolute_percentage_error,\n",
    ")\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "233a5a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK = [\n",
    "    \"RETRIEVAL_DOCUMENT\",\n",
    "    \"QUESTION_ANSWERING\",\n",
    "    \"FACT_VERIFICATION\",\n",
    "    \"CODE_RETRIEVAL_QUERY\",\n",
    "    \"RETRIEVAL_QUERY\",\n",
    "    \"CLASSIFICATION\",\n",
    "    \"CLUSTERING\",\n",
    "    \"SEMANTIC_SIMILARITY\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e690afcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Dataset/states/fl_split_RETRIEVAL_DOCUMENT.jsonl\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   review_id     10000 non-null  object\n",
      " 1   user_id       10000 non-null  object\n",
      " 2   business_id   10000 non-null  object\n",
      " 3   review_stars  10000 non-null  int64 \n",
      " 4   text          10000 non-null  object\n",
      " 5   embedding     10000 non-null  object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 468.9+ KB\n",
      "전체 데이터셋 크기: 10000\n",
      "6672\n",
      "732\n",
      "전체 데이터 수: 10000\n",
      "학습 데이터 수: 7000 (70.00%)\n",
      "검증 데이터 수: 1000 (10.00%)\n",
      "테스트 데이터 수: 2000 (20.00%)\n",
      "학습 임베딩 데이터 형태: (7000, 3072)\n",
      "검증 임베딩 데이터 형태: (1000, 3072)\n",
      "테스트 임베딩 데이터 형태: (2000, 3072)\n",
      "데이터 type: float32\n",
      "\n",
      "==== [RETRIEVAL_DOCUMENT] 버전 학습 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1756551813.505485   80524 gpu_device.cc:2342] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 8.1050 - mae: 2.2899 - rmse: 2.7456\n",
      "Epoch 1: val_rmse improved from None to 0.58258, saving model to final_best_gemini_model_RETRIEVAL_DOCUMENT_main.keras\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 3.4603 - mae: 1.2884 - rmse: 1.8602 - val_loss: 0.3394 - val_mae: 0.4535 - val_rmse: 0.5826\n",
      "Epoch 2/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.3474 - mae: 0.4640 - rmse: 0.5892\n",
      "Epoch 2: val_rmse improved from 0.58258 to 0.54483, saving model to final_best_gemini_model_RETRIEVAL_DOCUMENT_main.keras\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.3335 - mae: 0.4598 - rmse: 0.5775 - val_loss: 0.2968 - val_mae: 0.4312 - val_rmse: 0.5448\n",
      "Epoch 3/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.2997 - mae: 0.4325 - rmse: 0.5474\n",
      "Epoch 3: val_rmse improved from 0.54483 to 0.54012, saving model to final_best_gemini_model_RETRIEVAL_DOCUMENT_main.keras\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - loss: 0.2925 - mae: 0.4267 - rmse: 0.5408 - val_loss: 0.2917 - val_mae: 0.4202 - val_rmse: 0.5401\n",
      "Epoch 4/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.1829 - mae: 0.3200 - rmse: 0.4275\n",
      "Epoch 4: val_rmse did not improve from 0.54012\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.1771 - mae: 0.3157 - rmse: 0.4209 - val_loss: 0.3328 - val_mae: 0.4519 - val_rmse: 0.5769\n",
      "Epoch 5/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.1124 - mae: 0.2446 - rmse: 0.3353\n",
      "Epoch 5: val_rmse did not improve from 0.54012\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.1160 - mae: 0.2465 - rmse: 0.3405 - val_loss: 0.3386 - val_mae: 0.4620 - val_rmse: 0.5819\n",
      "Epoch 6/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0868 - mae: 0.2034 - rmse: 0.2945\n",
      "Epoch 6: val_rmse did not improve from 0.54012\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0900 - mae: 0.2089 - rmse: 0.3000 - val_loss: 0.3541 - val_mae: 0.4752 - val_rmse: 0.5951\n",
      "Epoch 7/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0718 - mae: 0.1847 - rmse: 0.2680\n",
      "Epoch 7: val_rmse did not improve from 0.54012\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0765 - mae: 0.1920 - rmse: 0.2767 - val_loss: 0.3535 - val_mae: 0.4707 - val_rmse: 0.5946\n",
      "Epoch 8/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0615 - mae: 0.1669 - rmse: 0.2480\n",
      "Epoch 8: val_rmse did not improve from 0.54012\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0640 - mae: 0.1717 - rmse: 0.2530 - val_loss: 0.3680 - val_mae: 0.4803 - val_rmse: 0.6066\n",
      "Epoch 9/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0525 - mae: 0.1531 - rmse: 0.2291\n",
      "Epoch 9: val_rmse did not improve from 0.54012\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.0549 - mae: 0.1585 - rmse: 0.2344 - val_loss: 0.3722 - val_mae: 0.4821 - val_rmse: 0.6101\n",
      "Epoch 10/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0417 - mae: 0.1389 - rmse: 0.2038\n",
      "Epoch 10: val_rmse did not improve from 0.54012\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.0470 - mae: 0.1480 - rmse: 0.2169 - val_loss: 0.3818 - val_mae: 0.4921 - val_rmse: 0.6179\n",
      "Epoch 11/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0373 - mae: 0.1308 - rmse: 0.1932\n",
      "Epoch 11: val_rmse did not improve from 0.54012\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0402 - mae: 0.1367 - rmse: 0.2005 - val_loss: 0.3963 - val_mae: 0.5007 - val_rmse: 0.6295\n",
      "Epoch 12/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0352 - mae: 0.1344 - rmse: 0.1877\n",
      "Epoch 12: val_rmse did not improve from 0.54012\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0353 - mae: 0.1310 - rmse: 0.1879 - val_loss: 0.3851 - val_mae: 0.4948 - val_rmse: 0.6206\n",
      "Epoch 13/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0296 - mae: 0.1212 - rmse: 0.1720\n",
      "Epoch 13: val_rmse did not improve from 0.54012\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0307 - mae: 0.1240 - rmse: 0.1751 - val_loss: 0.4040 - val_mae: 0.5083 - val_rmse: 0.6356\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "RETRIEVAL_DOCUMENT버전 모델 성능 평가\n",
      "MSE: 0.3008\n",
      "RMSE: 0.5484\n",
      "MAE: 0.4288\n",
      "MAPE: 15.23%\n",
      "\n",
      "============================================================\n",
      "                   실험 1/5 시작\n",
      "============================================================\n",
      "실험 1: 모델 학습 완료.\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "실험 1 결과 - RMSE: 0.5468, MAE: 0.4307, MAPE: 15.43%\n",
      "\n",
      "============================================================\n",
      "                   실험 2/5 시작\n",
      "============================================================\n",
      "실험 2: 모델 학습 완료.\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "실험 2 결과 - RMSE: 0.5531, MAE: 0.4458, MAPE: 15.37%\n",
      "\n",
      "============================================================\n",
      "                   실험 3/5 시작\n",
      "============================================================\n",
      "실험 3: 모델 학습 완료.\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "실험 3 결과 - RMSE: 0.5613, MAE: 0.4523, MAPE: 15.22%\n",
      "\n",
      "============================================================\n",
      "                   실험 4/5 시작\n",
      "============================================================\n",
      "실험 4: 모델 학습 완료.\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "실험 4 결과 - RMSE: 0.5530, MAE: 0.4308, MAPE: 15.50%\n",
      "\n",
      "============================================================\n",
      "                   실험 5/5 시작\n",
      "============================================================\n",
      "실험 5: 모델 학습 완료.\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "실험 5 결과 - RMSE: 0.5504, MAE: 0.4324, MAPE: 15.59%\n",
      "\n",
      "============================================================\n",
      "RETRIEVAL_DOCUMENT버전 모델 성능 통계 (5회 실행 평균)\n",
      "============================================================\n",
      "평균 MSE: 0.3057 (표준편차: 0.0053)\n",
      "평균 RMSE: 0.5529 (표준편차: 0.0048)\n",
      "평균 MAE : 0.4384 (표준편차: 0.0090)\n",
      "평균 MAPE: 15.42% (표준편차: 0.12)\n",
      "============================================================\n",
      "--- [RETRIEVAL_DOCUMENT] 버전 최종 성능 요약 테이블 ---\n",
      "csv로 저장 완료\n",
      "../Dataset/states/fl_split_QUESTION_ANSWERING.jsonl\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   review_id     10000 non-null  object\n",
      " 1   user_id       10000 non-null  object\n",
      " 2   business_id   10000 non-null  object\n",
      " 3   review_stars  10000 non-null  int64 \n",
      " 4   text          10000 non-null  object\n",
      " 5   embedding     10000 non-null  object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 468.9+ KB\n",
      "전체 데이터셋 크기: 10000\n",
      "6672\n",
      "732\n",
      "전체 데이터 수: 10000\n",
      "학습 데이터 수: 7000 (70.00%)\n",
      "검증 데이터 수: 1000 (10.00%)\n",
      "테스트 데이터 수: 2000 (20.00%)\n",
      "학습 임베딩 데이터 형태: (7000, 3072)\n",
      "검증 임베딩 데이터 형태: (1000, 3072)\n",
      "테스트 임베딩 데이터 형태: (2000, 3072)\n",
      "데이터 type: float32\n",
      "\n",
      "==== [QUESTION_ANSWERING] 버전 학습 시작\n",
      "Epoch 1/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 3.9451 - mae: 1.4923 - rmse: 1.8826\n",
      "Epoch 1: val_rmse improved from None to 0.58694, saving model to final_best_gemini_model_QUESTION_ANSWERING_main.keras\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 45ms/step - loss: 1.6267 - mae: 0.9055 - rmse: 1.2754 - val_loss: 0.3445 - val_mae: 0.4528 - val_rmse: 0.5869\n",
      "Epoch 2/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.3274 - mae: 0.4547 - rmse: 0.5721\n",
      "Epoch 2: val_rmse improved from 0.58694 to 0.55645, saving model to final_best_gemini_model_QUESTION_ANSWERING_main.keras\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - loss: 0.3117 - mae: 0.4422 - rmse: 0.5583 - val_loss: 0.3096 - val_mae: 0.4340 - val_rmse: 0.5565\n",
      "Epoch 3/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.2103 - mae: 0.3513 - rmse: 0.4581\n",
      "Epoch 3: val_rmse did not improve from 0.55645\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.1969 - mae: 0.3394 - rmse: 0.4437 - val_loss: 0.3395 - val_mae: 0.4585 - val_rmse: 0.5826\n",
      "Epoch 4/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.1196 - mae: 0.2537 - rmse: 0.3454\n",
      "Epoch 4: val_rmse did not improve from 0.55645\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.1175 - mae: 0.2535 - rmse: 0.3428 - val_loss: 0.3642 - val_mae: 0.4763 - val_rmse: 0.6035\n",
      "Epoch 5/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0764 - mae: 0.1988 - rmse: 0.2764\n",
      "Epoch 5: val_rmse did not improve from 0.55645\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.0806 - mae: 0.2035 - rmse: 0.2839 - val_loss: 0.3672 - val_mae: 0.4811 - val_rmse: 0.6060\n",
      "Epoch 6/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0591 - mae: 0.1675 - rmse: 0.2430\n",
      "Epoch 6: val_rmse did not improve from 0.55645\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.0598 - mae: 0.1724 - rmse: 0.2445 - val_loss: 0.3833 - val_mae: 0.4940 - val_rmse: 0.6191\n",
      "Epoch 7/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0436 - mae: 0.1476 - rmse: 0.2089\n",
      "Epoch 7: val_rmse did not improve from 0.55645\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.0445 - mae: 0.1507 - rmse: 0.2109 - val_loss: 0.3823 - val_mae: 0.4948 - val_rmse: 0.6183\n",
      "Epoch 8/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0311 - mae: 0.1296 - rmse: 0.1764\n",
      "Epoch 8: val_rmse did not improve from 0.55645\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.0332 - mae: 0.1338 - rmse: 0.1822 - val_loss: 0.3929 - val_mae: 0.4994 - val_rmse: 0.6268\n",
      "Epoch 9/50\n",
      "\u001b[1m42/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0232 - mae: 0.1150 - rmse: 0.1522\n",
      "Epoch 9: val_rmse did not improve from 0.55645\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m-0s\u001b[0m -9246us/step - loss: 0.0251 - mae: 0.1195 - rmse: 0.1585 - val_loss: 0.3874 - val_mae: 0.4950 - val_rmse: 0.6225\n",
      "Epoch 10/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0199 - mae: 0.1086 - rmse: 0.1411\n",
      "Epoch 10: val_rmse did not improve from 0.55645\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.0207 - mae: 0.1099 - rmse: 0.1440 - val_loss: 0.3893 - val_mae: 0.4997 - val_rmse: 0.6239\n",
      "Epoch 11/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0149 - mae: 0.0924 - rmse: 0.1219\n",
      "Epoch 11: val_rmse did not improve from 0.55645\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.0156 - mae: 0.0947 - rmse: 0.1248 - val_loss: 0.3786 - val_mae: 0.4927 - val_rmse: 0.6153\n",
      "Epoch 12/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0109 - mae: 0.0782 - rmse: 0.1046\n",
      "Epoch 12: val_rmse did not improve from 0.55645\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0113 - mae: 0.0794 - rmse: 0.1061 - val_loss: 0.3863 - val_mae: 0.4985 - val_rmse: 0.6215\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "QUESTION_ANSWERING버전 모델 성능 평가\n",
      "MSE: 0.3147\n",
      "RMSE: 0.5610\n",
      "MAE: 0.4381\n",
      "MAPE: 15.79%\n",
      "\n",
      "============================================================\n",
      "                   실험 1/5 시작\n",
      "============================================================\n",
      "실험 1: 모델 학습 완료.\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "실험 1 결과 - RMSE: 0.5672, MAE: 0.4416, MAPE: 16.16%\n",
      "\n",
      "============================================================\n",
      "                   실험 2/5 시작\n",
      "============================================================\n",
      "실험 2: 모델 학습 완료.\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "실험 2 결과 - RMSE: 0.5602, MAE: 0.4376, MAPE: 15.59%\n",
      "\n",
      "============================================================\n",
      "                   실험 3/5 시작\n",
      "============================================================\n",
      "실험 3: 모델 학습 완료.\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "실험 3 결과 - RMSE: 0.5761, MAE: 0.4565, MAPE: 15.87%\n",
      "\n",
      "============================================================\n",
      "                   실험 4/5 시작\n",
      "============================================================\n",
      "실험 4: 모델 학습 완료.\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "실험 4 결과 - RMSE: 0.5610, MAE: 0.4377, MAPE: 15.75%\n",
      "\n",
      "============================================================\n",
      "                   실험 5/5 시작\n",
      "============================================================\n",
      "실험 5: 모델 학습 완료.\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "실험 5 결과 - RMSE: 0.5720, MAE: 0.4568, MAPE: 15.79%\n",
      "\n",
      "============================================================\n",
      "QUESTION_ANSWERING버전 모델 성능 통계 (5회 실행 평균)\n",
      "============================================================\n",
      "평균 MSE: 0.3219 (표준편차: 0.0070)\n",
      "평균 RMSE: 0.5673 (표준편차: 0.0062)\n",
      "평균 MAE : 0.4460 (표준편차: 0.0088)\n",
      "평균 MAPE: 15.83% (표준편차: 0.19)\n",
      "============================================================\n",
      "--- [QUESTION_ANSWERING] 버전 최종 성능 요약 테이블 ---\n",
      "csv로 저장 완료\n",
      "../Dataset/states/fl_split_FACT_VERIFICATION.jsonl\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   review_id     10000 non-null  object\n",
      " 1   user_id       10000 non-null  object\n",
      " 2   business_id   10000 non-null  object\n",
      " 3   review_stars  10000 non-null  int64 \n",
      " 4   text          10000 non-null  object\n",
      " 5   embedding     10000 non-null  object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 468.9+ KB\n",
      "전체 데이터셋 크기: 10000\n",
      "6672\n",
      "732\n",
      "전체 데이터 수: 10000\n",
      "학습 데이터 수: 7000 (70.00%)\n",
      "검증 데이터 수: 1000 (10.00%)\n",
      "테스트 데이터 수: 2000 (20.00%)\n",
      "학습 임베딩 데이터 형태: (7000, 3072)\n",
      "검증 임베딩 데이터 형태: (1000, 3072)\n",
      "테스트 임베딩 데이터 형태: (2000, 3072)\n",
      "데이터 type: float32\n",
      "\n",
      "==== [FACT_VERIFICATION] 버전 학습 시작\n",
      "Epoch 1/50\n",
      "\u001b[1m15/55\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 154ms/step - loss: 11.7961 - mae: 3.0810 - rmse: 3.3955\n",
      "Epoch 1: val_rmse improved from None to 0.60025, saving model to final_best_gemini_model_FACT_VERIFICATION_main.keras\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 2.4178 - mae: 1.0782 - rmse: 1.5549 - val_loss: 0.3603 - val_mae: 0.4734 - val_rmse: 0.6002\n",
      "Epoch 2/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.3516 - mae: 0.4699 - rmse: 0.5929\n",
      "Epoch 2: val_rmse improved from 0.60025 to 0.56865, saving model to final_best_gemini_model_FACT_VERIFICATION_main.keras\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.3445 - mae: 0.4648 - rmse: 0.5869 - val_loss: 0.3234 - val_mae: 0.4422 - val_rmse: 0.5686\n",
      "Epoch 3/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.2749 - mae: 0.4105 - rmse: 0.5242\n",
      "Epoch 3: val_rmse did not improve from 0.56865\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.2585 - mae: 0.3946 - rmse: 0.5084 - val_loss: 0.3798 - val_mae: 0.4864 - val_rmse: 0.6163\n",
      "Epoch 4/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.1455 - mae: 0.2843 - rmse: 0.3813\n",
      "Epoch 4: val_rmse did not improve from 0.56865\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.1471 - mae: 0.2880 - rmse: 0.3836 - val_loss: 0.3550 - val_mae: 0.4727 - val_rmse: 0.5958\n",
      "Epoch 5/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0953 - mae: 0.2213 - rmse: 0.3086\n",
      "Epoch 5: val_rmse did not improve from 0.56865\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.1022 - mae: 0.2287 - rmse: 0.3197 - val_loss: 0.3794 - val_mae: 0.4854 - val_rmse: 0.6160\n",
      "Epoch 6/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0773 - mae: 0.1898 - rmse: 0.2779\n",
      "Epoch 6: val_rmse did not improve from 0.56865\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0813 - mae: 0.1970 - rmse: 0.2851 - val_loss: 0.3931 - val_mae: 0.4945 - val_rmse: 0.6270\n",
      "Epoch 7/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0618 - mae: 0.1710 - rmse: 0.2484\n",
      "Epoch 7: val_rmse did not improve from 0.56865\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.0677 - mae: 0.1787 - rmse: 0.2601 - val_loss: 0.3947 - val_mae: 0.4960 - val_rmse: 0.6282\n",
      "Epoch 8/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0527 - mae: 0.1591 - rmse: 0.2295\n",
      "Epoch 8: val_rmse did not improve from 0.56865\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0575 - mae: 0.1648 - rmse: 0.2397 - val_loss: 0.4200 - val_mae: 0.5169 - val_rmse: 0.6481\n",
      "Epoch 9/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0436 - mae: 0.1469 - rmse: 0.2086\n",
      "Epoch 9: val_rmse did not improve from 0.56865\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.0487 - mae: 0.1538 - rmse: 0.2206 - val_loss: 0.4133 - val_mae: 0.5095 - val_rmse: 0.6429\n",
      "Epoch 10/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0392 - mae: 0.1411 - rmse: 0.1979\n",
      "Epoch 10: val_rmse did not improve from 0.56865\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.0407 - mae: 0.1435 - rmse: 0.2018 - val_loss: 0.4198 - val_mae: 0.5144 - val_rmse: 0.6479\n",
      "Epoch 11/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0296 - mae: 0.1257 - rmse: 0.1720\n",
      "Epoch 11: val_rmse did not improve from 0.56865\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.0321 - mae: 0.1298 - rmse: 0.1793 - val_loss: 0.4295 - val_mae: 0.5205 - val_rmse: 0.6554\n",
      "Epoch 12/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0230 - mae: 0.1088 - rmse: 0.1515\n",
      "Epoch 12: val_rmse did not improve from 0.56865\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.0237 - mae: 0.1107 - rmse: 0.1540 - val_loss: 0.4236 - val_mae: 0.5160 - val_rmse: 0.6508\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "FACT_VERIFICATION버전 모델 성능 평가\n",
      "MSE: 0.3300\n",
      "RMSE: 0.5745\n",
      "MAE: 0.4522\n",
      "MAPE: 16.59%\n",
      "\n",
      "============================================================\n",
      "                   실험 1/5 시작\n",
      "============================================================\n",
      "실험 1: 모델 학습 완료.\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "실험 1 결과 - RMSE: 0.5927, MAE: 0.4680, MAPE: 17.05%\n",
      "\n",
      "============================================================\n",
      "                   실험 2/5 시작\n",
      "============================================================\n",
      "실험 2: 모델 학습 완료.\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "실험 2 결과 - RMSE: 0.5723, MAE: 0.4527, MAPE: 15.94%\n",
      "\n",
      "============================================================\n",
      "                   실험 3/5 시작\n",
      "============================================================\n",
      "실험 3: 모델 학습 완료.\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "실험 3 결과 - RMSE: 0.5665, MAE: 0.4464, MAPE: 15.69%\n",
      "\n",
      "============================================================\n",
      "                   실험 4/5 시작\n",
      "============================================================\n",
      "실험 4: 모델 학습 완료.\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "실험 4 결과 - RMSE: 0.5586, MAE: 0.4369, MAPE: 15.95%\n",
      "\n",
      "============================================================\n",
      "                   실험 5/5 시작\n",
      "============================================================\n",
      "실험 5: 모델 학습 완료.\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m-4s\u001b[0m 5ms/step\n",
      "실험 5 결과 - RMSE: 0.5727, MAE: 0.4498, MAPE: 15.67%\n",
      "\n",
      "============================================================\n",
      "FACT_VERIFICATION버전 모델 성능 통계 (5회 실행 평균)\n",
      "============================================================\n",
      "평균 MSE: 0.3280 (표준편차: 0.0130)\n",
      "평균 RMSE: 0.5726 (표준편차: 0.0113)\n",
      "평균 MAE : 0.4508 (표준편차: 0.0101)\n",
      "평균 MAPE: 16.06% (표준편차: 0.51)\n",
      "============================================================\n",
      "--- [FACT_VERIFICATION] 버전 최종 성능 요약 테이블 ---\n",
      "csv로 저장 완료\n",
      "../Dataset/states/fl_split_CODE_RETRIEVAL_QUERY.jsonl\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   review_id     10000 non-null  object\n",
      " 1   user_id       10000 non-null  object\n",
      " 2   business_id   10000 non-null  object\n",
      " 3   review_stars  10000 non-null  int64 \n",
      " 4   text          10000 non-null  object\n",
      " 5   embedding     10000 non-null  object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 468.9+ KB\n",
      "전체 데이터셋 크기: 10000\n",
      "6672\n",
      "732\n",
      "전체 데이터 수: 10000\n",
      "학습 데이터 수: 7000 (70.00%)\n",
      "검증 데이터 수: 1000 (10.00%)\n",
      "테스트 데이터 수: 2000 (20.00%)\n",
      "학습 임베딩 데이터 형태: (7000, 3072)\n",
      "검증 임베딩 데이터 형태: (1000, 3072)\n",
      "테스트 임베딩 데이터 형태: (2000, 3072)\n",
      "데이터 type: float32\n",
      "\n",
      "==== [CODE_RETRIEVAL_QUERY] 버전 학습 시작\n",
      "Epoch 1/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 4.5370 - mae: 1.5506 - rmse: 1.9973\n",
      "Epoch 1: val_rmse improved from None to 0.54895, saving model to final_best_gemini_model_CODE_RETRIEVAL_QUERY_main.keras\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - loss: 1.6977 - mae: 0.8741 - rmse: 1.3030 - val_loss: 0.3013 - val_mae: 0.4290 - val_rmse: 0.5489\n",
      "Epoch 2/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.3033 - mae: 0.4342 - rmse: 0.5506\n",
      "Epoch 2: val_rmse improved from 0.54895 to 0.53293, saving model to final_best_gemini_model_CODE_RETRIEVAL_QUERY_main.keras\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.2966 - mae: 0.4258 - rmse: 0.5446 - val_loss: 0.2840 - val_mae: 0.4180 - val_rmse: 0.5329\n",
      "Epoch 3/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.2349 - mae: 0.3686 - rmse: 0.4844\n",
      "Epoch 3: val_rmse did not improve from 0.53293\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.2165 - mae: 0.3539 - rmse: 0.4652 - val_loss: 0.3183 - val_mae: 0.4523 - val_rmse: 0.5642\n",
      "Epoch 4/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.1194 - mae: 0.2559 - rmse: 0.3454\n",
      "Epoch 4: val_rmse did not improve from 0.53293\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.1269 - mae: 0.2620 - rmse: 0.3562 - val_loss: 0.3381 - val_mae: 0.4707 - val_rmse: 0.5814\n",
      "Epoch 5/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0843 - mae: 0.2043 - rmse: 0.2903\n",
      "Epoch 5: val_rmse did not improve from 0.53293\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0887 - mae: 0.2090 - rmse: 0.2979 - val_loss: 0.3446 - val_mae: 0.4679 - val_rmse: 0.5870\n",
      "Epoch 6/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0625 - mae: 0.1733 - rmse: 0.2498\n",
      "Epoch 6: val_rmse did not improve from 0.53293\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.0703 - mae: 0.1851 - rmse: 0.2651 - val_loss: 0.3759 - val_mae: 0.4970 - val_rmse: 0.6131\n",
      "Epoch 7/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0518 - mae: 0.1618 - rmse: 0.2276\n",
      "Epoch 7: val_rmse did not improve from 0.53293\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0560 - mae: 0.1693 - rmse: 0.2366 - val_loss: 0.3657 - val_mae: 0.4851 - val_rmse: 0.6048\n",
      "Epoch 8/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0417 - mae: 0.1450 - rmse: 0.2043\n",
      "Epoch 8: val_rmse did not improve from 0.53293\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0421 - mae: 0.1455 - rmse: 0.2051 - val_loss: 0.3719 - val_mae: 0.4845 - val_rmse: 0.6098\n",
      "Epoch 9/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0299 - mae: 0.1252 - rmse: 0.1728\n",
      "Epoch 9: val_rmse did not improve from 0.53293\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.0301 - mae: 0.1259 - rmse: 0.1734 - val_loss: 0.3716 - val_mae: 0.4905 - val_rmse: 0.6096\n",
      "Epoch 10/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0232 - mae: 0.1112 - rmse: 0.1523\n",
      "Epoch 10: val_rmse did not improve from 0.53293\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.0229 - mae: 0.1112 - rmse: 0.1515 - val_loss: 0.3727 - val_mae: 0.4930 - val_rmse: 0.6105\n",
      "Epoch 11/50\n",
      "\u001b[1m51/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0173 - mae: 0.0975 - rmse: 0.1314\n",
      "Epoch 11: val_rmse did not improve from 0.53293\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m-0s\u001b[0m -8847us/step - loss: 0.0186 - mae: 0.1006 - rmse: 0.1364 - val_loss: 0.3744 - val_mae: 0.4918 - val_rmse: 0.6119\n",
      "Epoch 12/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0137 - mae: 0.0859 - rmse: 0.1169\n",
      "Epoch 12: val_rmse did not improve from 0.53293\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.0144 - mae: 0.0878 - rmse: 0.1198 - val_loss: 0.3668 - val_mae: 0.4822 - val_rmse: 0.6057\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "CODE_RETRIEVAL_QUERY버전 모델 성능 평가\n",
      "MSE: 0.3019\n",
      "RMSE: 0.5494\n",
      "MAE: 0.4346\n",
      "MAPE: 15.69%\n",
      "\n",
      "============================================================\n",
      "                   실험 1/5 시작\n",
      "============================================================\n",
      "실험 1: 모델 학습 완료.\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "실험 1 결과 - RMSE: 0.5582, MAE: 0.4275, MAPE: 15.91%\n",
      "\n",
      "============================================================\n",
      "                   실험 2/5 시작\n",
      "============================================================\n",
      "실험 2: 모델 학습 완료.\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "실험 2 결과 - RMSE: 0.5509, MAE: 0.4311, MAPE: 15.26%\n",
      "\n",
      "============================================================\n",
      "                   실험 3/5 시작\n",
      "============================================================\n",
      "실험 3: 모델 학습 완료.\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "실험 3 결과 - RMSE: 0.5460, MAE: 0.4161, MAPE: 14.51%\n",
      "\n",
      "============================================================\n",
      "                   실험 4/5 시작\n",
      "============================================================\n",
      "실험 4: 모델 학습 완료.\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "실험 4 결과 - RMSE: 0.5535, MAE: 0.4426, MAPE: 15.32%\n",
      "\n",
      "============================================================\n",
      "                   실험 5/5 시작\n",
      "============================================================\n",
      "실험 5: 모델 학습 완료.\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "실험 5 결과 - RMSE: 0.5611, MAE: 0.4536, MAPE: 15.46%\n",
      "\n",
      "============================================================\n",
      "CODE_RETRIEVAL_QUERY버전 모델 성능 통계 (5회 실행 평균)\n",
      "============================================================\n",
      "평균 MSE: 0.3069 (표준편차: 0.0059)\n",
      "평균 RMSE: 0.5540 (표준편차: 0.0053)\n",
      "평균 MAE : 0.4342 (표준편차: 0.0129)\n",
      "평균 MAPE: 15.29% (표준편차: 0.45)\n",
      "============================================================\n",
      "--- [CODE_RETRIEVAL_QUERY] 버전 최종 성능 요약 테이블 ---\n",
      "csv로 저장 완료\n",
      "../Dataset/states/fl_split_RETRIEVAL_QUERY.jsonl\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   review_id     10000 non-null  object\n",
      " 1   user_id       10000 non-null  object\n",
      " 2   business_id   10000 non-null  object\n",
      " 3   review_stars  10000 non-null  int64 \n",
      " 4   text          10000 non-null  object\n",
      " 5   embedding     10000 non-null  object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 468.9+ KB\n",
      "전체 데이터셋 크기: 10000\n",
      "6672\n",
      "732\n",
      "전체 데이터 수: 10000\n",
      "학습 데이터 수: 7000 (70.00%)\n",
      "검증 데이터 수: 1000 (10.00%)\n",
      "테스트 데이터 수: 2000 (20.00%)\n",
      "학습 임베딩 데이터 형태: (7000, 3072)\n",
      "검증 임베딩 데이터 형태: (1000, 3072)\n",
      "테스트 임베딩 데이터 형태: (2000, 3072)\n",
      "데이터 type: float32\n",
      "\n",
      "==== [RETRIEVAL_QUERY] 버전 학습 시작\n",
      "Epoch 1/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 4.1388 - mae: 1.4819 - rmse: 1.9054\n",
      "Epoch 1: val_rmse improved from None to 0.57023, saving model to final_best_gemini_model_RETRIEVAL_QUERY_main.keras\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 48ms/step - loss: 1.5655 - mae: 0.8515 - rmse: 1.2512 - val_loss: 0.3252 - val_mae: 0.4611 - val_rmse: 0.5702\n",
      "Epoch 2/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.3215 - mae: 0.4518 - rmse: 0.5667\n",
      "Epoch 2: val_rmse improved from 0.57023 to 0.52352, saving model to final_best_gemini_model_RETRIEVAL_QUERY_main.keras\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.2940 - mae: 0.4262 - rmse: 0.5423 - val_loss: 0.2741 - val_mae: 0.4076 - val_rmse: 0.5235\n",
      "Epoch 3/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.1927 - mae: 0.3348 - rmse: 0.4388\n",
      "Epoch 3: val_rmse did not improve from 0.52352\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.1891 - mae: 0.3301 - rmse: 0.4349 - val_loss: 0.3090 - val_mae: 0.4318 - val_rmse: 0.5559\n",
      "Epoch 4/50\n",
      "\u001b[1m18/55\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 129ms/step - loss: 0.1169 - mae: 0.2537 - rmse: 0.3418\n",
      "Epoch 4: val_rmse did not improve from 0.52352\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m-0s\u001b[0m -9270us/step - loss: 0.1124 - mae: 0.2478 - rmse: 0.3352 - val_loss: 0.3345 - val_mae: 0.4572 - val_rmse: 0.5784\n",
      "Epoch 5/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0689 - mae: 0.1860 - rmse: 0.2621\n",
      "Epoch 5: val_rmse did not improve from 0.52352\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.0756 - mae: 0.1961 - rmse: 0.2750 - val_loss: 0.3433 - val_mae: 0.4660 - val_rmse: 0.5859\n",
      "Epoch 6/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0543 - mae: 0.1646 - rmse: 0.2330\n",
      "Epoch 6: val_rmse did not improve from 0.52352\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0570 - mae: 0.1706 - rmse: 0.2387 - val_loss: 0.3542 - val_mae: 0.4743 - val_rmse: 0.5951\n",
      "Epoch 7/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0421 - mae: 0.1481 - rmse: 0.2051\n",
      "Epoch 7: val_rmse did not improve from 0.52352\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0426 - mae: 0.1499 - rmse: 0.2063 - val_loss: 0.3573 - val_mae: 0.4734 - val_rmse: 0.5978\n",
      "Epoch 8/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0270 - mae: 0.1188 - rmse: 0.1643\n",
      "Epoch 8: val_rmse did not improve from 0.52352\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.0289 - mae: 0.1229 - rmse: 0.1700 - val_loss: 0.3644 - val_mae: 0.4783 - val_rmse: 0.6037\n",
      "Epoch 9/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0181 - mae: 0.1005 - rmse: 0.1342\n",
      "Epoch 9: val_rmse did not improve from 0.52352\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.0207 - mae: 0.1063 - rmse: 0.1438 - val_loss: 0.3567 - val_mae: 0.4740 - val_rmse: 0.5973\n",
      "Epoch 10/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0196 - mae: 0.1069 - rmse: 0.1400\n",
      "Epoch 10: val_rmse did not improve from 0.52352\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.0194 - mae: 0.1055 - rmse: 0.1392 - val_loss: 0.3523 - val_mae: 0.4702 - val_rmse: 0.5936\n",
      "Epoch 11/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0145 - mae: 0.0914 - rmse: 0.1203\n",
      "Epoch 11: val_rmse did not improve from 0.52352\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.0156 - mae: 0.0948 - rmse: 0.1249 - val_loss: 0.3658 - val_mae: 0.4815 - val_rmse: 0.6048\n",
      "Epoch 12/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0107 - mae: 0.0780 - rmse: 0.1033\n",
      "Epoch 12: val_rmse did not improve from 0.52352\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.0115 - mae: 0.0805 - rmse: 0.1074 - val_loss: 0.3539 - val_mae: 0.4680 - val_rmse: 0.5949\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "RETRIEVAL_QUERY버전 모델 성능 평가\n",
      "MSE: 0.2853\n",
      "RMSE: 0.5341\n",
      "MAE: 0.4154\n",
      "MAPE: 14.34%\n",
      "\n",
      "============================================================\n",
      "                   실험 1/5 시작\n",
      "============================================================\n",
      "실험 1: 모델 학습 완료.\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "실험 1 결과 - RMSE: 0.5435, MAE: 0.4322, MAPE: 15.03%\n",
      "\n",
      "============================================================\n",
      "                   실험 2/5 시작\n",
      "============================================================\n",
      "실험 2: 모델 학습 완료.\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "실험 2 결과 - RMSE: 0.5480, MAE: 0.4250, MAPE: 15.72%\n",
      "\n",
      "============================================================\n",
      "                   실험 3/5 시작\n",
      "============================================================\n",
      "실험 3: 모델 학습 완료.\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "실험 3 결과 - RMSE: 0.5439, MAE: 0.4240, MAPE: 15.44%\n",
      "\n",
      "============================================================\n",
      "                   실험 4/5 시작\n",
      "============================================================\n",
      "실험 4: 모델 학습 완료.\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "실험 4 결과 - RMSE: 0.5412, MAE: 0.4234, MAPE: 15.16%\n",
      "\n",
      "============================================================\n",
      "                   실험 5/5 시작\n",
      "============================================================\n",
      "실험 5: 모델 학습 완료.\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "실험 5 결과 - RMSE: 0.5388, MAE: 0.4247, MAPE: 14.64%\n",
      "\n",
      "============================================================\n",
      "RETRIEVAL_QUERY버전 모델 성능 통계 (5회 실행 평균)\n",
      "============================================================\n",
      "평균 MSE: 0.2949 (표준편차: 0.0034)\n",
      "평균 RMSE: 0.5431 (표준편차: 0.0031)\n",
      "평균 MAE : 0.4258 (표준편차: 0.0032)\n",
      "평균 MAPE: 15.20% (표준편차: 0.37)\n",
      "============================================================\n",
      "--- [RETRIEVAL_QUERY] 버전 최종 성능 요약 테이블 ---\n",
      "csv로 저장 완료\n",
      "../Dataset/states/fl_split_CLASSIFICATION.jsonl\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   review_id     10000 non-null  object\n",
      " 1   user_id       10000 non-null  object\n",
      " 2   business_id   10000 non-null  object\n",
      " 3   review_stars  10000 non-null  int64 \n",
      " 4   text          10000 non-null  object\n",
      " 5   embedding     10000 non-null  object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 468.9+ KB\n",
      "전체 데이터셋 크기: 10000\n",
      "6672\n",
      "732\n",
      "전체 데이터 수: 10000\n",
      "학습 데이터 수: 7000 (70.00%)\n",
      "검증 데이터 수: 1000 (10.00%)\n",
      "테스트 데이터 수: 2000 (20.00%)\n",
      "학습 임베딩 데이터 형태: (7000, 3072)\n",
      "검증 임베딩 데이터 형태: (1000, 3072)\n",
      "테스트 임베딩 데이터 형태: (2000, 3072)\n",
      "데이터 type: float32\n",
      "\n",
      "==== [CLASSIFICATION] 버전 학습 시작\n",
      "Epoch 1/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 6.3444 - mae: 1.9636 - rmse: 2.4077\n",
      "Epoch 1: val_rmse improved from None to 0.58977, saving model to final_best_gemini_model_CLASSIFICATION_main.keras\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 46ms/step - loss: 2.5807 - mae: 1.1066 - rmse: 1.6065 - val_loss: 0.3478 - val_mae: 0.4963 - val_rmse: 0.5898\n",
      "Epoch 2/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.3367 - mae: 0.4613 - rmse: 0.5795\n",
      "Epoch 2: val_rmse improved from 0.58977 to 0.53338, saving model to final_best_gemini_model_CLASSIFICATION_main.keras\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.3087 - mae: 0.4339 - rmse: 0.5556 - val_loss: 0.2845 - val_mae: 0.4064 - val_rmse: 0.5334\n",
      "Epoch 3/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.2437 - mae: 0.3787 - rmse: 0.4934\n",
      "Epoch 3: val_rmse did not improve from 0.53338\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.2242 - mae: 0.3621 - rmse: 0.4735 - val_loss: 0.3211 - val_mae: 0.4488 - val_rmse: 0.5666\n",
      "Epoch 4/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.1373 - mae: 0.2693 - rmse: 0.3704\n",
      "Epoch 4: val_rmse did not improve from 0.53338\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.1352 - mae: 0.2696 - rmse: 0.3676 - val_loss: 0.3220 - val_mae: 0.4427 - val_rmse: 0.5674\n",
      "Epoch 5/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0971 - mae: 0.2156 - rmse: 0.3116\n",
      "Epoch 5: val_rmse did not improve from 0.53338\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.0971 - mae: 0.2172 - rmse: 0.3116 - val_loss: 0.3268 - val_mae: 0.4530 - val_rmse: 0.5717\n",
      "Epoch 6/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0771 - mae: 0.1873 - rmse: 0.2776\n",
      "Epoch 6: val_rmse did not improve from 0.53338\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0790 - mae: 0.1914 - rmse: 0.2811 - val_loss: 0.3596 - val_mae: 0.4791 - val_rmse: 0.5997\n",
      "Epoch 7/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0602 - mae: 0.1691 - rmse: 0.2449\n",
      "Epoch 7: val_rmse did not improve from 0.53338\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0692 - mae: 0.1802 - rmse: 0.2630 - val_loss: 0.3507 - val_mae: 0.4659 - val_rmse: 0.5922\n",
      "Epoch 8/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0547 - mae: 0.1621 - rmse: 0.2339\n",
      "Epoch 8: val_rmse did not improve from 0.53338\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0584 - mae: 0.1668 - rmse: 0.2417 - val_loss: 0.3562 - val_mae: 0.4765 - val_rmse: 0.5968\n",
      "Epoch 9/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0459 - mae: 0.1492 - rmse: 0.2143\n",
      "Epoch 9: val_rmse did not improve from 0.53338\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.0481 - mae: 0.1511 - rmse: 0.2192 - val_loss: 0.3755 - val_mae: 0.4858 - val_rmse: 0.6128\n",
      "Epoch 10/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0337 - mae: 0.1274 - rmse: 0.1836\n",
      "Epoch 10: val_rmse did not improve from 0.53338\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.0364 - mae: 0.1317 - rmse: 0.1907 - val_loss: 0.3661 - val_mae: 0.4830 - val_rmse: 0.6051\n",
      "Epoch 11/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0255 - mae: 0.1104 - rmse: 0.1595\n",
      "Epoch 11: val_rmse did not improve from 0.53338\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.0277 - mae: 0.1150 - rmse: 0.1664 - val_loss: 0.3789 - val_mae: 0.4901 - val_rmse: 0.6156\n",
      "Epoch 12/50\n",
      "\u001b[1m54/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0217 - mae: 0.1039 - rmse: 0.1471\n",
      "Epoch 12: val_rmse did not improve from 0.53338\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 64ms/step - loss: 0.0221 - mae: 0.1067 - rmse: 0.1486 - val_loss: 0.3698 - val_mae: 0.4827 - val_rmse: 0.6081\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "CLASSIFICATION버전 모델 성능 평가\n",
      "MSE: 0.3002\n",
      "RMSE: 0.5479\n",
      "MAE: 0.4239\n",
      "MAPE: 15.76%\n",
      "\n",
      "============================================================\n",
      "                   실험 1/5 시작\n",
      "============================================================\n",
      "실험 1: 모델 학습 완료.\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "실험 1 결과 - RMSE: 0.5406, MAE: 0.4150, MAPE: 15.28%\n",
      "\n",
      "============================================================\n",
      "                   실험 2/5 시작\n",
      "============================================================\n",
      "실험 2: 모델 학습 완료.\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "실험 2 결과 - RMSE: 0.5507, MAE: 0.4481, MAPE: 15.25%\n",
      "\n",
      "============================================================\n",
      "                   실험 3/5 시작\n",
      "============================================================\n",
      "실험 3: 모델 학습 완료.\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "실험 3 결과 - RMSE: 0.5391, MAE: 0.4311, MAPE: 14.91%\n",
      "\n",
      "============================================================\n",
      "                   실험 4/5 시작\n",
      "============================================================\n",
      "실험 4: 모델 학습 완료.\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "실험 4 결과 - RMSE: 0.5457, MAE: 0.4367, MAPE: 14.81%\n",
      "\n",
      "============================================================\n",
      "                   실험 5/5 시작\n",
      "============================================================\n",
      "실험 5: 모델 학습 완료.\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "실험 5 결과 - RMSE: 0.5427, MAE: 0.4255, MAPE: 15.05%\n",
      "\n",
      "============================================================\n",
      "CLASSIFICATION버전 모델 성능 통계 (5회 실행 평균)\n",
      "============================================================\n",
      "평균 MSE: 0.2957 (표준편차: 0.0045)\n",
      "평균 RMSE: 0.5438 (표준편차: 0.0041)\n",
      "평균 MAE : 0.4313 (표준편차: 0.0110)\n",
      "평균 MAPE: 15.06% (표준편차: 0.18)\n",
      "============================================================\n",
      "--- [CLASSIFICATION] 버전 최종 성능 요약 테이블 ---\n",
      "csv로 저장 완료\n",
      "../Dataset/states/fl_split_CLUSTERING.jsonl\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   review_id     10000 non-null  object\n",
      " 1   user_id       10000 non-null  object\n",
      " 2   business_id   10000 non-null  object\n",
      " 3   review_stars  10000 non-null  int64 \n",
      " 4   text          10000 non-null  object\n",
      " 5   embedding     10000 non-null  object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 468.9+ KB\n",
      "전체 데이터셋 크기: 10000\n",
      "6672\n",
      "732\n",
      "전체 데이터 수: 10000\n",
      "학습 데이터 수: 7000 (70.00%)\n",
      "검증 데이터 수: 1000 (10.00%)\n",
      "테스트 데이터 수: 2000 (20.00%)\n",
      "학습 임베딩 데이터 형태: (7000, 3072)\n",
      "검증 임베딩 데이터 형태: (1000, 3072)\n",
      "테스트 임베딩 데이터 형태: (2000, 3072)\n",
      "데이터 type: float32\n",
      "\n",
      "==== [CLUSTERING] 버전 학습 시작\n",
      "Epoch 1/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 4.4544 - mae: 1.5703 - rmse: 1.9882\n",
      "Epoch 1: val_rmse improved from None to 0.56038, saving model to final_best_gemini_model_CLUSTERING_main.keras\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 46ms/step - loss: 1.7320 - mae: 0.9089 - rmse: 1.3161 - val_loss: 0.3140 - val_mae: 0.4520 - val_rmse: 0.5604\n",
      "Epoch 2/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.3437 - mae: 0.4745 - rmse: 0.5861\n",
      "Epoch 2: val_rmse improved from 0.56038 to 0.54117, saving model to final_best_gemini_model_CLUSTERING_main.keras\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.3214 - mae: 0.4540 - rmse: 0.5669 - val_loss: 0.2929 - val_mae: 0.4211 - val_rmse: 0.5412\n",
      "Epoch 3/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.2350 - mae: 0.3728 - rmse: 0.4846\n",
      "Epoch 3: val_rmse did not improve from 0.54117\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.2200 - mae: 0.3596 - rmse: 0.4690 - val_loss: 0.3497 - val_mae: 0.4829 - val_rmse: 0.5914\n",
      "Epoch 4/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.1245 - mae: 0.2597 - rmse: 0.3527\n",
      "Epoch 4: val_rmse did not improve from 0.54117\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.1339 - mae: 0.2706 - rmse: 0.3659 - val_loss: 0.3626 - val_mae: 0.4938 - val_rmse: 0.6022\n",
      "Epoch 5/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0908 - mae: 0.2158 - rmse: 0.3012\n",
      "Epoch 5: val_rmse did not improve from 0.54117\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 0.0948 - mae: 0.2200 - rmse: 0.3079 - val_loss: 0.3546 - val_mae: 0.4788 - val_rmse: 0.5954\n",
      "Epoch 6/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0666 - mae: 0.1815 - rmse: 0.2578\n",
      "Epoch 6: val_rmse did not improve from 0.54117\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0733 - mae: 0.1906 - rmse: 0.2707 - val_loss: 0.3544 - val_mae: 0.4731 - val_rmse: 0.5953\n",
      "Epoch 7/50\n",
      "\u001b[1m15/55\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 149ms/step - loss: 0.0564 - mae: 0.1684 - rmse: 0.2374\n",
      "Epoch 7: val_rmse did not improve from 0.54117\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m-0s\u001b[0m -9132us/step - loss: 0.0578 - mae: 0.1701 - rmse: 0.2404 - val_loss: 0.3713 - val_mae: 0.4974 - val_rmse: 0.6093\n",
      "Epoch 8/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0402 - mae: 0.1421 - rmse: 0.2005\n",
      "Epoch 8: val_rmse did not improve from 0.54117\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0413 - mae: 0.1428 - rmse: 0.2033 - val_loss: 0.3754 - val_mae: 0.4970 - val_rmse: 0.6127\n",
      "Epoch 9/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0267 - mae: 0.1179 - rmse: 0.1634\n",
      "Epoch 9: val_rmse did not improve from 0.54117\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0294 - mae: 0.1213 - rmse: 0.1716 - val_loss: 0.3594 - val_mae: 0.4805 - val_rmse: 0.5995\n",
      "Epoch 10/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0223 - mae: 0.1074 - rmse: 0.1493\n",
      "Epoch 10: val_rmse did not improve from 0.54117\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.0239 - mae: 0.1118 - rmse: 0.1545 - val_loss: 0.3639 - val_mae: 0.4828 - val_rmse: 0.6033\n",
      "Epoch 11/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0192 - mae: 0.1036 - rmse: 0.1384\n",
      "Epoch 11: val_rmse did not improve from 0.54117\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0202 - mae: 0.1051 - rmse: 0.1420 - val_loss: 0.3703 - val_mae: 0.4894 - val_rmse: 0.6085\n",
      "Epoch 12/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0150 - mae: 0.0910 - rmse: 0.1225\n",
      "Epoch 12: val_rmse did not improve from 0.54117\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.0161 - mae: 0.0929 - rmse: 0.1267 - val_loss: 0.3680 - val_mae: 0.4852 - val_rmse: 0.6066\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "CLUSTERING버전 모델 성능 평가\n",
      "MSE: 0.3175\n",
      "RMSE: 0.5635\n",
      "MAE: 0.4414\n",
      "MAPE: 16.70%\n",
      "\n",
      "============================================================\n",
      "                   실험 1/5 시작\n",
      "============================================================\n",
      "실험 1: 모델 학습 완료.\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "실험 1 결과 - RMSE: 0.5598, MAE: 0.4508, MAPE: 16.27%\n",
      "\n",
      "============================================================\n",
      "                   실험 2/5 시작\n",
      "============================================================\n",
      "실험 2: 모델 학습 완료.\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "실험 2 결과 - RMSE: 0.5709, MAE: 0.4625, MAPE: 15.77%\n",
      "\n",
      "============================================================\n",
      "                   실험 3/5 시작\n",
      "============================================================\n",
      "실험 3: 모델 학습 완료.\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "실험 3 결과 - RMSE: 0.5685, MAE: 0.4645, MAPE: 16.27%\n",
      "\n",
      "============================================================\n",
      "                   실험 4/5 시작\n",
      "============================================================\n",
      "실험 4: 모델 학습 완료.\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "실험 4 결과 - RMSE: 0.5639, MAE: 0.4465, MAPE: 16.98%\n",
      "\n",
      "============================================================\n",
      "                   실험 5/5 시작\n",
      "============================================================\n",
      "실험 5: 모델 학습 완료.\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "실험 5 결과 - RMSE: 0.5607, MAE: 0.4423, MAPE: 16.66%\n",
      "\n",
      "============================================================\n",
      "CLUSTERING버전 모델 성능 통계 (5회 실행 평균)\n",
      "============================================================\n",
      "평균 MSE: 0.3190 (표준편차: 0.0049)\n",
      "평균 RMSE: 0.5647 (표준편차: 0.0043)\n",
      "평균 MAE : 0.4533 (표준편차: 0.0088)\n",
      "평균 MAPE: 16.39% (표준편차: 0.41)\n",
      "============================================================\n",
      "--- [CLUSTERING] 버전 최종 성능 요약 테이블 ---\n",
      "csv로 저장 완료\n",
      "../Dataset/states/fl_split_SEMANTIC_SIMILARITY.jsonl\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   review_id     10000 non-null  object\n",
      " 1   user_id       10000 non-null  object\n",
      " 2   business_id   10000 non-null  object\n",
      " 3   review_stars  10000 non-null  int64 \n",
      " 4   text          10000 non-null  object\n",
      " 5   embedding     10000 non-null  object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 468.9+ KB\n",
      "전체 데이터셋 크기: 10000\n",
      "6672\n",
      "732\n",
      "전체 데이터 수: 10000\n",
      "학습 데이터 수: 7000 (70.00%)\n",
      "검증 데이터 수: 1000 (10.00%)\n",
      "테스트 데이터 수: 2000 (20.00%)\n",
      "학습 임베딩 데이터 형태: (7000, 3072)\n",
      "검증 임베딩 데이터 형태: (1000, 3072)\n",
      "테스트 임베딩 데이터 형태: (2000, 3072)\n",
      "데이터 type: float32\n",
      "\n",
      "==== [SEMANTIC_SIMILARITY] 버전 학습 시작\n",
      "Epoch 1/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 3.7022 - mae: 1.4092 - rmse: 1.8067\n",
      "Epoch 1: val_rmse improved from None to 0.58071, saving model to final_best_gemini_model_SEMANTIC_SIMILARITY_main.keras\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - loss: 1.4290 - mae: 0.8224 - rmse: 1.1954 - val_loss: 0.3372 - val_mae: 0.4663 - val_rmse: 0.5807\n",
      "Epoch 2/50\n",
      "\u001b[1m12/55\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 185ms/step - loss: 0.3262 - mae: 0.4514 - rmse: 0.5706\n",
      "Epoch 2: val_rmse did not improve from 0.58071\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m-0s\u001b[0m -6648us/step - loss: 0.3009 - mae: 0.4293 - rmse: 0.5486 - val_loss: 0.3518 - val_mae: 0.4795 - val_rmse: 0.5931\n",
      "Epoch 3/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.1877 - mae: 0.3296 - rmse: 0.4332\n",
      "Epoch 3: val_rmse did not improve from 0.58071\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.1878 - mae: 0.3247 - rmse: 0.4333 - val_loss: 0.3532 - val_mae: 0.4709 - val_rmse: 0.5943\n",
      "Epoch 4/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.1167 - mae: 0.2467 - rmse: 0.3413\n",
      "Epoch 4: val_rmse did not improve from 0.58071\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.1152 - mae: 0.2481 - rmse: 0.3394 - val_loss: 0.3558 - val_mae: 0.4673 - val_rmse: 0.5965\n",
      "Epoch 5/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0811 - mae: 0.2031 - rmse: 0.2847\n",
      "Epoch 5: val_rmse did not improve from 0.58071\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.0833 - mae: 0.2041 - rmse: 0.2887 - val_loss: 0.3663 - val_mae: 0.4746 - val_rmse: 0.6052\n",
      "Epoch 6/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0621 - mae: 0.1712 - rmse: 0.2491\n",
      "Epoch 6: val_rmse did not improve from 0.58071\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0628 - mae: 0.1767 - rmse: 0.2506 - val_loss: 0.3781 - val_mae: 0.4802 - val_rmse: 0.6149\n",
      "Epoch 7/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0420 - mae: 0.1458 - rmse: 0.2049\n",
      "Epoch 7: val_rmse did not improve from 0.58071\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.0458 - mae: 0.1522 - rmse: 0.2141 - val_loss: 0.3767 - val_mae: 0.4826 - val_rmse: 0.6137\n",
      "Epoch 8/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0313 - mae: 0.1253 - rmse: 0.1767\n",
      "Epoch 8: val_rmse did not improve from 0.58071\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0333 - mae: 0.1315 - rmse: 0.1825 - val_loss: 0.3868 - val_mae: 0.4873 - val_rmse: 0.6219\n",
      "Epoch 9/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0249 - mae: 0.1145 - rmse: 0.1576\n",
      "Epoch 9: val_rmse did not improve from 0.58071\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0260 - mae: 0.1179 - rmse: 0.1612 - val_loss: 0.3900 - val_mae: 0.4918 - val_rmse: 0.6245\n",
      "Epoch 10/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0186 - mae: 0.1004 - rmse: 0.1364\n",
      "Epoch 10: val_rmse did not improve from 0.58071\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0205 - mae: 0.1049 - rmse: 0.1432 - val_loss: 0.3798 - val_mae: 0.4844 - val_rmse: 0.6163\n",
      "Epoch 11/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0147 - mae: 0.0890 - rmse: 0.1213\n",
      "Epoch 11: val_rmse did not improve from 0.58071\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0162 - mae: 0.0924 - rmse: 0.1274 - val_loss: 0.3915 - val_mae: 0.4917 - val_rmse: 0.6257\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "SEMANTIC_SIMILARITY버전 모델 성능 평가\n",
      "MSE: 0.3327\n",
      "RMSE: 0.5768\n",
      "MAE: 0.4688\n",
      "MAPE: 16.32%\n",
      "\n",
      "============================================================\n",
      "                   실험 1/5 시작\n",
      "============================================================\n",
      "실험 1: 모델 학습 완료.\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "실험 1 결과 - RMSE: 0.5603, MAE: 0.4373, MAPE: 15.68%\n",
      "\n",
      "============================================================\n",
      "                   실험 2/5 시작\n",
      "============================================================\n",
      "실험 2: 모델 학습 완료.\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "실험 2 결과 - RMSE: 0.5643, MAE: 0.4408, MAPE: 16.48%\n",
      "\n",
      "============================================================\n",
      "                   실험 3/5 시작\n",
      "============================================================\n",
      "실험 3: 모델 학습 완료.\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "실험 3 결과 - RMSE: 0.5639, MAE: 0.4507, MAPE: 16.13%\n",
      "\n",
      "============================================================\n",
      "                   실험 4/5 시작\n",
      "============================================================\n",
      "실험 4: 모델 학습 완료.\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "실험 4 결과 - RMSE: 0.5592, MAE: 0.4412, MAPE: 15.92%\n",
      "\n",
      "============================================================\n",
      "                   실험 5/5 시작\n",
      "============================================================\n",
      "실험 5: 모델 학습 완료.\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m-4s\u001b[0m 5ms/step\n",
      "실험 5 결과 - RMSE: 0.5601, MAE: 0.4412, MAPE: 16.28%\n",
      "\n",
      "============================================================\n",
      "SEMANTIC_SIMILARITY버전 모델 성능 통계 (5회 실행 평균)\n",
      "============================================================\n",
      "평균 MSE: 0.3153 (표준편차: 0.0024)\n",
      "평균 RMSE: 0.5615 (표준편차: 0.0021)\n",
      "평균 MAE : 0.4423 (표준편차: 0.0045)\n",
      "평균 MAPE: 16.10% (표준편차: 0.28)\n",
      "============================================================\n",
      "--- [SEMANTIC_SIMILARITY] 버전 최종 성능 요약 테이블 ---\n",
      "csv로 저장 완료\n"
     ]
    }
   ],
   "source": [
    "# 기존 모델 학습 코드를 이은다음에 for task in TASK로 반복 실행\n",
    "\n",
    "for task in TASK:\n",
    "    input_file = \"../Dataset/states/fl_split_\" + task + \".jsonl\"\n",
    "    print(input_file)\n",
    "\n",
    "    df_processed = pd.read_json(\n",
    "        input_file,\n",
    "        lines=True,\n",
    "    )\n",
    "\n",
    "    df_processed.info()\n",
    "\n",
    "    df_processed.head(10)\n",
    "\n",
    "    print(f\"전체 데이터셋 크기: {len(df_processed)}\")\n",
    "\n",
    "    # 각 인코더 객체 생성\n",
    "    user_encoder = LabelEncoder()\n",
    "    business_encoder = LabelEncoder()\n",
    "\n",
    "    # 인코딩 수행\n",
    "    encoded_user_ids = user_encoder.fit_transform(df_processed[\"user_id\"])\n",
    "    encoded_business_ids = business_encoder.fit_transform(df_processed[\"business_id\"])\n",
    "\n",
    "    # 데이터프레임에 인코딩된 열 추가\n",
    "    df_processed[\"user_encoded\"] = encoded_user_ids\n",
    "    df_processed[\"business_encoded\"] = encoded_business_ids\n",
    "\n",
    "    # 리뷰 데이터에서 고유한 사용자와 비지니스 수 계산(이후 모델 입력에 사용)\n",
    "\n",
    "    num_users = len(user_encoder.classes_)\n",
    "    num_businesses = len(business_encoder.classes_)\n",
    "\n",
    "    print(num_users)\n",
    "    print(num_businesses)\n",
    "\n",
    "    # 7:1:2 비율로 데이터셋을 학습, 검증, 테스트로 나누기\n",
    "    # 먼저 학습+검증 / 테스트로 나눔\n",
    "    # 그 후 학습 / 검증으로 나눔\n",
    "\n",
    "    # 학습+검증 / 테스트\n",
    "    train_val_df, test_df = train_test_split(\n",
    "        df_processed, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    # 학습 / 검증\n",
    "    val_size_ratio = 1 / 8  # 전체 데이터의 10% = 학습+검증 데이터의 12.5%\n",
    "    train_df, val_df = train_test_split(\n",
    "        train_val_df, test_size=val_size_ratio, random_state=42\n",
    "    )\n",
    "\n",
    "    print(f\"전체 데이터 수: {len(df_processed)}\")\n",
    "    print(\n",
    "        f\"학습 데이터 수: {len(train_df)} ({len(train_df)/len(df_processed)*100:.2f}%)\"\n",
    "    )\n",
    "    print(f\"검증 데이터 수: {len(val_df)} ({len(val_df)/len(df_processed)*100:.2f}%)\")\n",
    "    print(\n",
    "        f\"테스트 데이터 수: {len(test_df)} ({len(test_df)/len(df_processed)*100:.2f}%)\"\n",
    "    )\n",
    "\n",
    "    train_embeddings = np.array(train_df[\"embedding\"].tolist(), dtype=np.float32)\n",
    "    val_embeddings = np.array(val_df[\"embedding\"].tolist(), dtype=np.float32)\n",
    "    test_embeddings = np.array(test_df[\"embedding\"].tolist(), dtype=np.float32)\n",
    "\n",
    "    print(f\"학습 임베딩 데이터 형태: {train_embeddings.shape}\")\n",
    "    print(f\"검증 임베딩 데이터 형태: {val_embeddings.shape}\")\n",
    "    print(f\"테스트 임베딩 데이터 형태: {test_embeddings.shape}\")\n",
    "\n",
    "    print(f\"데이터 type: {train_embeddings.dtype}\")\n",
    "\n",
    "    # user_id, business_id의 벡터 차원\n",
    "    user_business_embedding_dim = 64\n",
    "\n",
    "    # 유저-비즈니스 상호작용을 처리하는 MLP의 레이어 크기\n",
    "    user_biz_mlp_dims = [128, 64]\n",
    "\n",
    "    # 제미나이 리뷰 텍스트 임베딩 차원\n",
    "    gemini_embedding_dim = 3072\n",
    "\n",
    "    # 최종 예측을 위한 MLP의 각 레이어 크기\n",
    "    final_mlp_dims = [32, 16]\n",
    "\n",
    "    # 학습률\n",
    "    learning_rate = 0.001\n",
    "\n",
    "    # 배치 사이즈\n",
    "    batch_size = 128\n",
    "    # batch_size = 32\n",
    "\n",
    "    # 입력층 정의\n",
    "    user_input = keras.Input(shape=(1,), name=\"user_id_input\")\n",
    "    business_input = keras.Input(shape=(1,), name=\"business_id_input\")\n",
    "\n",
    "    # 임베딩 레이어: 각 유저/비즈니스 ID를 고유한 벡터로 변환\n",
    "    user_embedding_layer = layers.Embedding(\n",
    "        num_users, user_business_embedding_dim, name=\"user_embedding\"\n",
    "    )\n",
    "    business_embedding_layer = layers.Embedding(\n",
    "        num_businesses, user_business_embedding_dim, name=\"business_embedding\"\n",
    "    )\n",
    "\n",
    "    user_vec = layers.Flatten()(user_embedding_layer(user_input))\n",
    "    business_vec = layers.Flatten()(business_embedding_layer(business_input))\n",
    "\n",
    "    # 두 벡터를 하나로 합침\n",
    "    combined_vec = layers.concatenate([user_vec, business_vec])\n",
    "\n",
    "    # 합쳐진 벡터를 MLP에 통과시켜 상호작용 특징을 추출\n",
    "    interaction_features = combined_vec\n",
    "    for dim in user_biz_mlp_dims:\n",
    "        interaction_features = layers.Dense(dim, activation=\"relu\")(\n",
    "            interaction_features\n",
    "        )\n",
    "\n",
    "    # 입력층 정의\n",
    "    gemini_input = keras.Input(\n",
    "        shape=(gemini_embedding_dim,), name=\"gemini_embedding_input\"\n",
    "    )\n",
    "\n",
    "    # 제미나이 임베딩(리뷰 텍스트)을 처리하는 MLP\n",
    "    review_features = layers.Dense(1536, activation=\"relu\")(gemini_input)\n",
    "    review_features = layers.Dense(768, activation=\"relu\")(review_features)\n",
    "    review_features = layers.Dense(512, activation=\"relu\")(review_features)\n",
    "    # review_features = layers.Dense(256, activation=\"relu\")(review_features)\n",
    "\n",
    "    # 모듈 1과 모듈 2에서 추출된 특징들을 concat\n",
    "    final_combined_features = layers.concatenate(\n",
    "        [interaction_features, review_features]\n",
    "    )\n",
    "\n",
    "    # 최종적으로 별점을 예측하는 MLP\n",
    "    predicted_rating = final_combined_features\n",
    "    for dim in final_mlp_dims:\n",
    "        predicted_rating = layers.Dense(dim, activation=\"relu\")(predicted_rating)\n",
    "\n",
    "    # 출력층 : 1개의 숫자로 된 최종 별점을 예측\n",
    "    output_rating = layers.Dense(1, activation=\"linear\", name=\"output_rating\")(\n",
    "        predicted_rating\n",
    "    )\n",
    "\n",
    "    # 최종 모델 정의, 어떤 입력들을 받고 어떤 출력을 내보낼지 설정\n",
    "    final_model = models.Model(\n",
    "        inputs=[user_input, business_input, gemini_input], outputs=output_rating\n",
    "    )\n",
    "\n",
    "    ############################################################\n",
    "\n",
    "    final_model.compile(\n",
    "        # Adam 옵티마이저\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        # loss 함수 = 평균 제곱 오차 (MSE)\n",
    "        loss=\"mse\",\n",
    "        # 학습 중 모니터링할 지표 설정(rmse, mae)\n",
    "        metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"rmse\"), \"mae\"],\n",
    "    )\n",
    "\n",
    "    final_model_base_path = f\"final_best_gemini_model_{task}\"\n",
    "\n",
    "    early_stopping_callback = callbacks.EarlyStopping(\n",
    "        monitor=\"val_rmse\",\n",
    "        patience=10,\n",
    "        min_delta=0.0005,\n",
    "        mode=\"min\",\n",
    "        restore_best_weights=True,\n",
    "    )\n",
    "\n",
    "    final_model_path = f\"{final_model_base_path}_main.keras\"\n",
    "\n",
    "    model_checkpoint_callback = callbacks.ModelCheckpoint(\n",
    "        filepath=final_model_path,\n",
    "        monitor=\"val_rmse\",\n",
    "        save_best_only=True,\n",
    "        mode=\"min\",\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    #####################################################\n",
    "\n",
    "    print(f\"\\n==== [{task}] 버전 학습 시작\")\n",
    "\n",
    "    epochs = 50\n",
    "\n",
    "    history = final_model.fit(\n",
    "        # 입력 데이터\n",
    "        {\n",
    "            \"user_id_input\": train_df[\"user_encoded\"],\n",
    "            \"business_id_input\": train_df[\"business_encoded\"],\n",
    "            \"gemini_embedding_input\": train_embeddings,\n",
    "        },\n",
    "        # 정답 데이터\n",
    "        train_df[\"review_stars\"],\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        # 검증 시 사용할 데이터\n",
    "        validation_data=(\n",
    "            {\n",
    "                \"user_id_input\": val_df[\"user_encoded\"],\n",
    "                \"business_id_input\": val_df[\"business_encoded\"],\n",
    "                \"gemini_embedding_input\": val_embeddings,\n",
    "            },\n",
    "            val_df[\"review_stars\"],\n",
    "        ),\n",
    "        # 콜백 설정\n",
    "        callbacks=[early_stopping_callback, model_checkpoint_callback],\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    #########################################################################################\n",
    "\n",
    "    final_model = keras.models.load_model(final_model_path)\n",
    "\n",
    "    test_predictions = final_model.predict(\n",
    "        {\n",
    "            \"user_id_input\": test_df[\"user_encoded\"],\n",
    "            \"business_id_input\": test_df[\"business_encoded\"],\n",
    "            \"gemini_embedding_input\": test_embeddings,\n",
    "        }\n",
    "    ).flatten()\n",
    "\n",
    "    # 테스트 데이터 평점 열을 nparray로 가져옴\n",
    "    true_ratings = test_df[\"review_stars\"].values\n",
    "\n",
    "    # 각종 평가지표 계산\n",
    "    mse = mean_squared_error(true_ratings, test_predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(true_ratings, test_predictions)\n",
    "    mape = mean_absolute_percentage_error(true_ratings, test_predictions) * 100\n",
    "\n",
    "    # 출력\n",
    "    print(f\"{task}버전 모델 성능 평가\")\n",
    "    print(f\"MSE: {mse:.4f}\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "    print(f\"MAPE: {mape:.2f}%\")\n",
    "\n",
    "    # 5번 반복해 테스트하고 각 평가지표들의 표준편차가 < 0.005 인지 확인\n",
    "\n",
    "    # 각 실행의 평가지표를 저장할 리스트 초기화\n",
    "    mse_scores = []\n",
    "    rmse_scores = []\n",
    "    mae_scores = []\n",
    "    mape_scores = []\n",
    "\n",
    "    # 총 실행 횟수\n",
    "    num_runs = 5\n",
    "    for i in range(num_runs):\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(f\"                   실험 {i+1}/{num_runs} 시작\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "        user_input = keras.Input(shape=(1,), name=\"user_id_input\")\n",
    "        business_input = keras.Input(shape=(1,), name=\"business_id_input\")\n",
    "        gemini_input = keras.Input(\n",
    "            shape=(gemini_embedding_dim,), name=\"gemini_embedding_input\"\n",
    "        )\n",
    "\n",
    "        user_embedding_layer = layers.Embedding(\n",
    "            num_users, user_business_embedding_dim, name=\"user_embedding\"\n",
    "        )\n",
    "        business_embedding_layer = layers.Embedding(\n",
    "            num_businesses, user_business_embedding_dim, name=\"business_embedding\"\n",
    "        )\n",
    "        user_vec = layers.Flatten()(user_embedding_layer(user_input))\n",
    "        business_vec = layers.Flatten()(business_embedding_layer(business_input))\n",
    "        combined_vec = layers.concatenate([user_vec, business_vec])\n",
    "        interaction_features = combined_vec\n",
    "        for dim in user_biz_mlp_dims:\n",
    "            interaction_features = layers.Dense(dim, activation=\"relu\")(\n",
    "                interaction_features\n",
    "            )\n",
    "\n",
    "        review_features = layers.Dense(1536, activation=\"relu\")(gemini_input)\n",
    "        review_features = layers.Dense(768, activation=\"relu\")(review_features)\n",
    "        review_features = layers.Dense(512, activation=\"relu\")(review_features)\n",
    "\n",
    "        final_combined_features = layers.concatenate(\n",
    "            [interaction_features, review_features]\n",
    "        )\n",
    "        predicted_rating = final_combined_features\n",
    "        for dim in final_mlp_dims:\n",
    "            predicted_rating = layers.Dense(dim, activation=\"relu\")(predicted_rating)\n",
    "        output_rating = layers.Dense(1, activation=\"linear\", name=\"output_rating\")(\n",
    "            predicted_rating\n",
    "        )\n",
    "\n",
    "        run_model = models.Model(\n",
    "            inputs=[user_input, business_input, gemini_input], outputs=output_rating\n",
    "        )\n",
    "        run_model.compile(\n",
    "            optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"rmse\"), \"mae\"],\n",
    "        )\n",
    "\n",
    "        ########\n",
    "\n",
    "        run_ckpt_path = f\"{final_model_base_path}_run{i+1}.keras\"\n",
    "        run_es = callbacks.EarlyStopping(\n",
    "            monitor=\"val_rmse\",\n",
    "            patience=10,\n",
    "            min_delta=0.0005,\n",
    "            mode=\"min\",\n",
    "            restore_best_weights=True,\n",
    "        )\n",
    "        run_ckpt = callbacks.ModelCheckpoint(\n",
    "            filepath=run_ckpt_path,\n",
    "            monitor=\"val_rmse\",\n",
    "            save_best_only=True,\n",
    "            mode=\"min\",\n",
    "            verbose=0,\n",
    "        )\n",
    "\n",
    "        ########\n",
    "\n",
    "        run_model.fit(\n",
    "            {\n",
    "                \"user_id_input\": train_df[\"user_encoded\"],\n",
    "                \"business_id_input\": train_df[\"business_encoded\"],\n",
    "                \"gemini_embedding_input\": train_embeddings,\n",
    "            },\n",
    "            train_df[\"review_stars\"],\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            validation_data=(\n",
    "                {\n",
    "                    \"user_id_input\": val_df[\"user_encoded\"],\n",
    "                    \"business_id_input\": val_df[\"business_encoded\"],\n",
    "                    \"gemini_embedding_input\": val_embeddings,\n",
    "                },\n",
    "                val_df[\"review_stars\"],\n",
    "            ),\n",
    "            callbacks=[run_es, run_ckpt],\n",
    "            verbose=0,\n",
    "        )\n",
    "        print(f\"실험 {i+1}: 모델 학습 완료.\")\n",
    "\n",
    "        best_model = keras.models.load_model(run_ckpt_path)\n",
    "\n",
    "        predictions = best_model.predict(\n",
    "            {\n",
    "                \"user_id_input\": test_df[\"user_encoded\"],\n",
    "                \"business_id_input\": test_df[\"business_encoded\"],\n",
    "                \"gemini_embedding_input\": test_embeddings,\n",
    "            }\n",
    "        ).flatten()\n",
    "\n",
    "        true_ratings = test_df[\"review_stars\"].values\n",
    "        mse = mean_squared_error(true_ratings, predictions)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae = mean_absolute_error(true_ratings, predictions)\n",
    "        mape = mean_absolute_percentage_error(true_ratings, predictions) * 100\n",
    "\n",
    "        # 결과 저장\n",
    "        mse_scores.append(mse)\n",
    "        rmse_scores.append(rmse)\n",
    "        mae_scores.append(mae)\n",
    "        mape_scores.append(mape)\n",
    "\n",
    "        print(f\"실험 {i+1} 결과 - RMSE: {rmse:.4f}, MAE: {mae:.4f}, MAPE: {mape:.2f}%\")\n",
    "\n",
    "        ####\n",
    "\n",
    "        del run_model\n",
    "        del best_model\n",
    "        del predictions\n",
    "\n",
    "        import gc\n",
    "\n",
    "        gc.collect()\n",
    "\n",
    "        tf.keras.backend.clear_session()\n",
    "\n",
    "    # mse 평가지표의 평균과 표준편차 계산\n",
    "    avg_mse = np.mean(mse_scores)\n",
    "    std_mse = np.std(mse_scores)\n",
    "\n",
    "    # rmse 평가지표의 평균과 표준편차 계산\n",
    "    avg_rmse = np.mean(rmse_scores)\n",
    "    std_rmse = np.std(rmse_scores)\n",
    "\n",
    "    # mae 평가지표의 평균과 표준편차 계산\n",
    "    avg_mae = np.mean(mae_scores)\n",
    "    std_mae = np.std(mae_scores)\n",
    "\n",
    "    # mape 평가지표의 평균과 표준편차 계산\n",
    "    avg_mape = np.mean(mape_scores)\n",
    "    std_mape = np.std(mape_scores)\n",
    "\n",
    "    # --- 최종 결과 보고 ---\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(f\"{task}버전 모델 성능 통계 (5회 실행 평균)\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"평균 MSE: {avg_mse:.4f} (표준편차: {std_mse:.4f})\")\n",
    "    print(f\"평균 RMSE: {avg_rmse:.4f} (표준편차: {std_rmse:.4f})\")\n",
    "    print(f\"평균 MAE : {avg_mae:.4f} (표준편차: {std_mae:.4f})\")\n",
    "    print(f\"평균 MAPE: {avg_mape:.2f}% (표준편차: {std_mape:.2f})\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # 결과 데이터를 딕셔너리 형태로 구성\n",
    "    # 각 평가지표에 대한 5회의 실행 결과, 평균, 표준편차를 정리\n",
    "    summary_data = {\n",
    "        \"Metric\": [\"MSE\", \"RMSE\", \"MAE\", \"MAPE (%)\"],\n",
    "        \"Run 1\": [mse_scores[0], rmse_scores[0], mae_scores[0], mape_scores[0]],\n",
    "        \"Run 2\": [mse_scores[1], rmse_scores[1], mae_scores[1], mape_scores[1]],\n",
    "        \"Run 3\": [mse_scores[2], rmse_scores[2], mae_scores[2], mape_scores[2]],\n",
    "        \"Run 4\": [mse_scores[3], rmse_scores[3], mae_scores[3], mape_scores[3]],\n",
    "        \"Run 5\": [mse_scores[4], rmse_scores[4], mae_scores[4], mape_scores[4]],\n",
    "        \"Average\": [avg_mse, avg_rmse, avg_mae, avg_mape],\n",
    "        \"Std. Deviation\": [std_mse, std_rmse, std_mae, std_mape],\n",
    "    }\n",
    "\n",
    "    # 딕셔너리를 DataFrame으로 변환\n",
    "    results_df = pd.DataFrame(summary_data)\n",
    "\n",
    "    # 가독성을 위해 소수점 자리수를 정리\n",
    "    results_df = results_df.round(\n",
    "        {\n",
    "            \"Run 1\": 4,\n",
    "            \"Run 2\": 4,\n",
    "            \"Run 3\": 4,\n",
    "            \"Run 4\": 4,\n",
    "            \"Run 5\": 4,\n",
    "            \"Average\": 4,\n",
    "            \"Std. Deviation\": 4,\n",
    "        }\n",
    "    )\n",
    "    # MAPE는 % 단위이므로 소수점 2자리로 별도 처리\n",
    "    results_df.loc[results_df[\"Metric\"] == \"MAPE (%)\"] = results_df.loc[\n",
    "        results_df[\"Metric\"] == \"MAPE (%)\"\n",
    "    ].round(2)\n",
    "\n",
    "    print(f\"--- [{task}] 버전 최종 성능 요약 테이블 ---\")\n",
    "\n",
    "    results_df.to_csv(\n",
    "        \"../performance/model_performance_\" + task + \".csv\",\n",
    "        index=False,\n",
    "        encoding=\"utf-8-sig\",\n",
    "    )\n",
    "    print(\"csv로 저장 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7f6920",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
